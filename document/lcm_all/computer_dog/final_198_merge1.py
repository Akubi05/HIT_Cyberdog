# coding: utf-8
'''
This demo show the communication interface of MR813 motion control board based on Lcm
- robot_control_cmd_lcmt.py
- cyberdog2_ctrl.toml
'''
import lcm
import sys
import time
import os
import toml
from threading import Thread, Lock
from sensor_msgs.msg import Image, LaserScan, Imu
from robot_control_cmd_lcmt import robot_control_cmd_lcmt
from robot_control_response_lcmt import robot_control_response_lcmt
import rclpy
from rclpy.node import Node
from sensor_msgs.msg import LaserScan
from rclpy.qos import QoSProfile, ReliabilityPolicy, HistoryPolicy
import numpy as np
from sensor_msgs.msg import Image
from cv_bridge import CvBridge
from rclpy.executors import MultiThreadedExecutor
import cv2
import termios
import tty
import select
from enum import Enum, auto
from pyzbar import pyzbar
from NodeBase import SteroCameraNode, DepthNode, QRCodeDetector ,YellowLightDetector
from CtrlBase import Robot_Ctrl,State
from color_config import *
import datetime
import math
import queue
from std_msgs.msg import String
# from protocol.msg import AudioPlayExtend, BmsStatus
import json
import base64
import ssl
import requests
import re
from pc_cmd_send import PC_cmd_send

IMG_SAVE_DIR = "/Users/huangzhicheng/Desktop/lcm/pictures"
if not os.path.exists(IMG_SAVE_DIR):
    os.makedirs(IMG_SAVE_DIR)
    print(f"âœ… å·²åˆ›å»ºå›¾ç‰‡å­˜å‚¨ç›®å½•: {IMG_SAVE_DIR}")

def save_debug_image(filename, image):
    full_save_path = os.path.join(IMG_SAVE_DIR, filename)
    success = cv2.imwrite(full_save_path, image)
    if success:
        print(f"ğŸ“¸ ç…§ç‰‡å·²ä¿å­˜è‡³: {full_save_path}")
    else:
        print(f"ä¿å­˜å¤±è´¥: {full_save_path}")
    return success


class Color(Enum):
    RED = 0
    GREEN = 1
    BLUE = 2
    UNKNOWN = 3

class Direction(Enum):
    UNKNOWN = 0
    Left = 1
    Right = 2

def findAllFile(base):
    for root, ds, fs in os.walk(base):
        for f in fs:
            yield f

def signal_handler(sig, frame):
    global exit_flag
    exit_flag = True
    sys.exit(0) 

class adjustment(Enum):
    near = 1
    faraway = 2
    mid = 3

class PurpleDetector():
    def __init__(self):
        self.lower_purple = np.array([120,50,50])
        self.upper_purple = np.array([170,255,255])
        self.lower_yellow = np.array([20,100,100])
        self.upper_yellow = np.array([30,255,255])
        self.bottom_roi = None
        self.yellow_roi = None
        self.angle = 0

    def get_angle(self,ellipse):
        (center,axes,angle) = ellipse
        if axes[0] < axes[1]:
            angle += 90
        angle = angle % 180
        if angle > 90:
            angle -= 180
        return angle

    def process_purple(self,origin_frame):
        print("get new frame")
        height, width = origin_frame.shape[:2]
        roi_y_start = int(height * 1/2)
        roi_y_end = int(height * 4/5)

        roi_x_start = 0
        roi_x_end = width
        enlarge_factor = 0.8
        # ROI
        self.bottom_roi = origin_frame[roi_y_start:roi_y_end, roi_x_start:roi_x_end]

        roi_height , roi_width = self.bottom_roi.shape[:2]
        hsv = cv2.cvtColor(self.bottom_roi,cv2.COLOR_BGR2HSV)
        mask = cv2.inRange(hsv,self.lower_purple,self.upper_purple)
        mask = cv2.GaussianBlur(mask, (5,5), 0)
        kernel = np.ones((5,5), np.uint8)
        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)   # å»é™¤å°å™ªç‚¹
        if cv2.__version__.startswith('3'):
        # OpenCV 3.x
            _, contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        else:
        # OpenCV 4.x
            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if (contours):
            purple_cnt = max(contours, key=cv2.contourArea)
            if cv2.contourArea(purple_cnt) > 300:
                return True
                # x, y, w, h = cv2.boundingRect(purple_cnt)
                # new_w = int(w * enlarge_factor)
                # new_h = int(h * enlarge_factor)  
                # # è®¡ç®—åç§»é‡ï¼ˆä¸­å¿ƒç‚¹ä¸å˜ï¼‰
                # dx = int((new_w - w) / 2)
                # dy = int((new_h - h) / 2)
                # # è®¡ç®—æ”¾å¤§åçš„åæ ‡ï¼Œç¡®ä¿ä¸è¶…å‡ºå›¾åƒè¾¹ç•Œ
                # new_x = max(0, x - dx)
                # new_y = 0
                # new_x2 = min(roi_width, x + w + dx)
                # new_y2 = min(roi_height, y + h + dy)

                # self.yellow_roi = self.bottom_roi[new_y:new_y2, new_x:new_x2]
                # hsv_roi = cv2.cvtColor(self.yellow_roi, cv2.COLOR_BGR2HSV)
                # yellow_mask = cv2.inRange(hsv_roi, self.lower_yellow, self.upper_yellow)
                # # å½¢æ€å­¦å¤„ç†ä¼˜åŒ–é»„è‰²åŒºåŸŸ (æ°´å¹³è¿æ¥)
                # kernel_horizontal = np.ones((1, 15), np.uint8)  
                # yellow_mask = cv2.morphologyEx(yellow_mask, cv2.MORPH_CLOSE, kernel_horizontal)        
                # if cv2.__version__.startswith('3'):
                # # OpenCV 3.x
                #     _, yellow_contours, _ = cv2.findContours(yellow_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                # else:
                # # OpenCV 4.x
                #     yellow_contours, _ = cv2.findContours(yellow_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)              
                
                # if (yellow_contours):
                #     yellow_cnt = max(yellow_contours, key=cv2.contourArea)
                #     if cv2.contourArea(yellow_cnt) > 100:
                #         self.angle = None
                #         ellipse = cv2.fitEllipse(yellow_cnt)
                #         angle = self.get_angle(ellipse)
                #         if abs(angle) <= 60:
                #             self.angle = angle
                #             return True

        return False


#ç»¿è‰²ç®­å¤´
class ArrowDetector:
    def __init__(self):
        self.convex_hull = None
        self.center = None
        self.target_point = None
        self.direction = Direction.UNKNOWN
        self.real_direction = Direction.UNKNOWN#çœŸæ­£çš„ç»“æœ
        #hsvç»¿è‰²é˜ˆå€¼
        self.lower_green = np.array([40, 40, 40])
        self.upper_green = np.array([85, 255, 255])
        #è½®å»“æ‹Ÿåˆè¶Šå¤§è¶Šç²—ç•¥
        self.approx_param = 0.02
        #é¢ç§¯é˜ˆå€¼
        self.min_area = 350
        #è·ç¦»ç›¸ç­‰é˜ˆå€¼
        self.equal_param = 0.2
        #
        self.result_frame = None
      
        self.distance = 0
        self.yaw_deg = 0
        #æœ‰æ•ˆæ–¹å‘æ•°
        self.direction_count = 0
        #neican  jibian
        self.InnerMatrix = np.array([
            [
                416.6850297391639,
                0.0,
                319.98128281389444
            ],
            [
                0.0,
                415.51316371220037,
                227.93040503278888
            ],
            [
                0.0,
                0.0,
                1.0
            ]
        ],dtype=np.float32)
        self.distCoeffs = np.array([0.0024461913801336077,
            -0.04339171678852136,
            -0.006551805033021212,
            -0.0003024566454255968,
            0.0],dtype=np.float32)

    def getGreenFrame(self,origin_frame):
        hsv_frame = cv2.cvtColor(origin_frame, cv2.COLOR_BGR2HSV)
    
        mask = cv2.inRange(hsv_frame, self.lower_green, self.upper_green)
        mask = mask.astype(np.uint8)
        #å›¾åƒæ’å€¼æ”¾å¤§ï¼ŒåŸå›¾åˆ†è¾¨ç‡è¿‡ä½
        mask = cv2.resize(mask, None, fx=2, fy=2, interpolation=cv2.INTER_LINEAR)
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)

        #cv2.imshow("mask1",mask)

        return mask


    def SortConvexHull(self):
        self.center = np.mean(self.convex_hull, axis=0)
        center_y = self.center[0][1]
        distances = np.abs(self.convex_hull[:, 0, 1] - center_y)
        sorted_indices = np.argsort(distances)
        return sorted_indices

    def judgeTarget(self,id):
        point = self.convex_hull[id]
        #
        for i in range(1,3):
            id_1 = (id + i - 5) if (id + i) > 4 else (id + i)
            id_2 = (id - i + 5) if (id - i) < 0 else (id - i)
            distance_1 = np.linalg.norm(point - self.convex_hull[id_1])
            distance_2 = np.linalg.norm(point - self.convex_hull[id_2])
            distance_threshold = (distance_1+distance_2)*self.equal_param
            diff_distance = abs(distance_1-distance_2)

            if diff_distance > distance_threshold:
                return False

        return True

    def order_points(self,pts):
        x_sorted = pts[np.argsort(pts[:, 0])]
    
        # å°†ç‚¹åˆ†ä¸ºå·¦å³ä¸¤ç»„
        left_points = x_sorted[:2] 
        right_points = x_sorted[2:]  
    
        left_points = left_points[np.argsort(left_points[:, 1])]
    
        # å³ä¾§ç‚¹ï¼šæŒ‰Yå€¼ä»å°åˆ°å¤§ï¼ˆä»ä¸Šåˆ°ä¸‹ï¼‰
        right_points = right_points[np.argsort(right_points[:, 1])]
    
        tl = left_points[0]  # å·¦ä¸Š (top-left)
        bl = left_points[1]  # å·¦ä¸‹ (bottom-left)
        br = right_points[1]  # å³ä¸‹ (bottom-right)
        tr = right_points[0]  # å³ä¸Š (top-right)
    
        # è¿”å›æ ‡å‡†é¡ºåºï¼šå·¦ä¸Šã€å³ä¸Šã€å³ä¸‹ã€å·¦ä¸‹
        return np.array([tl, tr, br, bl], dtype="float32")

    def detect_arrow(self,origin_frame):
        if origin_frame is None:
            print("fail to grab image")
            return

        self.result_frame = np.copy(origin_frame)
        self.convex_hull = None
        self.center = None
        self.target_point = None
        self.direction = Direction.UNKNOWN
        
        mask = self.getGreenFrame(origin_frame)
        if cv2.__version__.startswith('3'):
        # OpenCV 3.x
            _, contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        else:
        # OpenCV 4.x
            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        for contour in contours:
            if self.direction != Direction.UNKNOWN:#å·²ç»æ‰¾åˆ°äº†
                break
            area = cv2.contourArea(contour)
            if area < self.min_area:
                continue

            epsilon = self.approx_param * cv2.arcLength(contour, True)
            approx_contour = cv2.approxPolyDP(contour, epsilon, True)
            self.convex_hull = cv2.convexHull(approx_contour)
            # æ£€æŸ¥å‡¸åŒ…é¡¶ç‚¹æ•°é‡æ˜¯å¦ä¸ºäº”ä¸ª
            if len(self.convex_hull) == 5:
                
                sorted_indices = self.SortConvexHull()#è·å–ç´¢å¼•
            
                for id in sorted_indices:
                    if self.judgeTarget(id):
                        self.target_point = self.convex_hull[id]
                        center_x = self.center[0][0]
                        self.direction = Direction.Left if self.target_point[0][0] < center_x else Direction.Right
                        id_1 = (id + 1 - 5) if (id + 1) > 4 else (id + 1)
                        id_2 = (id - 1 + 5) if (id - 1) < 0 else (id - 1)
                        id_3 = (id + 2 - 5) if (id + 2) > 4 else (id + 2)
                        id_4 = (id - 2 + 5) if (id - 2) < 0 else (id - 2)
                        
                        point1 = self.convex_hull[id_1][0]
                        point2 = self.convex_hull[id_2][0]
                        point3 = self.convex_hull[id_3][0]
                        point4 = self.convex_hull[id_4][0]
                        pts = np.array([point1,point2,point3,point4])
                        self.rect = self.order_points(pts) 
                        self.rect = self.rect/2
                        break    

        if self.direction != Direction.UNKNOWN:
            #è®¡ç®—è·ç¦»
            if self.direction == Direction.Left:
                self.object_points = np.array([
                    [-0.058,0.043,0],
                    [0.058,0.0215,0],
                    [0.058,-0.0215,0],
                    [-0.058,-0.043,0]
                ],dtype = np.float32)
            else:
                self.object_points = np.array([
                    [-0.058,0.0215,0],
                    [0.058,0.043,0],
                    [0.058,-0.043,0],
                    [-0.058,-0.0215,0]
                ],dtype = np.float32)

            success, rvec, tvec = cv2.solvePnP(
                self.object_points,  # 3Dç‚¹
                self.rect,   # 2Dç‚¹
                self.InnerMatrix,
                self.distCoeffs
            )
            if success:
                self.distance = tvec[2]
                rotation_matrix, _ = cv2.Rodrigues(rvec)
                yaw_rad = np.arctan2(rotation_matrix[1, 0], rotation_matrix[0, 0])
                self.yaw_deg = np.degrees(yaw_rad)

        return self.direction

    #è¿”å›ç®­å¤´æ–¹å‘
    def get_arrow_direction(self,real_rgb_camera_node):
        left_count = 0
        right_count = 0
        for i in range(11):
            frame = real_rgb_camera_node.get_new_frame()
            direction = self.detect_arrow(frame)
            if direction == Direction.Left:
                left_count += 1
            if direction == Direction.Right:
                right_count += 1

        if left_count > right_count:
            most_frequent_direction = Direction.Left
        elif left_count < right_count:
            most_frequent_direction = Direction.Right
        else:
            most_frequent_direction = Direction.UNKNOWN

        if most_frequent_direction == Direction.UNKNOWN:
            #print("Direction UNKNOWN!")
            return False,most_frequent_direction

        else:
            return True,most_frequent_direction

    #åˆ©ç”¨ç®­å¤´è°ƒæ•´æœå‘å’Œè·ç¦»
    def get_arrow_adjust(self,real_rgb_camera_node):
        yaw_deg_list = []
        distance_list = []
        for i in range(7):
            frame = real_rgb_camera_node.get_new_frame()
            direction = self.detect_arrow(frame)
            if direction != Direction.UNKNOWN:
                yaw_deg_list.append(self.yaw_deg)
                distance_list.append(self.distance)
        
        if not yaw_deg_list or not distance_list:
            #print("æœªæ£€æµ‹åˆ°æœ‰æ•ˆç®­å¤´æ•°æ®ï¼Œä½¿ç”¨é»˜è®¤å€¼")
            return 10, 1.5  # è¿”å›é»˜è®¤å€¼
        
        yaw_deg_np = np.array(yaw_deg_list)
        distance_np = np.array(distance_list)
        median_yaw_deg = np.median(yaw_deg_np)
        median_distance = np.median(distance_np)

        return median_yaw_deg , median_distance
class duiqi():
    def __init__(self):
        self.angle = 0
        self.angle_iny = 0
        self.yellow_y = 0
        self.yellow_y_iny = 0
        #self.yellow_x = 0
        self.distance = 0
        self.distance_iny = 0
        #self.x_distance = 0
        #ç›´çº¿è·ç¦»å‚æ•°
        self.ratio = 0.008
        self.ratio_iny = 0.008
        #æ²¡ç”¨
        self.x_right_ratio = 0.0027
        self.x_left_ratio = 0.0027
        self.find_line = True
    
        # é»„è‰²æ£€æµ‹å‚æ•°
        # self.lab_lower = np.array([0, 0, 80])  # Labé¢œè‰²ç©ºé—´ä¸‹é™
        # self.lab_upper = np.array([255, 140, 255])  # Labé¢œè‰²ç©ºé—´ä¸Šé™
        
        # è¾¹ç¼˜æ£€æµ‹å’Œç›´çº¿æ£€æµ‹å‚æ•°
        self.canny_threshold1 = 50
        self.canny_threshold2 = 150
        self.hough_threshold = 50
        self.min_line_length = 30
        self.max_line_gap = 10
        self.horizontal_angle_tol = 20  # è§’åº¦å®¹å·®èŒƒå›´(åº¦)
        self.horizontal_angle_tol_iny = 15

        
        # å½¢æ€å­¦å¤„ç†å‚æ•°
        self.kernel_size = (10, 1)  # æ°´å¹³æ–¹å‘çš„æ ¸
        self.min_contour_area = 100

        # è°ƒè¯•å›¾åƒè·¯å¾„
        self.debug_img_path = IMG_SAVE_DIR
        os.makedirs(self.debug_img_path, exist_ok=True)
        self.img_counter = 0 
    def get_yellow_line(self, frame,Right):
        """æ£€æµ‹é»„è‰²æ¨ªçº¿å¹¶è®¡ç®—è§’åº¦å’ŒYåæ ‡å¹³å‡å€¼"""
        # æˆªå–å›¾åƒä¸‹ä¸‰åˆ†ä¹‹äºŒåŒºåŸŸ
        self.find_line = True
        height, width = frame.shape[:2]
        roi_height = int(height * 1 / 3)
        roi = frame[roi_height:, :].copy()
        roi_width = roi.shape[1]
        
        # 1. å¢å¼ºå¤„ç†ï¼ˆé€‚åº¦ä¼˜åŒ–ï¼‰
        # HSVäº®åº¦å¢å¼ºï¼ˆè§£å†³æš—åŒºï¼‰
        hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)
        hsv[:,:,2] = cv2.equalizeHist(hsv[:,:,2])  # å¢å¼ºäº®åº¦
        hsv[:,:,1] = cv2.add(hsv[:,:,1], 30)       # è½»å¾®å¢å¼ºé¥±å’Œåº¦
        
        # 2. ç›´æ¥åœ¨HSVç©ºé—´æ£€æµ‹é»„è‰²ï¼ˆæ— éœ€è½¬æ¢ä¸ºLabï¼‰
        # é»„è‰²åœ¨HSVç©ºé—´çš„èŒƒå›´ï¼šHåœ¨15-30åº¦ä¹‹é—´
        yellow_mask = cv2.inRange(hsv, (15, 80, 80), (30, 255, 255))
        
        # 3. åå¤„ç†ä¼˜åŒ–
        # åº”ç”¨å½¢æ€å­¦æ“ä½œæ›¿ä»£é«˜æ–¯æ¨¡ç³Š+é˜ˆå€¼
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
        yellow_mask = cv2.morphologyEx(yellow_mask, cv2.MORPH_OPEN, kernel)
        yellow_mask = cv2.morphologyEx(yellow_mask, cv2.MORPH_CLOSE, kernel)
        
        # 4. åç»­å¤„ç†ä¿æŒä¸å˜
        # å½¢æ€å­¦å¤„ç†å¢å¼ºç‰¹å¾
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, self.kernel_size)
        morph = cv2.morphologyEx(yellow_mask, cv2.MORPH_OPEN, kernel)        
        # Cannyè¾¹ç¼˜æ£€æµ‹
        edges = cv2.Canny(morph, self.canny_threshold1, self.canny_threshold2)
        
        # éœå¤«å˜æ¢æ£€æµ‹æ‰€æœ‰ç›´çº¿
        lines = cv2.HoughLinesP(
            edges, 
            rho=1, 
            theta=np.pi/180, 
            threshold=self.hough_threshold,
            minLineLength=self.min_line_length,
            maxLineGap=self.max_line_gap
        )
        
        # ä¿å­˜è°ƒè¯•å›¾åƒ
        # self._save_debug_images(roi, yellow_mask, morph, edges)
        
        # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°ç›´çº¿åˆ™è¿”å›
        if lines is None:
            print("No lines detected")
            self.angle = 0
            self.yellow_y = 0
            self.distance = 0
            self.find_line = False
            return morph, None
        
        # ç­›é€‰æ¨ªçº¿å¹¶è®¡ç®—ä¸­ç‚¹å’Œè§’åº¦
        candidates = []  # å­˜å‚¨å€™é€‰æ¨ªçº¿ä¿¡æ¯ (ä¸­ç‚¹x, ä¸­ç‚¹y, è§’åº¦, çº¿æ®µ)
        
        for line in lines:
            x1, y1, x2, y2 = line[0]
            # è®¡ç®—çº¿æ®µä¸­ç‚¹
            if Right == True:
                mid_x = min(x1, x2)
            else: 
                mid_x = max(x1, x2)
            mid_y = (y1 + y2)/2
            
            # è®¡ç®—çº¿æ®µè§’åº¦ï¼ˆåŒºåˆ†æ­£è´Ÿï¼‰
            angle = np.arctan2(y2 - y1, x2 - x1) * 180 / np.pi
            # å½’ä¸€åŒ–åˆ°[-90, 90]èŒƒå›´
            if angle > 90:
                angle -= 180
            elif angle < -90:
                angle += 180
            
            # ç­›é€‰æ¨ªçº¿ï¼ˆè€ƒè™‘å®¹å·®èŒƒå›´ï¼‰
            if abs(angle) < self.horizontal_angle_tol:
                # ä¿å­˜å€™é€‰ä¿¡æ¯
                candidates.append({
                    'mid_x': mid_x,
                    'mid_y': mid_y,
                    'angle': angle,
                    'line': line[0]
                })
        
        # å¦‚æœæ²¡æœ‰ç¬¦åˆçš„æ¨ªçº¿åˆ™è¿”å›
        if not candidates:
            print("No horizontal lines detected")
            self.angle = 0
            self.yellow_y = 0
            self.distance = 0
            #self.yellow_x = 0
            self.find_line = False
            return morph, None
        
        # æŒ‰mid_Xåæ ‡æ’åºï¼ˆä»å·¦åˆ°å³ï¼‰
        candidates.sort(key=lambda c: c['mid_x'])
        
        # é€‰æ‹©æœ€å·¦(å³)ä¾§çš„5æ¡æ¨ªçº¿ï¼ˆæˆ–æ‰€æœ‰å°‘äº5æ¡çš„ï¼‰
        if Right:
            selected = candidates[:5] if len(candidates) > 5 else candidates

        # æ£€æŸ¥æ˜¯å¦åœ¨åˆç†èŒƒå›´å†…ï¼šè·ç¦»æœ€å·¦(å³)æ¨ªçº¿ä¸è¶…è¿‡åŠå±
            min_x = selected[0]['mid_x']
            max_allowed_x = min_x + roi_width / 2
        # è¿‡æ»¤è¶…å‡ºèŒƒå›´çš„çº¿æ®µ
            filtered = [c for c in selected if c['mid_x'] <= max_allowed_x]
        else:
            selected = candidates[-5:] if len(candidates) > 5 else candidates
            max_x = selected[-1]['mid_x']
            max_allowed_x = max_x - roi_width / 2
            filtered = [c for c in selected if c['mid_x'] >= max_allowed_x]
        

        
        # å¦‚æœæ²¡æœ‰ç¬¦åˆçš„çº¿æ®µåˆ™ä½¿ç”¨åŸå§‹é€‰æ‹©
        if not filtered:
            print("All selected lines are too far, using all candidates")
            filtered = selected
        
        # æå–è§’åº¦å’ŒYåæ ‡
        angles = [c['angle'] for c in filtered]
        y_coords = [c['mid_y'] + roi_height for c in filtered]  # è½¬æ¢ä¸ºå…¨å›¾Yåæ ‡
        # x_coords = [c['mid_x'] for c in filtered]   ä¿å­˜Xåæ ‡
        # x_coords = min_x + np.array([c['mid_x'] - min_x for c in filtered]) 
        # è®¡ç®—å¹³å‡å€¼
        self.angle = -np.mean(angles) if angles else 0
        self.yellow_y = np.mean(y_coords) if y_coords else 0
        # if Right:
        #     self.yellow_x = min_x
        # else:
        #     self.yellow_x = max_x
        # è®¡ç®—è·ç¦»
        self.distance = (frame.shape[0] - self.yellow_y) * self.ratio if self.yellow_y else 0
        # if  Right:
        #     self.x_distance = -(self.yellow_x - 155) * self.x_right_ratio if self.yellow_x else 0    #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!155æ˜¯ç›´æ¥æµ‹çš„ æ‘†æ­£ç‹— ç›´æ¥æµ‹yellow_x x_ratioä¹Ÿæ˜¯ç›´æ¥æµ‹çš„     #!!!!!!!!!!155æ˜¯ç›´æ¥æµ‹çš„ æ‘†æ­£ç‹— ç›´æ¥æµ‹yellow_x x_ratioä¹Ÿæ˜¯ç›´æ¥æµ‹çš„ 
        # else:
        #     self.x_distance = -(self.yellow_x - 490) * self.x_left_ratio if self.yellow_x else 0    #!!!!!!!!!!155æ˜¯ç›´æ¥æµ‹çš„ æ‘†æ­£ç‹— ç›´æ¥æµ‹yellow_x x_ratioä¹Ÿæ˜¯ç›´æ¥æµ‹çš„     #!!!!!!!!!!155æ˜¯ç›´æ¥æµ‹çš„ æ‘†æ­£ç‹— ç›´æ¥æµ‹yellow_x x_ratioä¹Ÿæ˜¯ç›´æ¥æµ‹çš„ 

        # # æå–æ‰€æœ‰é€‰ä¸­çš„çº¿æ®µï¼ˆåŒ…å«ROIåæ ‡ç³»ä¸­ï¼‰
        selected_lines = [c['line'] for c in filtered]
        
        # # åˆ›å»ºå¯è§†åŒ–å›¾åƒ
        # vis_img = frame.copy()
        
        # # ç»˜åˆ¶æ‰€æœ‰å€™é€‰çº¿ï¼ˆç°è‰²ï¼‰
        # for c in candidates:
        #     x1, y1, x2, y2 = c['line']
        #     cv2.line(vis_img, 
        #              (x1, y1 + roi_height), 
        #              (x2, y2 + roi_height), 
        #              (150, 150, 150), 1)  # ç°è‰²è¡¨ç¤ºæ‰€æœ‰å€™é€‰çº¿
            
        # # ç»˜åˆ¶æœ€ç»ˆé€‰ä¸­çš„çº¿ï¼ˆç»¿è‰²ï¼‰
        # for i, c in enumerate(filtered):
        #     x1, y1, x2, y2 = c['line']
        #     cv2.line(vis_img, 
        #              (x1, y1 + roi_height), 
        #              (x2, y2 + roi_height), 
        #              (0, 255, 0), 2)  # ç»¿è‰²è¡¨ç¤ºæœ€ç»ˆé€‰ä¸­çš„çº¿
            
        #     # æ ‡è®°è§’åº¦å€¼
        #     angle_str = f"{c['angle']:.1f}Â°"
        #     mid_x = int(x1)
        #     mid_y = int((y1 + y2) / 2) + roi_height
        #     cv2.putText(vis_img, angle_str, 
        #                (mid_x, mid_y), 
        #                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)
        
        # # æ ‡è®°å¹³å‡è§’åº¦å’ŒYå€¼
        # cv2.putText(vis_img, f"Avg Angle: {self.angle:.1f}Â°", 
        #            (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
        # cv2.putText(vis_img, f"Avg Y: {self.yellow_y:.1f}", 
        #            (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
        # cv2.putText(vis_img, f"Dist: {self.distance:.1f}mm", 
        #            (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
        
        # # ç»˜åˆ¶é€‰æ‹©èŒƒå›´ï¼ˆçº¢è‰²åŠå±çº¿ï¼‰
        # cv2.line(vis_img, 
        #          (int(max_allowed_x), roi_height), 
        #          (int(max_allowed_x), height), 
        #          (0, 0, 255), 1)
        # cv2.putText(vis_img, "Selection Boundary", 
        #            (int(max_allowed_x) + 5, roi_height + 30), 
        #            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)
        
        # cv2.imwrite(f"{self.debug_img_path}result_{self.img_counter:04d}.png", vis_img)
        # self.img_counter += 1
        
        # è¿”å›æ‰€æœ‰é€‰ä¸­çš„çº¿æ®µï¼ˆåœ¨ROIåæ ‡ç³»
        return morph, selected_lines
    
    def get_yellow_line_y(self, frame):
            """æ£€æµ‹é»„è‰²æ¨ªçº¿å¹¶é€‰æ‹©æœ€ä¸Šæ–¹çš„5æ¡æ¨ªçº¿"""
            self.find_line = True
            height, width = frame.shape[:2]
            
            # æˆªå–å›¾åƒä¸‹ä¸‰åˆ†ä¹‹äºŒåŒºåŸŸ
            roi_height = int(height * 1 / 4)
            roi = frame[roi_height:, :].copy()
            roi_height_px = roi.shape[0]  # ROIåŒºåŸŸçš„é«˜åº¦ï¼ˆåƒç´ ï¼‰
            
            # 1. å¢å¼ºå¤„ç†ï¼ˆä¸get_yellow_lineç›¸åŒï¼‰
            hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)
            hsv[:,:,2] = cv2.equalizeHist(hsv[:,:,2])
            hsv[:,:,1] = cv2.add(hsv[:,:,1], 30)
            
            # 2. HSVç©ºé—´æ£€æµ‹é»„è‰² æ­£å¼çš„
            yellow_mask = cv2.inRange(hsv, (15, 80, 80), (30, 255, 255))
            #test æ—©ä¸Š
            # yellow_mask = cv2.inRange(hsv, (20, 50, 80), (40, 255, 255))
            # 3. åå¤„ç†ä¼˜åŒ–
            kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
            yellow_mask = cv2.morphologyEx(yellow_mask, cv2.MORPH_OPEN, kernel)
            yellow_mask = cv2.morphologyEx(yellow_mask, cv2.MORPH_CLOSE, kernel)
            
            # 4. å½¢æ€å­¦å¤„ç†å¢å¼ºç‰¹å¾
            kernel = cv2.getStructuringElement(cv2.MORPH_RECT, self.kernel_size)
            morph = cv2.morphologyEx(yellow_mask, cv2.MORPH_OPEN, kernel)        
            
            # 5. Cannyè¾¹ç¼˜æ£€æµ‹
            edges = cv2.Canny(morph, self.canny_threshold1, self.canny_threshold2)
            
            # 6. éœå¤«å˜æ¢æ£€æµ‹ç›´çº¿
            lines = cv2.HoughLinesP(
                edges, 
                rho=1, 
                theta=np.pi/180, 
                threshold=self.hough_threshold,
                minLineLength=self.min_line_length,
                maxLineGap=self.max_line_gap
            )
            
            # 7. å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°ç›´çº¿åˆ™è¿”å›
            if lines is None:
                print("No lines_y detected")
                self.angle_iny = 0
                self.yellow_y_iny = 0
                self.distance_iny= 0
                self.find_line = False
                return morph, None
            
            # 8. ç­›é€‰æ¨ªçº¿å¹¶è®¡ç®—ä¸­ç‚¹å’Œè§’åº¦
            candidates = []
            
            for line in lines:
                x1, y1, x2, y2 = line[0]
                mid_y = (y1 + y2)/2  # åªå…³æ³¨Yåæ ‡
                
                # è®¡ç®—çº¿æ®µè§’åº¦
                angle = np.arctan2(y2 - y1, x2 - x1) * 180 / np.pi
                if angle > 90: angle -= 180
                elif angle < -90: angle += 180
                
                # ç­›é€‰æ¨ªçº¿ï¼ˆè€ƒè™‘å®¹å·®èŒƒå›´ï¼‰
                if abs(angle) < self.horizontal_angle_tol_iny:
                    candidates.append({
                        'mid_y': mid_y,
                        'angle': angle,
                        'line': line[0]
                    })
            
            if not candidates:
                print("No horizontal lines detected")
                self.angle_iny = 0
                self.yellow_y_iny = 0
                self.distance_iny = 0
                self.find_line = False
                return morph, None
            
            # 9. æŒ‰Yåæ ‡æ’åºï¼ˆä»å°åˆ°å¤§ï¼Œå³ä»é«˜åˆ°ä½ï¼‰
            candidates.sort(key=lambda c: c['mid_y'])
            
            # 10. é€‰æ‹©æœ€ä¸Šæ–¹çš„çº¿ä½œä¸ºåŸºå‡†
            highest_y = candidates[0]['mid_y']
            
            # 11. ç¡®å®šæœ€å¤§å…è®¸Yåæ ‡å·®ï¼ˆ1/8å›¾åƒé«˜åº¦ï¼‰
            max_y_diff = roi_height_px * 0.0625
            
            # 12. ç­›é€‰ä¸æœ€é«˜çº¿ç›¸è¿‘çš„çº¿ï¼ˆæœ€å¤š5æ¡ï¼‰
            filtered = []
            for c in candidates:
                # æ£€æŸ¥æ˜¯å¦è¶…è¿‡æœ€å¤§Yå·®
                if c['mid_y'] - highest_y > max_y_diff:
                    break
                
                filtered.append(c)
                
                # æœ€å¤šå–5æ¡ç¬¦åˆæ¡ä»¶çš„çº¿
                if len(filtered) >= 5:
                    break
            
            # 13. æå–è§’åº¦å’ŒYåæ ‡
            angles = [c['angle'] for c in filtered]
            y_coords = [c['mid_y'] + roi_height for c in filtered]  # è½¬æ¢ä¸ºå…¨å›¾Yåæ ‡
            
            # 14. è®¡ç®—å¹³å‡å€¼
            self.angle_iny = -np.mean(angles) if angles else 0
            self.yellow_y_iny = np.mean(y_coords) if y_coords else 0
            self.distance_iny = (frame.shape[0] - self.yellow_y_iny) * self.ratio_iny if self.yellow_y_iny else 0
            
            # 15. æå–é€‰ä¸­çš„çº¿æ®µï¼ˆåŒ…å«ROIåæ ‡ç³»ä¸­ï¼‰
            selected_lines = [c['line'] for c in filtered]

            # # åˆ›å»ºå¯è§†åŒ–å›¾åƒ
            # vis_img = frame.copy()
            
            # # ç»˜åˆ¶æ‰€æœ‰å€™é€‰çº¿ï¼ˆç°è‰²ï¼‰
            # for c in candidates:
            #     x1, y1, x2, y2 = c['line']
            #     cv2.line(vis_img, 
            #             (x1, y1 + roi_height), 
            #             (x2, y2 + roi_height), 
            #             (150, 150, 150), 1)  # ç°è‰²è¡¨ç¤ºæ‰€æœ‰å€™é€‰çº¿
            
            # # ç»˜åˆ¶æœ€ç»ˆé€‰ä¸­çš„çº¿ï¼ˆç»¿è‰²ï¼‰
            # for i, c in enumerate(filtered):
            #     x1, y1, x2, y2 = c['line']
            #     cv2.line(vis_img, 
            #             (x1, y1 + roi_height), 
            #             (x2, y2 + roi_height), 
            #             (0, 255, 0), 2)  # ç»¿è‰²è¡¨ç¤ºæœ€ç»ˆé€‰ä¸­çš„çº¿
                
            #     # æ ‡è®°è§’åº¦å€¼
            #     angle_str = f"{c['angle']:.1f}Â°"
            #     mid_x = int((x1 + x2) / 2)
            #     mid_y = int((y1 + y2) / 2) + roi_height
            #     cv2.putText(vis_img, angle_str, 
            #             (mid_x, mid_y), 
            #             cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)
            
            # # æ ‡è®°å¹³å‡è§’åº¦å’ŒYå€¼
            # cv2.putText(vis_img, f"Avg Angle: {self.angle:.1f}Â°", 
            #         (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
            # cv2.putText(vis_img, f"Avg Y: {self.yellow_y:.1f}", 
            #         (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
            # cv2.putText(vis_img, f"Dist: {self.distance:.1f}mm", 
            #         (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
            
            # # ç»˜åˆ¶æœ€é«˜çº¿ä½ç½®ï¼ˆçº¢è‰²çº¿ï¼‰
            # cv2.line(vis_img, 
            #         (0, int(highest_y + roi_height)), 
            #         (width, int(highest_y + roi_height)), 
            #         (0, 0, 255), 1)
            # cv2.putText(vis_img, "Highest Line", 
            #         (10, int(highest_y + roi_height) - 10), 
            #         cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)
            
            # # ç»˜åˆ¶æœ€å¤§å…è®¸Yå·®èŒƒå›´ï¼ˆè“è‰²çº¿ï¼‰
            # max_y_line = int(highest_y + max_y_diff + roi_height)
            # cv2.line(vis_img, 
            #         (0, max_y_line), 
            #         (width, max_y_line), 
            #         (255, 0, 0), 1)
            # cv2.putText(vis_img, "Max Y Diff Boundary", 
            #         (10, max_y_line - 10), 
            #         cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)
            
            # # ä¿å­˜å¯è§†åŒ–å›¾åƒ
            # cv2.imwrite(f"{self.debug_img_path}result_y_{self.img_counter:04d}.png", vis_img)
            
            # # ä¿å­˜ä¸­é—´å¤„ç†å›¾åƒ
            # cv2.imwrite(f"{self.debug_img_path}roi_y_{self.img_counter:04d}.png", roi)
            # cv2.imwrite(f"{self.debug_img_path}mask_y_{self.img_counter:04d}.png", yellow_mask)
            # cv2.imwrite(f"{self.debug_img_path}morph_y_{self.img_counter:04d}.png", morph)
            # cv2.imwrite(f"{self.debug_img_path}edges_y_{self.img_counter:04d}.png", edges)
            
            # self.img_counter += 1

            return morph, selected_lines

    def _save_debug_images(self, roi, mask, morph, edges):
        """ä¿å­˜è°ƒè¯•è¿‡ç¨‹å›¾åƒ"""
        save_debug_image(f"roi_{self.img_counter:04d}.png", roi)
        save_debug_image(f"mask_{self.img_counter:04d}.png", mask)
        save_debug_image(f"morph_{self.img_counter:04d}.png", morph)
        save_debug_image(f"edges_{self.img_counter:04d}.png", edges)
    
    # def get_distance(self, frame):
    #     """è®¡ç®—é»„è‰²æ¨ªçº¿ä¸å›¾åƒåº•éƒ¨çš„è·ç¦»"""
    #     _, lines = self.get_yellow_line(frame)
        
    #     # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°ç›´çº¿ï¼Œè¿”å›-1è¡¨ç¤ºå¤±è´¥
    #     if lines is None:
    #         self.distance = -1
    #         return self.distance
        
    #     # è®¡ç®—è·ç¦»ï¼ˆä½¿ç”¨å·²è®¡ç®—çš„self.yellow_yï¼‰
    #     self.distance = (frame.shape[0] - self.yellow_y) * self.ratio
    #     return self.distance
    
    # def get_angle(self, frame):
    #     self.get_yellow_line(frame)
    #     print(f"self.angle: {self.angle}")
    #     return self.angle

def jiaozheng_bianxian(yaw): #å¼§åº¦
    w_bia = 0
    msg.mode=11
    msg.gait_id=27
    yaw_speed = 20/180*3.14     
    msg.duration= int(abs(yaw/yaw_speed)*1000)
    if yaw < 0:
        yaw_speed = -yaw_speed - w_bia
    elif yaw > 0:
        yaw_speed = yaw_speed - w_bia
    elif yaw == 0:
        pass
    print(f"yaw_speed: {yaw_speed}")
    msg.vel_des=[0.0,0.0,yaw_speed]
    msg.step_height = [0.01, 0.01]
    msg.life_count=(msg.life_count+1)%128    
    Ctrl.Send_cmd(msg)
    time.sleep(3)
#new!!!!!!!!!!
def go_short_bianxian(vel, duration):  # å‰è¿›
    msg.mode = 11
    msg.gait_id = 27
    msg.vel_des = [vel, 0.0, 0.0]
    msg.step_height = [0.01, 0.01]
    msg.duration = duration
    msg.life_count = (msg.life_count + 1) % 128
    Ctrl.Send_cmd(msg)
    Ctrl.Wait_finish_5(11, 27)
    time.sleep(1.3)

def duiqi_control(Right):
    count = 0
    while(True):
        count += 1
        frame = real_rgb_camera.get_new_frame()
        duiqi_node.get_yellow_line(frame,Right)
        print(f"Angle: {duiqi_node.angle}")
        print(f"find_line:{duiqi_node.find_line}")

        if duiqi_node.find_line == False:
            if count <= 2:
                if Right == True:
                    jiaozheng_bianxian(4*15*3.14/180)
                    frame = real_rgb_camera.get_new_frame()
                    duiqi_node.get_yellow_line(frame,Right)
                else:
                    jiaozheng_bianxian(-4*15*3.14/180)
                    frame = real_rgb_camera.get_new_frame()
                    duiqi_node.get_yellow_line(frame,Right)
            else:
                break

        # print(f"Distance: {duiqi_node.distance}")
        #time.sleep(100000)

        if duiqi_node.angle > 0.2 and duiqi_node.angle < 6:
            jiaozheng_bianxian(4.5*duiqi_node.angle*3.14/180)
        elif duiqi_node.angle >= 6:
            jiaozheng_bianxian(4.4*duiqi_node.angle*3.14/180)
        elif duiqi_node.angle < -0.2 and duiqi_node.angle > -6:
            jiaozheng_bianxian(4.4*duiqi_node.angle*3.14/180)
        elif duiqi_node.angle <= -6:
            jiaozheng_bianxian(4.8*duiqi_node.angle*3.14/180)
        print("angle_over")
        # frame = real_rgb_camera.get_new_frame()
        # duiqi_node.get_yellow_line(frame,Right)
        # vel = (duiqi_node.x_distance)/2
        # print(f"X_distance: {duiqi_node.x_distance}")
        # go_x_bianxian(vel,2000)


        frame = real_rgb_camera.get_new_frame()
        duiqi_node.get_yellow_line(frame,Right)
        print("distance_start")

        if duiqi_node.distance <= 0.6 and duiqi_node.distance > 0:
            vel = (duiqi_node.distance- 0.2)/1
            print(f"Distance: {duiqi_node.distance}, Vel: {vel}")
            #time.sleep(1)
            #standup()
            #print("standup over")
            go_short_bianxian(vel,1000)
        elif duiqi_node.distance > 0.6: 
            print(f"Distance: {duiqi_node.distance},vel: 0.2")
            #time.sleep(1)
            #standup()
            #print("standup over")
            go_short_bianxian(0.2, 1500)
        if(duiqi_node.distance <= 0.2 or duiqi_node.distance == -1 or duiqi_node.distance -0.3 <= 0.2):
            print("duiqi_over")
            break

duiqi_node = duiqi()

class s_curve_processor():
    def __init__(self):
        #å¤„ç†å¯¹è±¡
        self.left = False
        #åŸå§‹å›¾
        self.origin_frame = None
        self.origin_frame_change = None
        #é‡å¿ƒå‚è€ƒä½ç½®
        self.reference_y = 0
        #roi/ç»˜åˆ¶å›¾
        self.bottom_roi = None
        self.roi_change = None
        #é»„è‰²é˜ˆå€¼
        self.lower_yellow = np.array([20, 100, 100])
        self.upper_yellow = np.array([30, 255, 255])
        #é‡å¿ƒä½ç½®
        self.center_x = 0
        self.center_y = 0
        #è°ƒæ•´
        self.tolerance_ratio = 1/4
        self.adjust = adjustment.mid
        #æ¤­åœ†æ–œç‡
        self.angle = None
        self.rotate_speed = 0
        #
        self.coeffs = 0
        self.fit_y = 0
        self.points = 0

    def find_target_contour(self,image):
        target_contour = None
        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
        mask = cv2.inRange(hsv, self.lower_yellow, self.upper_yellow)
    
        kernel = np.ones((5,5), np.uint8)
        closed = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel, iterations=1)

        if cv2.__version__.startswith('3'):
        # OpenCV 3.x
            _, contours, _ = cv2.findContours(closed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        else:
        # OpenCV 4.x
            contours, _ = cv2.findContours(closed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        #æ‰¾é‡å¿ƒ
        target = None
        center_x = 0
        center_y = 0
        for index, cnt in enumerate(contours):
            area = cv2.contourArea(cnt)
            if area < 200:
                continue
            M = cv2.moments(cnt)
            if M["m00"] != 0:  
                cX = int(M["m10"] / M["m00"])
                cY = int(M["m01"] / M["m00"])
                if cY > center_y:
                    center_y = cY
                    center_x = cX
                    target = index

        if target == None:
            return False,target_contour
        else:
            target_contour = contours[target]
            return True,target_contour


    def image_process(self,frame):
        self.origin_frame = frame.copy()
        height, width = frame.shape[:2]
        
        roi_y_start = int(height * 2/3)
        roi_y_end = height
        # 1/3å’Œ3/4
        if self.left:
            roi_x_start = int(width * 1/4)
            roi_x_end = width
        else:
            roi_x_start = 0
            roi_x_end = int(width * 3/4)
        # ROI
        self.bottom_roi = frame[roi_y_start:roi_y_end, roi_x_start:roi_x_end]
        roi_height , roi_width = self.bottom_roi.shape[:2]
        self.reference_y = roi_height//2

        findflag,target_contour = self.find_target_contour(self.bottom_roi)
        if not findflag:
            return False
        
        M = cv2.moments(target_contour)
        if M["m00"] != 0:  
            self.center_x = int(M["m10"] / M["m00"])
            self.center_y = int(M["m01"] / M["m00"])
        #æ‰¾åˆ°äº†
        self.angle = None
        ellipse = cv2.fitEllipse(target_contour)
        angle = self.get_angle(ellipse)
        if abs(angle) <= 45:
            self.angle = angle

        return True


    def fit_yellow_curve(self, frame, flag_change, num_points=5, point_interval=30):     #å‚æ•°:frame: è¾“å…¥å›¾åƒ num_points: å·¦å³å„å–ç‚¹çš„æ•°é‡ point_interval: ç‚¹ä¹‹é—´çš„é—´éš”(åƒç´ åˆ—æ•°)
        self.origin_frame_change = frame.copy()
        height, width = frame.shape[:2]
    
        roi_y_start = int(height * 2/3)
        roi_y_end = height
        if flag_change == 0:
            roi_x_start = int(width * 1/4)
            roi_x_end = width
        else:
            roi_x_start = 0
            roi_x_end = int(width * 3/4)
        
        self.roi_change = frame[roi_y_start:roi_y_end, roi_x_start:roi_x_end]
        roi_height, roi_width = self.roi_change.shape[:2]
        
        findflag,target_contour = self.find_target_contour(self.roi_change)
        if not findflag:
            return False
            
        center_x = roi_width // 2
        mask = np.zeros((roi_height, roi_width), dtype=np.uint8)
        cv2.drawContours(mask, [target_contour], contourIdx=-1, color=255, thickness=-1)
        # åœ¨å·¦å³æ–¹å‘ç­‰é—´éš”å–æ ·ç‚¹
        points = []
        
        # å‘å³å–æ ·ç‚¹
        for i in range(num_points):
            x = center_x + i * point_interval
            if x >= roi_width: 
                break
                
            # åœ¨xä½ç½®å–ä¸€ä¸ªå‚ç›´åˆ—
            col = mask[:, x]
            
            # è®¡ç®—å½“å‰åˆ—çš„é»„è‰²åŒºåŸŸä¸­å¿ƒYåæ ‡
            if np.any(col > 0):
                y_center = np.mean(np.where(col > 0)[0])
                points.append([x, y_center])
        
        # å‘å·¦å–æ ·ç‚¹
        for i in range(num_points):
            x = center_x - (i + 1) * point_interval  
            if x < 0: 
                break
                
            # åœ¨xä½ç½®å–ä¸€ä¸ªå‚ç›´åˆ—
            col = mask[:, x]
            
            # è®¡ç®—å½“å‰åˆ—çš„é»„è‰²åŒºåŸŸä¸­å¿ƒYåæ ‡
            if np.any(col > 0):
                y_center = np.mean(np.where(col > 0)[0])
                points.append([x, y_center])
           
        if len(points) < 10: 
            return False
        
        # äºŒæ¬¡å¤šé¡¹å¼æ‹Ÿåˆ (y = axÂ² + bx + c)
        self.points = np.array(points)
        x_coords = self.points[:, 0]
        y_coords = self.points[:, 1]
        self.coeffs = np.polyfit(x_coords, y_coords, 2)

        a, b, c = self.coeffs
        
        fit_x = np.arange(0, roi_width, 1)
        self.fit_y = a * fit_x**2 + b * fit_x + c
        return True
        
    def get_angle(self,ellipse):
        (center, axes, angle) = ellipse
    
        if axes[0] < axes[1]:
            angle += 90
    
        # å°†è§’åº¦è½¬æ¢åˆ°[-90,90]èŒƒå›´
        angle = angle % 180
        if angle > 90:
            angle -= 180
    
        return angle


    def main_process(self,image):
        target = self.image_process(image)
        if target == False:
            return False
    
        upper_y = int(self.reference_y * (1 + self.tolerance_ratio*1.2))
        lower_y = int(self.reference_y * (1 - self.tolerance_ratio*0.7))
        if self.center_y < upper_y and self.center_y > lower_y:
            self.adjust = adjustment.mid
        if self.center_y <= lower_y:
            self.adjust = adjustment.near
        if self.center_y >= upper_y:
            self.adjust = adjustment.faraway
        
        return True

class SteroCameraNode(Node):
    def __init__(self,name):
        super().__init__(name)
        qos_profile = QoSProfile(depth=10)
        qos_profile.reliability = ReliabilityPolicy.BEST_EFFORT

        self.is_node_running = False
        self.left = False
        
        self.bridge = CvBridge()

        self.data_lock_left = Lock()
        self.data_lock_right = Lock()

        self.frame_left = None
        self.frame_right = None

        self.update_left = False
        self.update_right = False
        # self.InnerMatrix = np.array([[175.25,0,160],[0,175.25,90],[0,0,1]],dtype=np.float32)
        # self.distCoeffs = np.array([0.0,0.0,0.0,0.0,0.0],dtype=np.float32)
        # self.cameraToRobot = [275.76,0,125.794]
        self.subscriber_left = self.create_subscription(Image,"/mi_desktop_48_b0_2d_5f_be_5c/image_left",self.ImageCallBackLeft,qos_profile)
        self.subscriber_right = self.create_subscription(Image,"/mi_desktop_48_b0_2d_5f_be_5c/image_right",self.ImageCallBackRight,qos_profile)

    def get_new_frame(self,left):
        if left == True:
            while(True):
                if self.update_left == False or self.frame_left.all == None:
                    time.sleep(0.01)
                else:
                    with self.data_lock_left:
                        self.update_left = False
                        return self.frame_left
        else:            
            while(True):
                if self.update_right == False or self.frame_right.all == None:
                    time.sleep(0.01)
                else:
                    with self.data_lock_right:
                        self.update_right = False
                        return self.frame_right
                

    def ImageCallBackLeft(self,receive_msg):
        if(self.is_node_running):
            try:
                cv_image = self.bridge.imgmsg_to_cv2(receive_msg, desired_encoding='bgr8')
                with self.data_lock_left:
                    self.frame_left = cv_image
                    self.update_left = True

            except Exception as e:
                self.get_logger().error(f"Exception in callback: {e}")
                self.is_node_running = False
        else:
            pass

    def ImageCallBackRight(self,receive_msg):
        if(self.is_node_running):
            try:
                cv_image = self.bridge.imgmsg_to_cv2(receive_msg, desired_encoding='bgr8')
                with self.data_lock_right:
                    self.frame_right = cv_image
                    self.update_right = True

            except Exception as e:
                self.get_logger().error(f"Exception in callback: {e}")
                self.is_node_running = False
        else:
            pass

#rgb for s_cur
class RGBCameraNode(Node):
    def __init__(self,name):
        super().__init__(name)
        qos_profile = QoSProfile(depth=10)
        qos_profile.reliability = ReliabilityPolicy.BEST_EFFORT

        self.is_node_running = False
        #self.rgb = False
        
        self.bridge = CvBridge()

        self.data_lock_rgb = Lock()
        #self.data_lock_right = Lock()

        self.frame_rgb = None
        #self.frame_right = None

        self.update_rgb = False
        #self.update_right = False
        # self.InnerMatrix = np.array([[175.25,0,160],[0,175.25,90],[0,0,1]],dtype=np.float32)
        # self.distCoeffs = np.array([0.0,0.0,0.0,0.0,0.0],dtype=np.float32)
        # self.cameraToRobot = [275.76,0,125.794]
        self.subscriber_rgb = self.create_subscription(Image,"/mi_desktop_48_b0_2d_5f_be_5c/image_rgb",self.ImageCallBackrgb,qos_profile)
        #self.subscriber_right = self.create_subscription(Image,"/mi_desktop_48_b0_2d_5f_be_5c/image_right",self.ImageCallBackRight,qos_profile)

    def get_new_frame(self):
        while(True):
            #print("getnewframe")
            if self.update_rgb == False or self.frame_rgb.all == None:
                time.sleep(0.01)
            else:
                with self.data_lock_rgb:
                    self.update_rgb = False
                    return self.frame_rgb

                

    def ImageCallBackrgb(self,receive_msg):
        if(self.is_node_running):
            #print("nodeisrunning")
            try:
                cv_image = self.bridge.imgmsg_to_cv2(receive_msg, desired_encoding='bgr8')
                with self.data_lock_rgb:
                    self.frame_rgb = cv_image
                    self.update_rgb = True

            except Exception as e:
                self.get_logger().error(f"Exception in callback: {e}")
                self.is_node_running = False
        else:
            pass

#è¯­éŸ³èŠ‚ç‚¹
class SpeechProcessor(Node):
    """ä¿ç•™å®Œæ•´è¯­éŸ³å’Œç”µæ± æ£€æµ‹åŠŸèƒ½çš„ROS2èŠ‚ç‚¹"""
    def __init__(self):
        super().__init__('speech_processor')
        
        # åˆå§‹åŒ–è¿åŠ¨æ§åˆ¶å™¨ï¼ˆä¸å®˜æ–¹ä¾‹ç¨‹ç›¸åŒçš„åˆå§‹åŒ–é¡ºåºï¼‰
        
        # ROS2é€šä¿¡æ¥å£ï¼ˆä¿æŒåŸæœ‰åŠŸèƒ½ï¼‰
        self.asr_subscription = self.create_subscription(
            String, '/mi_desktop_48_b0_2d_5f_be_5c/asr_text',
            self.asr_callback, 10)
        # self.bms_subscription = self.create_subscription(
        #     BmsStatus, '/mi_desktop_48_b0_2d_5f_be_5c/bms_status',
        #     self.bms_callback, 10)
        # self.speech_publisher = self.create_publisher(
        #     AudioPlayExtend, '/mi_desktop_48_b0_2d_5f_be_5c/speech_play_extend', 10)
        self.speech_publisher = None
        
        # çŠ¶æ€æ ‡å¿—ï¼ˆä¿æŒåŸæœ‰åŠŸèƒ½ï¼‰
        self.countdown_active = False
        self.current_count = 0
        self.countdown_timer = None
        self.is_charging = False
        self.was_charging = False

    def asr_callback(self, msg):
        global now_state
        """ä¿æŒåŸæœ‰è¯­éŸ³å¤„ç†é€»è¾‘"""
        text = msg.data.strip()
        print(text)
        print(now_state)
        
        
        if text == "å¯åŠ¨":
            now_state = 1
            self.play_speech("å¯åŠ¨æˆåŠŸ")
            
        elif text == "é»„ç¯":
            self.start_countdown()
            
        else:
            self.play_speech(text)
        

    def bms_callback(self, msg):
        """ä¿æŒåŸæœ‰ç”µæ± æ£€æµ‹é€»è¾‘"""
        self.was_charging = self.is_charging
        self.is_charging = msg.power_wired_charging
        
        if self.was_charging and not self.is_charging:
            self.handle_disconnection()
            
        elif not self.was_charging and self.is_charging:
            self.play_speech("å……ç”µä¸­")

    # ä»¥ä¸‹ä¸ºæ–°å¢çš„åŠŸèƒ½æ–¹æ³•ï¼ˆä¿æŒåŸæœ‰ä¸šåŠ¡é€»è¾‘ï¼‰
    def start_countdown(self):
        """é»„ç¯å€’è®¡æ—¶å¤„ç†"""
        if self.countdown_timer:
            self.countdown_timer.cancel()
        self.countdown_active = True
        self.current_count = 5
        self.countdown_timer = self.create_timer(1.0, self.countdown_callback)

    def handle_disconnection(self):
        """å……ç”µçº¿æ‹”å‡ºå¤„ç†æµç¨‹"""
        self.play_speech("å……ç”µçº¿æ‹”å‡º")
        
        # ä¸¥æ ¼éµå¾ªå®˜æ–¹ä¾‹ç¨‹çš„åŠ¨ä½œé¡ºåº
        msg = robot_control_cmd_lcmt()
        msg.mode = 12  # Recovery stand
        msg.gait_id = 0
        msg.life_count += 1
        self.motion_controller.Send_cmd(msg)
        self.motion_controller.Wait_finish(12, 0)
        
        msg.mode = 11  # Locomotion
        msg.gait_id = 27  # TROT_SLOW
        msg.vel_des = [0.2, 0, 0]
        msg.duration = 4000
        msg.life_count += 1
        self.motion_controller.Send_cmd(msg)
        self.motion_controller.Wait_finish(11, 27)
        
        msg.mode = 7  # PureDamper
        msg.life_count += 1
        self.motion_controller.Send_cmd(msg)
        self.motion_controller.Wait_finish(7, 0)

    def play_speech(self, text):
        """ç»Ÿä¸€è¯­éŸ³æ’­æŠ¥æ¥å£"""
        # msg = AudioPlayExtend()
        # msg.module_name = "voice_interaction"
        # msg.is_online = True
        # msg.text = text
        # self.speech_publisher.publish(msg)
        self.get_logger().info(f'è¯­éŸ³æ’­æŠ¥(å·²ç¦ç”¨åè®®å‘å¸ƒ): {text}')

    def countdown_callback(self):
        """å€’è®¡æ—¶å¤„ç†"""
        if self.current_count > 0:
            self.play_speech(str(self.current_count))
            self.current_count -= 1
        else:
            self.countdown_timer.cancel()
            self.countdown_active = False

    def destroy_node(self):
        """èµ„æºæ¸…ç†ï¼ˆä¸å®˜æ–¹ä¾‹ç¨‹ä¸€è‡´ï¼‰"""
        self.motion_controller.stop()
        super().destroy_node()


#è§†è§‰èŠ‚ç‚¹
class VisionNode(Node):
    def __init__(self):
        super().__init__('vision_node')
        self.bridge = CvBridge()
        qos_profile = QoSProfile(depth=10)
        self.frame = None
        self.frame_nose = None
        self.update = False
        self.update_nose = False
        self.vis_running = True
        #ç›¸æœºå†…å‚
        self.InnerMatrix = np.array([
            [
                416.6850297391639,
                0.0,
                319.98128281389444
            ],
            [
                0.0,
                415.51316371220037,
                227.93040503278888
            ],
            [
                0.0,
                0.0,
                1.0
            ]
        ],dtype=np.float32)
        self.distCoeffs = np.array([0.0024461913801336077,
            -0.04339171678852136,
            -0.006551805033021212,
            -0.0003024566454255968,
            0.0],dtype=np.float32)
        #ç›¸æœºå¤–å‚
        self.cameraToRobot = [275.76,0,125.794]#å•ä½æ¯«ç±³
        qos_profile.reliability = ReliabilityPolicy.BEST_EFFORT
        # åªåˆå§‹åŒ–rgbè®¢é˜…
        self.subscription = self.create_subscription(
            Image,
            '/mi_desktop_48_b0_2d_5f_be_5c/image_rgb',
            self.rgb_callback,
            qos_profile)
        self.sub_nose = None
        self.current_mode = 'rgb'  # å½“å‰è®¢é˜…æ¨¡å¼
        # self.ArrowDetector = ArrowDetector()
        # self.QRCodeDetector = QRCodeDetector(self.InnerMatrix,self.distCoeffs)
        # self.YellowLightDetector = YellowLightDetector(self.InnerMatrix,self.distCoeffs)
        # self.LimitHeightDetector = LimitHeightDetector(self.InnerMatrix,self.distCoeffs)
        self.lower_yellow = np.array([20, 100, 100])    # åŸ [20,100,100]
        self.upper_yellow = np.array([30, 255, 255])  # åŸ [30,255,255]
        self.detection_threshold = 0.15  # 25%é»„è‰²åƒç´ å æ¯”
        self._yaw_adjust = 0.0
        self._lateral_error = 0.0
        self._max_side_length = 0
        self._line_angle = 0.0  # æ£€æµ‹åˆ°çš„çº¿æ¡è§’åº¦ï¼ˆå¼§åº¦ï¼‰
        self._line_threshold = 0.05 # è§’åº¦è¯¯å·®é˜ˆå€¼ï¼ˆå¼§åº¦ï¼‰
        self._line_1 = 0.015
        self._alignment_start_time = 0.0  # å¯¹é½å¼€å§‹æ—¶é—´æˆ³
        self._aligned_duration = 0.0      # å·²å¯¹é½æŒç»­æ—¶é—´
        self._state9_threshold = 0.15
        self._state10_threshold = 0.15
        self._limit_height_distance = None
        self._yellow_light_distance = None
        self._detected = False
        # æ–œå¡æ£€æµ‹å‚æ•°ï¼ˆæ·±ç°è‰²é˜ˆå€¼ï¼‰
        self.lower_slope = np.array([0, 0, 30], dtype=np.uint8)   # HSVä¸‹é™ï¼ˆæ·±ç°ï¼‰
        self.upper_slope = np.array([180, 50, 90], dtype=np.uint8) # HSVä¸Šé™
        self.min_slope_area = 500  # æœ€å°è½®å»“é¢ç§¯é˜ˆå€¼
        self.slope_top_y = None    # æ–œå¡é¡¶éƒ¨çš„yåæ ‡
        self.prev_angle = 0
        self.integral = 0
        self.last_error = 0
        self.angle_0 = 0
        self._lock = Lock()
        self.real_debug_mode = False
        self._last_detection_time = 0
        self._detected_flags = {
            '0': False,
            '3': False,
            '4': False,
            '4_5': False,
            '5': False,
            '6': False,
            '8': False,
            '9': False,
            '10': False,
            '12': False,
            '13': False,
            '14': False,
            '15': False,
            '16': False,
            '17': False,
            '17.5': False,
            '18': False,
            '18_5': False,
            '19': False,
            '19_5': False,
            '19_55': False,
            '19_6': False,
            '20': False,
            '21': False,
            '22': False,
            '23': False,
            '24': False,
            '25': False,
            '26': False,
            '27': False,
            '28': False,
            '29': False,
            '30': False,
            '32': False,
            '33': False,
            '34': False,
            '34_5': False,
            '35': False,
            '35_5': False,
            '36': False,
            '36_5': False,
            '37': False,
            '38': False,
            '39': False,
            '39_55': False,
            '40': True,
            '41': False,
            '42': False,
            '43': False,
            '44': False,
            '45': False,
            '46': False,
            '47': False,
            '48': False,
            '49': False,
            '50': False,
            '51': False,
            '52': False,
        }
        # è°ƒè¯•çª—å£ï¼ˆå®é™…éƒ¨ç½²æ—¶å¯å…³é—­ï¼‰
        self.debug_mode = False
        # å®šæ—¶æ£€æŸ¥å¹¶åˆ‡æ¢è®¢é˜…
        self.check_camera_timer = self.create_timer(0.2, self.check_camera_subscription)
        # é˜Ÿåˆ—ä¸çº¿ç¨‹
        self.image_queue = queue.Queue(maxsize=5)
        from threading import Thread
        self.worker_thread = Thread(target=self.image_worker, daemon=True)
        self.worker_thread.start()

    def check_camera_subscription(self):
        global state_id
        qos_profile = QoSProfile(depth=10)
        qos_profile.reliability = ReliabilityPolicy.BEST_EFFORT
        # åªåœ¨3,4,4.5æ—¶ç”¨nose
        if state_id in [99, 100]:
            if self.current_mode != 'nose':
                # åˆ‡æ¢åˆ°nose
                if self.subscription is not None:
                    self.destroy_subscription(self.subscription)
                    self.subscription = None
                if self.sub_nose is None:
                    self.sub_nose = self.create_subscription(
                        Image,
                        '/mi_desktop_48_b0_2d_5f_be_5c/image',
                        self.nose_callback,
                        qos_profile)
                self.current_mode = 'nose'
        else:
            if self.current_mode != 'rgb':
                # åˆ‡æ¢åˆ°rgb
                if self.sub_nose is not None:
                    self.destroy_subscription(self.sub_nose)
                    self.sub_nose = None
                if self.subscription is None:
                    self.subscription = self.create_subscription(
                        Image,
                        '/mi_desktop_48_b0_2d_5f_be_5c/image_rgb',
                        self.rgb_callback,
                        qos_profile)
                self.current_mode = 'rgb'

    def rgb_callback(self, msg):
        # print("[LOG] rgb_callback æ”¶åˆ°æ–°å›¾åƒ")
        try:
            cv_image = self.bridge.imgmsg_to_cv2(msg, "bgr8")
            self.frame = cv_image
            self.update = True 
            # cv_image = cv2.undistort(cv_image, self.InnerMatrix, self.distCoeffs)
            if not self.image_queue.full():
                # print(f"[LOG] rgb_callback æ”¾å…¥é˜Ÿåˆ—, é˜Ÿåˆ—é•¿åº¦: {self.image_queue.qsize()}")
                self.image_queue.put(("rgb", cv_image))
            else:
                # print("[WARN] image_queue å·²æ»¡ï¼Œä¸¢å¼ƒå›¾åƒ")
                pass
        except Exception as e:
            # print(f"[ERROR] RGBå›¾åƒå¤„ç†å¤±è´¥: {str(e)}")
            self.get_logger().error(f"RGBå›¾åƒå¤„ç†å¤±è´¥: {str(e)}")

    def nose_callback(self, msg):
        """å¤„ç† /image å›¾åƒ"""
        try:
            cv_image = self.bridge.imgmsg_to_cv2(msg, "bgr8")
            # cv_image = cv2.undistort(cv_image, self.InnerMatrix, self.distCoeffs)
            # self.frame_nose = cv_image.copy()
            # self.update_nose = True
            # self.process_image()
            if not self.image_queue.full():
                self.image_queue.put(("nose", cv_image))
        except Exception as e:
            self.get_logger().error(f"Noseå›¾åƒå¤„ç†å¤±è´¥: {str(e)}")

    def image_worker(self):
        # print("[LOG] image_worker çº¿ç¨‹å¯åŠ¨")
        while True:
            try:
                # print(f"[LOG] image_worker ç­‰å¾…é˜Ÿåˆ—ï¼Œå½“å‰é•¿åº¦: {self.image_queue.qsize()}")
                img_type, cv_image = self.image_queue.get()
                if img_type == "nose":
                    cv_image = cv2.undistort(cv_image, self.InnerMatrix, self.distCoeffs)
                # print(f"[LOG] image_worker å–å‡ºå›¾åƒ, ç±»å‹: {img_type}")
                self.process_image(img_type, cv_image)
            except Exception as e:
                # print(f"[ERROR] å›¾åƒå¤„ç†çº¿ç¨‹å¼‚å¸¸: {str(e)}")
                self.get_logger().error(f"å›¾åƒå¤„ç†çº¿ç¨‹å¼‚å¸¸: {str(e)}")

    def get_new_frame(self):
        while(True):
            if self.update == False:
                time.sleep(0.01)
                #print("getframebutfalse")
            else:
                self.update == False
                return self.frame

    def process_image(self, img_type, cv_image):
        global state_id, QR1, QR2
        try:
            # print(f"[LOG] process_image è¢«è°ƒç”¨, img_type: {img_type}, state_id: {state_id}")
            # åªåœ¨state_idå’Œimg_typeåŒ¹é…æ—¶å¤„ç†
            if state_id in [99]:
                if img_type != "nose":
                    # print("[LOG] process_image: state_idåœ¨[3,4,4.5]ä½†img_typeä¸æ˜¯noseï¼Œè¿”å›")
                    return
            else:
                if img_type != "rgb":
                    # print("[LOG] process_image: state_idä¸åœ¨[3,4,4.5]ä½†img_typeä¸æ˜¯rgbï¼Œè¿”å›")
                    return
            current_state = state_id  # è·å–å½“å‰çŠ¶æ€
            # print(f"[LOG] process_image: current_state={current_state}")
            if current_state == 0:
                # print("[LOG] process_image: è°ƒç”¨ _detect_0")
                self._detect_0(cv_image)
            elif current_state == 1 or current_state == 2 or current_state == 7 or current_state == 31 or current_state == 44 or current_state == 48 or current_state == 53 or current_state == 15: 
                pass
            elif current_state == 2.5:
                self._detect_2_5(cv_image)
            elif current_state == 3:
                self._detect_3(cv_image)
            elif current_state == 4:
                self._detect_4(cv_image)
            # elif current_state == 4.5:
            #     self._detect_4_5(cv_image)
            elif current_state == 5:
                self._detect_5(cv_image)
            elif current_state == 6:
                self._detect_6(cv_image)
            elif current_state == 8:
                self._detect_8(cv_image)
            elif current_state == 9:
                self._detect_9(cv_image)
            elif current_state == 10:
                self._detect_10(cv_image)
            # elif current_state == 11:
                # self._detect_11(cv_image)
            elif current_state == 12:
                self._detect_12(cv_image)
            elif current_state == 13:
                self._detect_13(cv_image)
            elif current_state == 14:
                self._detect_14(cv_image)
            # elif current_state == 15:
            #     self._detect_15(cv_image)
            elif current_state == 16:
                self._detect_16(cv_image)
            elif current_state == 17:
                self._detect_17(cv_image)
            elif current_state == 17.5:
                pass
            elif current_state == 18:
                self._detect_18(cv_image)
            elif current_state == 18.5:
                self._detect_18_5(cv_image)
            # elif current_state == 19:
            #     self._detect_19(cv_image)
            elif current_state == 19.5:
                self._detect_19_5(cv_image)
            elif current_state == 19.55:
                self._detect_19_55(cv_image)
            elif current_state == 19.6:
                self._detect_19_6(cv_image)
            elif current_state == 20:
                self._detect_20(cv_image)
            elif current_state == 21:
                self._detect_21(cv_image)
            elif current_state == 22:
                self._detect_22(cv_image)
            elif current_state == 23:
                self._detect_23(cv_image)
            elif current_state == 24:
                self._detect_24(cv_image)
            elif current_state == 26:
                self._detect_26(cv_image)
            elif current_state == 27:
                self._detect_27(cv_image)
            elif current_state == 28:
                self._detect_28(cv_image)
            elif current_state == 29:
                self._detect_29(cv_image)
            elif current_state == 30:
                self._detect_30(cv_image)
            elif current_state == 32:
                self._detect_32(cv_image)
            elif current_state == 33:
                self._detect_33(cv_image)
            elif current_state == 34:
                self._detect_34(cv_image)
            elif current_state == 34.5:
                self._detect_34_5(cv_image)
            elif current_state == 35:
                self._detect_35(cv_image)
            elif current_state == 35.5:
                self._detect_35_5(cv_image)
            # elif current_state == 36:
            #     self._detect_36(cv_image)
            elif current_state == 36.5:
                self._detect_36_5(cv_image)
            elif current_state == 37:
                self._detect_37(cv_image)
            elif current_state == 38:
                self._detect_38(cv_image)
            elif current_state == 39:
                self._detect_39(cv_image)
            elif current_state == 39.55:
                self._detect_39_55(cv_image)
            elif current_state == 40:
                self._detect_40(cv_image)
            elif current_state == 41:
                self._detect_41(cv_image)
            elif current_state == 42:
                self._detect_42(cv_image)
            elif current_state == 43:
                self._detect_43(cv_image)
            elif current_state == 45:
                self._detect_45(cv_image)
            elif current_state == 46:
                self._detect_46(cv_image)
            elif current_state == 47:
                self._detect_47(cv_image)
            elif current_state == 49:
                self._detect_49(cv_image)
            elif current_state == 50:
                self._detect_50(cv_image)
            elif current_state == 51:
                self._detect_51(cv_image)
            elif current_state == 52:
                self._detect_52(cv_image)
            else:
                pass
        except Exception as e:
            self.get_logger().error(f"å›¾åƒå¤„ç†å¤±è´¥: {str(e)}")
            
    def _show(self, cv_image):
        if self.debug_mode:
        # cv2.destroyAllWindows()
            cv2.imshow("Detection Preview", cv_image)
            cv2.waitKey(1)

    def _detect_0(self, cv_image):
        # === 1. é¢„å¤„ç†å¹¶è½¬æ¢ä¸º HSV ===
        blurred = cv2.GaussianBlur(cv_image, (5, 5), 0)
        hsv = cv2.cvtColor(blurred, cv2.COLOR_BGR2HSV)
        height, width = hsv.shape[:2]

        # === 2. æå–å³ä¸‹è§’ ROI åŒºåŸŸ ===
        roi_height1 = height // 2 - 60
        roi_height2 = roi_height1 - 10
        x_start = 7 * width // 8
        x_end = x_start + width // 8
        y_start = height - roi_height1
        y_end = height - roi_height2
        roi_hsv = hsv[height-roi_height1:height - roi_height2, x_start:x_end]
        
        # === 3. ä½¿ç”¨æ¨¡å—å‡½æ•°ç”Ÿæˆâ€œé»„+æ³›ç™½é»„â€æ©ç  ===
        '''mask_combined = get_combined_color_mask(roi_hsv, YELLOW_COMBINED_KEYS)

        # === 4. å½¢æ€å­¦å»å™ª ===
        mask_combined = cv2.morphologyEx(mask_combined, cv2.MORPH_OPEN, MORPH_KERNEL)
        mask_combined = cv2.morphologyEx(mask_combined, cv2.MORPH_CLOSE, MORPH_KERNEL)

        
        # === 5. é»„è‰²åƒç´ å æ¯”è®¡ç®— ===
        yellow_ratio = np.count_nonzero(mask_combined) / (mask_combined.size + 1e-5)'''
        mask = cv2.inRange(roi_hsv, self.lower_yellow, self.upper_yellow)
        kernel = np.ones((3,3), np.uint8)
        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
        yellow_ratio = np.count_nonzero(mask) / (mask.size + 1e-5)
        # print(yellow_ratio)
        # === 6. æ£€æµ‹é€»è¾‘ï¼ˆéœ€æŒç»­500msï¼‰===
        with self._lock:
            current_time = time.time()
            if yellow_ratio > YELLOW_RATIO_THRESHOLD:
                if current_time - self._last_detection_time < 0.5:
                    self._detected_flags['0'] = True
                self._last_detection_time = current_time
            else:
                self._detected_flags['0'] = False
        
        # === 7. å¯è§†åŒ–è°ƒè¯• ===
        if self.debug_mode:
            cv2.imshow("Detection Preview", debug_img)
            cv2.imshow("Mask", mask_combined)
            cv2.waitKey(1)

        if self.real_debug_mode:
            debug_img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
            cv2.rectangle(debug_img, (x_start, y_start), (x_end, y_end), (0, 255, 255), 2)
            cv2.putText(debug_img, f"Yellow Ratio: {yellow_ratio:.3f}", (10, 30),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)
            cv2.putText(debug_img, f"Detected: {self._detected_flags['0']}", (10, 60),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255) if not self._detected_flags['0'] else (0, 255, 0), 2)
            
            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S_%f")  # ç²¾ç¡®åˆ°å¾®ç§’
            filename = f"detect0_{timestamp}.jpg"

            save_debug_image(filename, debug_img)
        
    def _detect_3(self, cv_image):
        print("è¿›å…¥æ£€æµ‹3")

    def _detect_4(self, cv_image):
        
        print("è¿›å…¥æ£€æµ‹4")

        #cv2.imwrite("test.jpg", cv_image)

        global QR1
        global QR1_cnt
        if cv_image is None:
            print("QRCodeDetector Error: no frame")
            return

        # ä¿è¯å…¼å®¹ python2 å’Œ python3
        IS_PY3 = sys.version_info.major == 3
        if IS_PY3:
            from urllib.request import urlopen, Request
            from urllib.error import URLError
            from urllib.parse import urlencode
        else:
            from urllib2 import urlopen, Request, URLError
            from urllib import urlencode

        # é˜²æ­¢ https è¯ä¹¦æ ¡éªŒä¸æ­£ç¡®
        ssl._create_default_https_context = ssl._create_unverified_context

        # API Key å’Œ Secret Key
        API_KEY = 'ZyIjArFIzoRtgnT8WAUw5tCv'
        SECRET_KEY = '9JlkvkYt7r0C0GsJGcuRyoMhWaJx12yF'

        # è·å– access_token
        def fetch_token():
            url = "https://aip.baidubce.com/oauth/2.0/token"
            params = {
                "grant_type": "client_credentials",
                "client_id": API_KEY,
                "client_secret": SECRET_KEY
            }
            return str(requests.post(url, params=params).json().get("access_token"))

        def cv2_to_base64(cv_img):
            _, buffer = cv2.imencode(".jpg", cv_img)
            return base64.b64encode(buffer).decode()

        def ocr_text(img_base64, token):
            url = "https://aip.baidubce.com/rest/2.0/ocr/v1/accurate_basic?access_token=" + token
            headers = {'content-type': 'application/x-www-form-urlencoded'}
            data = {"image": img_base64}
            response = requests.post(url, data=data, headers=headers)
            result_json = response.json()
            if "words_result" in result_json:
                return "".join([item["words"] for item in result_json["words_result"]])
            else:
                return None

        def ocr_qrcode(img_base64, token):
            url = "https://aip.baidubce.com/rest/2.0/ocr/v1/qrcode?access_token=" + token
            headers = {'content-type': 'application/x-www-form-urlencoded'}
            data = {"image": img_base64}
            response = requests.post(url, data=data, headers=headers)
            result_json = response.json()
            if "codes_result" in result_json:
                codes = []
                for code in result_json["codes_result"]:
                    text = code.get("text", "")
                    if isinstance(text, list):
                        text = " ".join(text)
                    codes.append(str(text))
                return "\n".join(codes)
            else:
                return None
        
        # è·å– token
        token = fetch_token()

        # qr_result = cv_qrcode(cv_image)

        # å¾…è¯†åˆ«çš„å›¾ç‰‡
        img_base64 = cv2_to_base64(cv_image)

        # å…ˆå°è¯•è¯†åˆ«äºŒç»´ç 
        dir_result = None
        qr_result = ocr_qrcode(img_base64, token) ##APIè¯†åˆ«äºŒç»´ç 
        QR1_cnt = QR1_cnt + 1 
        # end_QR1_time = time.time()
        print("è¯†åˆ«æ€»æ¬¡æ•°:", QR1_cnt)

        if qr_result == "A-1" or qr_result == "A-2" :
            print("ã€äºŒç»´ç è¯†åˆ«ç»“æœã€‘\n", qr_result)
            QR1 = qr_result
            dir_result = qr_result
        
        elif (QR1_cnt % 3 == 1):
            print("ã€æœªæ£€æµ‹åˆ°äºŒç»´ç ï¼Œå°è¯•æ–‡å­—è¯†åˆ«ã€‘")
            text_result = ocr_text(img_base64, token)
            text_state = 0
            normalized_string = ""

            if not text_result:
                print("\næœªè¯†åˆ«åˆ°ä»»ä½•æœ‰æ•ˆæ–‡å­—ã€‚")
            else:
                #sorted_texts = sorted(text_result, key = lambda item: item['box'][0])
                #full_detected_string = "".join([item['text'] for item in sorted_texts])

                #æ›´ä¸¥æ ¼çš„æ¸…æ´—è§„åˆ™
                normalized_string = re.sub(r'[^AB12]', '', text_result.upper())
                print(f"ä¸¥æ ¼æ¸…æ´—å (åªä¿ç•™A,B,1,2): '{normalized_string}'")

                #æ˜ å°„é€»è¾‘
                # æ£€æŸ¥æ˜¯å¦åŒæ—¶åŒ…å« 'A' å’Œ '1'
            if 'A' in normalized_string and '1' in normalized_string:
                text_state = 1
                QR1 = "A-1"
                dir_result = "A-1"
            # æ£€æŸ¥æ˜¯å¦åŒæ—¶åŒ…å« 'A' å’Œ '2'
            elif 'A' in normalized_string and '2' in normalized_string:
                text_state = 2
                QR1 = "A-2"
                dir_result = "A-2"
            # æ£€æŸ¥æ˜¯å¦åŒæ—¶åŒ…å« 'B' å’Œ '1'
            elif 'B' in normalized_string and '1' in normalized_string:
                text_state = 3
                QR1 = "B-1"
                dir_result = "B-1"
            # æ£€æŸ¥æ˜¯å¦åŒæ—¶åŒ…å« 'B' å’Œ '2'
            elif 'B' in normalized_string and '2' in normalized_string:
                text_state = 4
                QR1 = "B-2"
                dir_result = "B-2"

            print("\n--- æœ€ç»ˆçŠ¶æ€ ---")
            if text_state == 0:
                print(f"æœªèƒ½åŒ¹é…åˆ°ç›®æ ‡çŠ¶æ€ (æ¸…æ´—åç»“æœ: '{normalized_string}')ã€‚")
                dir_result = None
            else:
                # ã€ä¿®æ”¹ã€‘æ‰“å°ä¿¡æ¯æ›´æ¸…æ™°
                print(f"æˆåŠŸåŒ¹é…åˆ°æ¨¡å¼ '{dir_result}' (æ¥è‡ª: '{normalized_string}')ï¼Œè®¾ç½®çŠ¶æ€ä¸º: {text_state}")

            print("ã€æ–‡å­—è¯†åˆ«ç»“æœã€‘\n", dir_result)
        with self._lock:
            self._detected_flags['4'] = (dir_result is not None )
            print(f"AåŒºåº“ä½æ–¹å‘æ£€æµ‹æ ‡è¯†ä½æ›´æ–°ä¸º: {self._detected_flags['4']}")

    def _detect_5(self, cv_image):
        print(5)
        # é¢„å¤„ç†
        global QR1
        blurred = cv2.GaussianBlur(cv_image, (5, 5), 0)
        hsv = cv2.cvtColor(blurred, cv2.COLOR_BGR2HSV)

        # ä½¿ç”¨é…ç½®æ¨¡å—æå–é»„è‰²æ©ç 
        mask_combined = get_combined_color_mask(hsv, YELLOW_COMBINED_KEYS)
        mask_combined = cv2.morphologyEx(mask_combined, cv2.MORPH_OPEN, MORPH_KERNEL)
        mask_combined = cv2.morphologyEx(mask_combined, cv2.MORPH_CLOSE, MORPH_KERNEL)
        
        '''mask = cv2.inRange(roi_hsv, self.lower_yellow, self.upper_yellow)
        kernel = np.ones((3,3), np.uint8)
        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)'''
        # åªä¿ç•™æœ€å¤§çš„ä¸¤ä¸ªè¿é€šåŸŸ
        num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(mask_combined, connectivity=8)
        clean_mask = np.zeros_like(mask_combined)
        if num_labels > 1:
            areas = stats[1:, cv2.CC_STAT_AREA]
            sorted_idx = np.argsort(areas)[::-1] + 1
            for i in sorted_idx[:min(2, len(sorted_idx))]:
                clean_mask[labels == i] = 255
        mask_combined = clean_mask

        # åˆ›å»ºROIèšç„¦å›¾åƒåº•éƒ¨ (é«˜åº¦1/2åŒºåŸŸ)
        height, width = mask_combined.shape[:2]
        roi_y_start = height - height // 2
        roi_x_start = width // 2
        roi_mask = np.zeros_like(mask_combined)
        if QR1 == 'A-1':
            roi_mask[roi_y_start:, roi_x_start:3 * width // 4] = 255
        else:
            roi_mask[roi_y_start:, width // 4:roi_x_start] = 255
        masked_roi = cv2.bitwise_and(mask_combined, roi_mask)

        # === ä¸“ä¸šæ–¹æ³•ï¼šæ£€æµ‹é»„è‰²è¾¹çº¿çš„å®é™…è¾¹ç•Œ ===
        # 1. æ‰¾åˆ°é»„è‰²åŒºåŸŸçš„è½®å»“
        contour_result = cv2.findContours(mask_combined, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if len(contour_result) == 3:  # OpenCV 3.x
            contours = contour_result[1]
        elif len(contour_result) == 2:  # OpenCV 4.x
            contours = contour_result[0]
        else:
            contours = contour_result
        # 2. æå–æ‰€æœ‰è¾¹ç•Œç‚¹
        boundary_points = []
        
        # 3. å¯¹æ¯ä¸ªè½®å»“ï¼Œæå–å…¶åº•éƒ¨è¾¹ç•Œç‚¹
        for contour in contours:
            # åˆ›å»ºè½®å»“çš„è¾¹ç•Œæ¡†
            x, y, w, h = cv2.boundingRect(contour)
            
            # åªå¤„ç†ROIåŒºåŸŸå†…çš„è½®å»“
            if y + h < roi_y_start:
                continue
            
            # åˆ›å»ºè½®å»“çš„æ©ç 
            contour_mask = np.zeros_like(mask_combined)
            cv2.drawContours(contour_mask, [contour], -1, 255, thickness=cv2.FILLED)
            
            # å¯¹è½®å»“è¿›è¡Œå¤šè¾¹å½¢è¿‘ä¼¼
            epsilon = 0.005 * cv2.arcLength(contour, True)
            approx = cv2.approxPolyDP(contour, epsilon, True)
            
            # æå–è½®å»“çš„åº•éƒ¨è¾¹ç¼˜ç‚¹
            for point in approx.squeeze():
                px, py = point
                # åªè€ƒè™‘ROIåŒºåŸŸå†…çš„ç‚¹
                if py < roi_y_start:
                    continue
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯åº•éƒ¨ç‚¹ï¼šè¯¥ç‚¹ä¸‹æ–¹ä¸æ˜¯é»„è‰²åŒºåŸŸ
                if py < height - 1:
                    if mask_combined[py + 1, px] == 0:  # ä¸‹æ–¹åƒç´ æ˜¯èƒŒæ™¯
                        boundary_points.append([px, py])
        
        # 4. å¦‚æœæ²¡æœ‰è¶³å¤Ÿè¾¹ç•Œç‚¹ï¼Œå°è¯•å¤‡ç”¨æ–¹æ³•
        if len(boundary_points) < 20:
            # å¤‡ç”¨æ–¹æ³•ï¼šé€åˆ—æ‰«æåº•éƒ¨è¾¹ç¼˜
            boundary_points = []
            for x in range(width // 4, 3 * width // 4):
                for y in range(height - 2, roi_y_start - 1, -1):
                    if mask_combined[y, x] == 255 and mask_combined[y + 1, x] == 0:
                        boundary_points.append([x, y])
                        break  # æ‰¾åˆ°è¯¥åˆ—çš„ç¬¬ä¸€ä¸ªè¾¹ç•Œç‚¹å³åœæ­¢
        
        # 5. ä½¿ç”¨RANSACç®—æ³•è¿›è¡Œç¨³å¥ç›´çº¿æ‹Ÿåˆ
        best_line = None
        best_inliers = []
        max_inliers = 0
        
        if len(boundary_points) >= 10:
            points_array = np.array(boundary_points)
            
            # ä½¿ç”¨RANSACå¤šæ¬¡è¿­ä»£å¯»æ‰¾æœ€ä½³æ‹Ÿåˆçº¿
            for _ in range(2):
                # éšæœºé€‰æ‹©ä¸¤ä¸ªç‚¹
                idx = np.random.choice(len(points_array), 2, replace=False)
                p1, p2 = points_array[idx[0]], points_array[idx[1]]
                
                # è®¡ç®—ç›´çº¿å‚æ•°
                dx = p2[0] - p1[0]
                dy = p2[1] - p1[1]
                if dx == 0:  # é¿å…é™¤ä»¥é›¶
                    continue
                    
                # ç›´çº¿æ–¹ç¨‹: y = mx + c
                m = dy / dx
                c = p1[1] - m * p1[0]
                
                # è®¡ç®—æ‰€æœ‰ç‚¹åˆ°ç›´çº¿çš„è·ç¦»
                distances = []
                for point in points_array:
                    px, py = point
                    # ç‚¹åˆ°ç›´çº¿çš„è·ç¦»å…¬å¼
                    dist = abs(m * px - py + c) / np.sqrt(m**2 + 1)
                    distances.append(dist)
                
                # ç»Ÿè®¡å†…ç‚¹ï¼ˆè·ç¦»å°äºé˜ˆå€¼çš„ç‚¹ï¼‰
                inlier_threshold = 2.0  # åƒç´ è·ç¦»é˜ˆå€¼
                inliers = [i for i, dist in enumerate(distances) if dist < inlier_threshold]
                
                if len(inliers) > max_inliers:
                    max_inliers = len(inliers)
                    best_inliers = inliers
                    best_line = (m, c, p1, p2)
        
        current_time = time.time()
        with self._lock:
            self._detected_flags['5'] = False
            self._line_angle = 0.0
            
            if best_line is not None and len(best_inliers) >= 10:
                m, c, p1, p2 = best_line
                
                # ä½¿ç”¨å†…ç‚¹é‡æ–°æ‹Ÿåˆç›´çº¿ï¼ˆæ›´ç²¾ç¡®ï¼‰
                inlier_points = points_array[best_inliers]
                vx, vy, cx, cy = cv2.fitLine(inlier_points, cv2.DIST_L2, 0, 0.01, 0.01)
                
                # è®¡ç®—ç›´çº¿è§’åº¦ï¼ˆç›¸å¯¹äºæ°´å¹³è½´ï¼‰
                line_angle = np.arctan2(vy, vx)[0]
                angle_deg = np.degrees(line_angle)
                target_angle = 0
                angle_diff = angle_deg - target_angle
                
                self._line_angle = np.radians(angle_diff)
                self._detected_flags['5'] = True
                
                # æŒç»­å¯¹é½è®¡æ—¶é€»è¾‘
                if abs(self._line_angle) < self._line_threshold:
                    if self._alignment_start_time == 0:
                        self._alignment_start_time = current_time
                    self._aligned_duration = current_time - self._alignment_start_time
                else:
                    self._alignment_start_time = 0.0
                    self._aligned_duration = 0.0
            else:
                self._alignment_start_time = 0.0
                self._aligned_duration = 0.0
                self._detected_flags['5'] = False

            # è°ƒè¯•å›¾åƒå¤„ç†
            debug_img = cv2.cvtColor(mask_combined, cv2.COLOR_GRAY2BGR)
            cv2.rectangle(debug_img, (0, roi_y_start), (width, height), (255, 0, 0), 2)  # ç»˜åˆ¶ROIåŒºåŸŸ
            
            # ç»˜åˆ¶æ‰€æœ‰è¾¹ç•Œç‚¹
            for point in boundary_points:
                cv2.circle(debug_img, tuple(point), 2, (0, 255, 0), -1)  # ç»¿è‰²ç‚¹è¡¨ç¤ºè¾¹ç•Œç‚¹
            
            # å¦‚æœæ£€æµ‹åˆ°ç›´çº¿ï¼Œç»˜åˆ¶æœ€ä½³æ‹Ÿåˆçº¿å’Œå†…ç‚¹
            if self._detected_flags['5']:
                # ç»˜åˆ¶å†…ç‚¹ï¼ˆè“è‰²ï¼‰
                for idx in best_inliers:
                    point = boundary_points[idx]
                    cv2.circle(debug_img, tuple(point), 3, (255, 0, 0), -1)  # è“è‰²ç‚¹è¡¨ç¤ºå†…ç‚¹
                
                # ç»˜åˆ¶æ‹Ÿåˆç›´çº¿ï¼ˆçº¢è‰²ç²—çº¿ï¼‰
                length = 500
                pt1 = (int(cx - vx * length), int(cy - vy * length))
                pt2 = (int(cx + vx * length), int(cy + vy * length))
                cv2.line(debug_img, pt1, pt2, (0, 0, 255), 3)
                
                # æ˜¾ç¤ºè§’åº¦ä¿¡æ¯
                cv2.putText(debug_img, 
                            f"Points: {len(boundary_points)} | Inliers: {len(best_inliers)} | Angle: {angle_diff:+.1f}\u00B0 | Hold: {self._aligned_duration:.1f}s", 
                            (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            
            # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°åˆé€‚çš„ç›´çº¿
            elif len(boundary_points) >= 10:
                cv2.putText(debug_img, 
                            f"WARNING: No suitable line found ({len(boundary_points)} boundary points)", 
                            (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
            else:
                cv2.putText(debug_img, 
                            f"WARNING: Not enough boundary points ({len(boundary_points)})", 
                            (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
            
            # ç»˜åˆ¶æ‰€æœ‰è½®å»“
            cv2.drawContours(debug_img, contours, -1, (255, 255, 0), 2)  # é’è‰²è½®å»“
            
            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            save_debug_image(f"detect5_{timestamp}.jpg", debug_img)
            
            # å®æ—¶è°ƒè¯•æ˜¾ç¤º
            if self.debug_mode:
                cv2.imshow("Detection Preview", debug_img)
                cv2.waitKey(1) 


    def _detect_6(self, cv_image):
        #print('d6')
        hsv = cv2.cvtColor(cv_image, cv2.COLOR_BGR2HSV)
        height, width = hsv.shape[:2]
        roi_height1 = 30
        roi_height2 = roi_height1 - 20
        x_start = width // 4
        x_end = 3 * width // 4
        roi = hsv[height-roi_height1:height - roi_height2, x_start:x_end]
        
        mask = cv2.inRange(roi, self.lower_yellow, self.upper_yellow)
        kernel = np.ones((3,3), np.uint8)
        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
        
        yellow_ratio = np.count_nonzero(mask) / (roi.size + 1e-5)  # é˜²æ­¢é™¤é›¶
        print(str(yellow_ratio))
        #debuginfo
        with self._lock:
            current_time = time.time()
            print(str(yellow_ratio))
            if yellow_ratio > 0.09:
                self._detected_flags['6'] = True
                '''if current_time - self._last_detection_time < 0.5:
                    self._detected_flags['6'] = True
                else:
                    self._detected_flags['6'] = False  # é‡ç½®çŸ­æš‚æ£€æµ‹'''
                self._last_detection_time = current_time
            else:
                self._detected_flags['6'] = False

        debug_img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
        cv2.rectangle(debug_img,
                    (x_start, height-roi_height1),           # å·¦ä¸Šè§’
                    (x_end, height - roi_height2),             # å³ä¸‹è§’
                    (0, 255, 0), 2)          # ç»¿è‰²æ¡†ï¼Œçº¿å®½ 2
        cv2.putText(debug_img, f"Yellow Ratio: {yellow_ratio:.3f}", (10, 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)
        cv2.putText(debug_img, f"Detected: {self._detected_flags['14']}", (10, 60),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255) if not self._detected_flags['14'] else (0, 255, 0), 2)
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        save_debug_image(f"detect6_{timestamp}_{yellow_ratio}.jpg", debug_img)

        # è°ƒè¯•æ˜¾ç¤º
        if self.debug_mode:
            debug_img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
            cv2.rectangle(debug_img, 
                        (x_start, height-roi_height1),
                        (x_end, height - roi_height2),
                        (0,255,0), 2)
            cv2.imshow("Detection Preview", debug_img)
            cv2.waitKey(1)

    def _detect_8(self, cv_image):
        # é¢„å¤„ç†
        blurred = cv2.GaussianBlur(cv_image, (5, 5), 0)
        hsv = cv2.cvtColor(blurred, cv2.COLOR_BGR2HSV)

        # ä½¿ç”¨é…ç½®æ¨¡å—æå–é»„è‰²æ©ç 
        mask_combined = get_combined_color_mask(hsv, YELLOW_COMBINED_KEYS)
        mask_combined = cv2.morphologyEx(mask_combined, cv2.MORPH_OPEN, MORPH_KERNEL)
        mask_combined = cv2.morphologyEx(mask_combined, cv2.MORPH_CLOSE, MORPH_KERNEL)
        
        # åªä¿ç•™æœ€å¤§çš„ä¸¤ä¸ªè¿é€šåŸŸ
        num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(mask_combined, connectivity=8)
        clean_mask = np.zeros_like(mask_combined)
        if num_labels > 1:
            areas = stats[1:, cv2.CC_STAT_AREA]
            sorted_idx = np.argsort(areas)[::-1] + 1
            for i in sorted_idx[:min(2, len(sorted_idx))]:
                clean_mask[labels == i] = 255
        mask_combined = clean_mask

        # åˆ›å»ºROIèšç„¦å›¾åƒåº•éƒ¨ (é«˜åº¦1/2åŒºåŸŸ)
        height, width = mask_combined.shape[:2]
        roi_y_start = height - height // 2
        roi_x_start =2 * width // 5
        roi_x_end = 3 * width // 5
        roi_mask = np.zeros_like(mask_combined)
        roi_mask[roi_y_start:, roi_x_start:roi_x_end] = 255
        masked_roi = cv2.bitwise_and(mask_combined, roi_mask)

        # === ä¸“ä¸šæ–¹æ³•ï¼šæ£€æµ‹é»„è‰²è¾¹çº¿çš„å®é™…è¾¹ç•Œ ===
        # 1. æ‰¾åˆ°é»„è‰²åŒºåŸŸçš„è½®å»“
        contour_result = cv2.findContours(mask_combined, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if len(contour_result) == 3:  # OpenCV 3.x
            contours = contour_result[1]
        elif len(contour_result) == 2:  # OpenCV 4.x
            contours = contour_result[0]
        else:
            contours = contour_result
        # 2. æå–æ‰€æœ‰è¾¹ç•Œç‚¹
        boundary_points = []
        
        # 3. å¯¹æ¯ä¸ªè½®å»“ï¼Œæå–å…¶åº•éƒ¨è¾¹ç•Œç‚¹
        for contour in contours:
            # åˆ›å»ºè½®å»“çš„è¾¹ç•Œæ¡†
            x, y, w, h = cv2.boundingRect(contour)
            
            # åªå¤„ç†ROIåŒºåŸŸå†…çš„è½®å»“
            if y + h < roi_y_start:
                continue
            
            # åˆ›å»ºè½®å»“çš„æ©ç 
            contour_mask = np.zeros_like(mask_combined)
            cv2.drawContours(contour_mask, [contour], -1, 255, thickness=cv2.FILLED)
            
            # å¯¹è½®å»“è¿›è¡Œå¤šè¾¹å½¢è¿‘ä¼¼
            epsilon = 0.005 * cv2.arcLength(contour, True)
            approx = cv2.approxPolyDP(contour, epsilon, True)
            
            # æå–è½®å»“çš„åº•éƒ¨è¾¹ç¼˜ç‚¹
            for point in approx.squeeze():
                px, py = point
                # åªè€ƒè™‘ROIåŒºåŸŸå†…çš„ç‚¹
                if py < roi_y_start:
                    continue
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯åº•éƒ¨ç‚¹ï¼šè¯¥ç‚¹ä¸‹æ–¹ä¸æ˜¯é»„è‰²åŒºåŸŸ
                if py < height - 1:
                    if mask_combined[py + 1, px] == 0:  # ä¸‹æ–¹åƒç´ æ˜¯èƒŒæ™¯
                        boundary_points.append([px, py])
        
        # 4. å¦‚æœæ²¡æœ‰è¶³å¤Ÿè¾¹ç•Œç‚¹ï¼Œå°è¯•å¤‡ç”¨æ–¹æ³•
        if len(boundary_points) < 20:
            # å¤‡ç”¨æ–¹æ³•ï¼šé€åˆ—æ‰«æåº•éƒ¨è¾¹ç¼˜
            boundary_points = []
            for x in range(2 * width // 5, 3 * width // 5):
                for y in range(height - 2, roi_y_start - 1, -1):
                    if mask_combined[y, x] == 255 and mask_combined[y + 1, x] == 0:
                        boundary_points.append([x, y])
                        break  # æ‰¾åˆ°è¯¥åˆ—çš„ç¬¬ä¸€ä¸ªè¾¹ç•Œç‚¹å³åœæ­¢
        
        # 5. ä½¿ç”¨RANSACç®—æ³•è¿›è¡Œç¨³å¥ç›´çº¿æ‹Ÿåˆ
        best_line = None
        best_inliers = []
        max_inliers = 0
        
        if len(boundary_points) >= 10:
            points_array = np.array(boundary_points)
            
            # ä½¿ç”¨RANSACå¤šæ¬¡è¿­ä»£å¯»æ‰¾æœ€ä½³æ‹Ÿåˆçº¿
            for _ in range(2):
                # éšæœºé€‰æ‹©ä¸¤ä¸ªç‚¹
                idx = np.random.choice(len(points_array), 2, replace=False)
                p1, p2 = points_array[idx[0]], points_array[idx[1]]
                
                # è®¡ç®—ç›´çº¿å‚æ•°
                dx = p2[0] - p1[0]
                dy = p2[1] - p1[1]
                if dx == 0:  # é¿å…é™¤ä»¥é›¶
                    continue
                    
                # ç›´çº¿æ–¹ç¨‹: y = mx + c
                m = dy / dx
                c = p1[1] - m * p1[0]
                
                # è®¡ç®—æ‰€æœ‰ç‚¹åˆ°ç›´çº¿çš„è·ç¦»
                distances = []
                for point in points_array:
                    px, py = point
                    # ç‚¹åˆ°ç›´çº¿çš„è·ç¦»å…¬å¼
                    dist = abs(m * px - py + c) / np.sqrt(m**2 + 1)
                    distances.append(dist)
                
                # ç»Ÿè®¡å†…ç‚¹ï¼ˆè·ç¦»å°äºé˜ˆå€¼çš„ç‚¹ï¼‰
                inlier_threshold = 2.0  # åƒç´ è·ç¦»é˜ˆå€¼
                inliers = [i for i, dist in enumerate(distances) if dist < inlier_threshold]
                
                if len(inliers) > max_inliers:
                    max_inliers = len(inliers)
                    best_inliers = inliers
                    best_line = (m, c, p1, p2)
        
        current_time = time.time()
        with self._lock:
            self._detected_flags['8'] = False
            self._line_angle = 0.0
            
            if best_line is not None and len(best_inliers) >= 10:
                m, c, p1, p2 = best_line
                
                # ä½¿ç”¨å†…ç‚¹é‡æ–°æ‹Ÿåˆç›´çº¿ï¼ˆæ›´ç²¾ç¡®ï¼‰
                inlier_points = points_array[best_inliers]
                vx, vy, cx, cy = cv2.fitLine(inlier_points, cv2.DIST_L2, 0, 0.01, 0.01)
                
                # è®¡ç®—ç›´çº¿è§’åº¦ï¼ˆç›¸å¯¹äºæ°´å¹³è½´ï¼‰
                line_angle = np.arctan2(vy, vx)[0]
                angle_deg = np.degrees(line_angle)
                target_angle = 0
                angle_diff = angle_deg - target_angle
                
                self._line_angle = np.radians(angle_diff)
                self._detected_flags['8'] = True
                
                # æŒç»­å¯¹é½è®¡æ—¶é€»è¾‘
                if abs(self._line_angle) < self._line_threshold:
                    if self._alignment_start_time == 0:
                        self._alignment_start_time = current_time
                    self._aligned_duration = current_time - self._alignment_start_time
                else:
                    self._alignment_start_time = 0.0
                    self._aligned_duration = 0.0
            else:
                self._alignment_start_time = 0.0
                self._aligned_duration = 0.0
                self._detected_flags['8'] = False

            # è°ƒè¯•å›¾åƒå¤„ç†
            debug_img = cv2.cvtColor(mask_combined, cv2.COLOR_GRAY2BGR)
            cv2.rectangle(debug_img, (0, roi_y_start), (width, height), (255, 0, 0), 2)  # ç»˜åˆ¶ROIåŒºåŸŸ
            
            # ç»˜åˆ¶æ‰€æœ‰è¾¹ç•Œç‚¹
            for point in boundary_points:
                cv2.circle(debug_img, tuple(point), 2, (0, 255, 0), -1)  # ç»¿è‰²ç‚¹è¡¨ç¤ºè¾¹ç•Œç‚¹
            
            # å¦‚æœæ£€æµ‹åˆ°ç›´çº¿ï¼Œç»˜åˆ¶æœ€ä½³æ‹Ÿåˆçº¿å’Œå†…ç‚¹
            if self._detected_flags['8']:
                # ç»˜åˆ¶å†…ç‚¹ï¼ˆè“è‰²ï¼‰
                for idx in best_inliers:
                    point = boundary_points[idx]
                    cv2.circle(debug_img, tuple(point), 3, (255, 0, 0), -1)  # è“è‰²ç‚¹è¡¨ç¤ºå†…ç‚¹
                
                # ç»˜åˆ¶æ‹Ÿåˆç›´çº¿ï¼ˆçº¢è‰²ç²—çº¿ï¼‰
                length = 500
                pt1 = (int(cx - vx * length), int(cy - vy * length))
                pt2 = (int(cx + vx * length), int(cy + vy * length))
                cv2.line(debug_img, pt1, pt2, (0, 0, 255), 3)
                
                # æ˜¾ç¤ºè§’åº¦ä¿¡æ¯
                cv2.putText(debug_img, 
                            f"Points: {len(boundary_points)} | Inliers: {len(best_inliers)} | Angle: {angle_diff:+.1f}\u00B0 | Hold: {self._aligned_duration:.1f}s", 
                            (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            
            # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°åˆé€‚çš„ç›´çº¿
            elif len(boundary_points) >= 10:
                cv2.putText(debug_img, 
                            f"WARNING: No suitable line found ({len(boundary_points)} boundary points)", 
                            (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
            else:
                cv2.putText(debug_img, 
                            f"WARNING: Not enough boundary points ({len(boundary_points)})", 
                            (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
            
            # ç»˜åˆ¶æ‰€æœ‰è½®å»“
            cv2.drawContours(debug_img, contours, -1, (255, 255, 0), 2)  # é’è‰²è½®å»“
            
            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            save_debug_image(f"detect8_{timestamp}.jpg", debug_img)
            
            # å®æ—¶è°ƒè¯•æ˜¾ç¤º
            if self.debug_mode:
                cv2.imshow("Detection Preview", debug_img)
                cv2.waitKey(1)

    def _detect_9(self, cv_image):
        # === 1. é¢„å¤„ç†å¹¶è½¬æ¢ä¸º HSV ===
        blurred = cv2.GaussianBlur(cv_image, (5, 5), 0)
        hsv = cv2.cvtColor(blurred, cv2.COLOR_BGR2HSV)
        height, width = hsv.shape[:2]

       # å®šä¹‰ ROI ä½ç½®ï¼šä½äºåº•éƒ¨å¾€ä¸Š 1/4 é«˜åº¦çš„ä½ç½®
        quarter_height = height // 6
        roi_center_y = height - quarter_height  # è·ç¦»åº•éƒ¨ 1/4 çš„ä½ç½®ï¼ˆå³æ•´ä½“çš„ 3/4 å¤„ï¼‰

        # å®šä¹‰ ROI é«˜åº¦ï¼ˆä¾‹å¦‚ 20 åƒç´ é«˜ï¼‰
        roi_height = height // 32

        # è®¡ç®—ä¸Šä¸‹è¾¹ç•Œ
        y_start = roi_center_y - roi_height // 2
        y_end = roi_center_y + roi_height // 2

        # ç¡®ä¿ä¸è¶Šç•Œ
        y_start = max(y_start, 0)
        y_end = min(y_end, height)

        # æ¨ªå‘ï¼šæ•´å¹…å®½åº¦
        x_start = width // 5 * 2
        x_end = width //5 * 3 # æˆ–ç›´æ¥ç”¨ width

        # æå– ROI
        roi_hsv = hsv[y_start:y_end, x_start:x_end]

        # === 3. ä½¿ç”¨æ¨¡å—å‡½æ•°ç”Ÿæˆâ€œé»„+æ³›ç™½é»„â€æ©ç  ===
        mask_combined = get_combined_color_mask(roi_hsv, YELLOW_COMBINED_KEYS)

        # === 4. å½¢æ€å­¦å»å™ª ===
        mask_combined = cv2.morphologyEx(mask_combined, cv2.MORPH_OPEN, MORPH_KERNEL)
        mask_combined = cv2.morphologyEx(mask_combined, cv2.MORPH_CLOSE, MORPH_KERNEL)

        # === 5. é»„è‰²åƒç´ å æ¯”è®¡ç®— ===
        yellow_ratio = np.count_nonzero(mask_combined) / (mask_combined.size + 1e-5)

        with self._lock:
            if yellow_ratio > 0.5:
                self._detected_flags['9'] = True
            else:
                self._detected_flags['9'] = False

        debug_img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
        cv2.rectangle(debug_img,
                    (x_start, y_start),           # å·¦ä¸Šè§’
                    (x_end, y_end),             # å³ä¸‹è§’
                    (0, 255, 0), 2)          # ç»¿è‰²æ¡†ï¼Œçº¿å®½ 2
        cv2.putText(debug_img, f"Yellow Ratio: {yellow_ratio:.3f}", (10, 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)
        cv2.putText(debug_img, f"Detected: {self._detected_flags['9']}", (10, 60),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255) if not self._detected_flags['9'] else (0, 255, 0), 2)
        
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S_%f")  # ç²¾ç¡®åˆ°å¾®ç§’
        save_debug_image(f"detect9_{timestamp}.jpg", debug_img)
        # è°ƒè¯•æ˜¾ç¤º
        if self.debug_mode:
            cv2.imshow("Detection Preview", debug_img)
            cv2.waitKey(1)

        if self.real_debug_mode:
            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S_%f")  # ç²¾ç¡®åˆ°å¾®ç§’
            filename = f"detect9_{timestamp}.jpg"

            save_debug_image(filename, debug_img)

    def _detect_10(self, cv_image):
        hsv = cv2.cvtColor(cv_image, cv2.COLOR_BGR2HSV)
        height, width = hsv.shape[:2]
        
        roi_height = height // 3
        roi_height1 = roi_height - 20
        x_start = 2 * width // 5
        x_end = 3 * width // 5
        roi = hsv[height-roi_height:height-roi_height1, x_start:x_end]
        
        '''mask = cv2.inRange(roi, self.lower_yellow, self.upper_yellow)
        kernel = np.ones((3,3), np.uint8)
        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
        yellow_ratio = np.count_nonzero(mask) / (roi.size + 1e-5)'''

        mask_combined = get_combined_color_mask(roi, YELLOW_COMBINED_KEYS)

        # === 4. å½¢æ€å­¦å»å™ª ===
        mask_combined = cv2.morphologyEx(mask_combined, cv2.MORPH_OPEN, MORPH_KERNEL)
        mask_combined = cv2.morphologyEx(mask_combined, cv2.MORPH_CLOSE, MORPH_KERNEL)

        # === 5. é»„è‰²åƒç´ å æ¯”è®¡ç®— ===
        yellow_ratio = np.count_nonzero(mask_combined) / (mask_combined.size + 1e-5)

        debug_img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
        cv2.rectangle(debug_img, 
                    (x_start, height-roi_height),
                    (x_end, height),
                    (0,255,0), 2)
        cv2.putText(debug_img, f"Y10: {yellow_ratio:.2f}", (x_start+10, height-10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,0), 2)
        
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S_%f")  # ç²¾ç¡®åˆ°å¾®ç§’
        save_debug_image(f"detect10_{timestamp}_{yellow_ratio}.jpg", debug_img)

        with self._lock:
            current_time = time.time()
            if yellow_ratio < 0.1:
                if current_time - self._last_detection_time < 3:
                    self._detected_flags['10'] = True
                else:
                    self._detected_flags['10'] = False
                self._last_detection_time = current_time
            else:
                self._detected_flags['10'] = False

        # è°ƒè¯•æ˜¾ç¤º
        if self.debug_mode:
            debug_img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
            cv2.rectangle(debug_img, 
                        (x_start, height-roi_height),
                        (x_end, height),
                        (0,255,0), 2)
            cv2.putText(debug_img, f"Y10: {yellow_ratio:.2f}", (x_start+10, height-10),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,0), 2)
            cv2.imshow("Detection Preview", debug_img)
            cv2.waitKey(1)

    def _detect_11(self, cv_image):
        # é¢„å¤„ç†
        blurred = cv2.GaussianBlur(cv_image, (5, 5), 0)
        hsv = cv2.cvtColor(blurred, cv2.COLOR_BGR2HSV)

        # ä½¿ç”¨é…ç½®æ¨¡å—æå–é»„è‰²æ©ç 
        mask_combined = get_combined_color_mask(hsv, YELLOW_COMBINED_KEYS)
        mask_combined = cv2.morphologyEx(mask_combined, cv2.MORPH_OPEN, MORPH_KERNEL)
        mask_combined = cv2.morphologyEx(mask_combined, cv2.MORPH_CLOSE, MORPH_KERNEL)
        
        # ===== æ–°å¢ï¼šåªä¿ç•™æœ€å¤§çš„ä¸¤ä¸ªè¿é€šåŸŸ =====
        # 1. è¿é€šåŸŸåˆ†æ
        num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(mask_combined, connectivity=8)
        
        # 2. åˆ›å»ºæ–°çš„å¹²å‡€æ©ç 
        clean_mask = np.zeros_like(mask_combined)
        if num_labels > 1:  # è‡³å°‘æœ‰ä¸€ä¸ªéèƒŒæ™¯åŒºåŸŸ
            # è·å–é¢ç§¯æ’åºçš„ç´¢å¼•ï¼ˆè·³è¿‡èƒŒæ™¯0ï¼‰
            areas = stats[1:, cv2.CC_STAT_AREA]
            sorted_idx = np.argsort(areas)[::-1] + 1  # é™åºæ’åˆ—
            
            # åªä¿ç•™å‰ä¸¤ä¸ªæœ€å¤§åŒºåŸŸ
            for i in sorted_idx[:min(2, len(sorted_idx))]:
                clean_mask[labels == i] = 255
        # ===== æ–°å¢éƒ¨åˆ†ç»“æŸ =====
        
        # ä½¿ç”¨æ–°çš„clean_maskæ›¿ä»£åŸæ¥çš„mask_combined
        mask_combined = clean_mask

        # åˆ›å»ºROIèšç„¦å›¾åƒåº•éƒ¨ (é«˜åº¦1/4åŒºåŸŸ)
        height, width = mask_combined.shape[:2]
        roi_y_start = height - height // 2
        roi_mask = np.zeros_like(mask_combined)
        roi_mask[roi_y_start:, :] = 255
        masked_roi = cv2.bitwise_and(mask_combined, roi_mask)

        # è¾¹ç¼˜æ£€æµ‹
        edges = cv2.Canny(masked_roi, 50, 150)
        
        # === æ ¸å¿ƒä¿®æ”¹ï¼šåªæå–æœ€ä¸‹æ–¹è¾¹ç¼˜çš„ç‚¹ ===
        # 1. æ‰¾åˆ°å›¾åƒæœ€åº•éƒ¨çš„è¾¹ç¼˜ç‚¹
        bottom_edge_points = []
        # ä»åº•éƒ¨å‘ä¸Šæ‰«æï¼Œå¯»æ‰¾è¾¹ç¼˜ç‚¹
        for y in range(height-1, roi_y_start-1, -1):  # ä»åº•éƒ¨å‘ä¸Šæ‰«æ
            for x in range(width):
                if edges[y, x] != 0:
                    # æ£€æŸ¥è¿™ä¸ªç‚¹æ˜¯å¦æ˜¯è¿ç»­è¾¹ç¼˜çš„ä¸€éƒ¨åˆ†
                    if len(bottom_edge_points) == 0:
                        bottom_edge_points.append([x, y])
                    else:
                        # åªæ·»åŠ ä¸ç°æœ‰ç‚¹ç›¸è¿æˆ–æ¥è¿‘çš„ç‚¹
                        last_x, last_y = bottom_edge_points[-1]
                        if abs(x - last_x) < 50:  # æ°´å¹³è·ç¦»é˜ˆå€¼
                            bottom_edge_points.append([x, y])
            
            # å¦‚æœå·²ç»æ‰¾åˆ°ä¸€æ¡è¿ç»­çš„è¾¹ç¼˜çº¿ï¼Œåœæ­¢æ‰«æ
            if len(bottom_edge_points) > width//4:  # æ‰¾åˆ°è¶³å¤Ÿé•¿çš„è¾¹ç¼˜çº¿
                break
        
        # 2. å¦‚æœæ²¡æœ‰æ‰¾åˆ°åº•éƒ¨è¾¹ç¼˜ï¼Œå°è¯•å¯»æ‰¾ä¸»è¦è¾¹ç¼˜çº¿
        if len(bottom_edge_points) < 10:
            # ä½¿ç”¨è¿é€šç»„ä»¶åˆ†ææ‰¾åˆ°ä¸»è¦è¾¹ç¼˜çº¿
            num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(edges)
            
            # æ‰¾åˆ°æœ€åº•éƒ¨çš„è¿é€šç»„ä»¶
            max_bottom_y = 0
            target_label = -1
            for i in range(1, num_labels):  # è·³è¿‡èƒŒæ™¯æ ‡ç­¾0
                bottom_y = stats[i, cv2.CC_STAT_TOP] + stats[i, cv2.CC_STAT_HEIGHT] - 1
                if bottom_y > max_bottom_y:
                    max_bottom_y = bottom_y
                    target_label = i
            
            # æå–ç›®æ ‡è¿é€šç»„ä»¶çš„ç‚¹
            if target_label != -1:
                y_coords, x_coords = np.where(labels == target_label)
                bottom_edge_points = [[x, y] for x, y in zip(x_coords, y_coords)]
        
        current_time = time.time()
        with self._lock:
            self._detected_flags['11'] = False
            self._line_angle = 0.0
            
            if len(bottom_edge_points) >= 10:  # ç¡®ä¿æœ‰è¶³å¤Ÿçš„ç‚¹è¿›è¡Œæ‹Ÿåˆ
                # ä½¿ç”¨æœ€å°äºŒä¹˜æ³•æ‹Ÿåˆç›´çº¿
                points_array = np.array(bottom_edge_points)
                vx, vy, cx, cy = cv2.fitLine(points_array, cv2.DIST_L2, 0, 0.01, 0.01)
                
                # è®¡ç®—ç›´çº¿è§’åº¦ï¼ˆç›¸å¯¹äºæ°´å¹³è½´ï¼‰
                line_angle = np.arctan2(vy, vx)[0]
                angle_deg = np.degrees(line_angle)
                target_angle = 0
                angle_diff = angle_deg - target_angle
                
                self._line_angle = np.radians(angle_diff)
                print(self._line_angle)
                self._detected_flags['11'] = True
                
                # æŒç»­å¯¹é½è®¡æ—¶é€»è¾‘
                if abs(self._line_angle) < self._line_threshold:
                    if self._alignment_start_time == 0:
                        self._alignment_start_time = current_time
                    self._aligned_duration = current_time - self._alignment_start_time
                else:
                    self._alignment_start_time = 0.0
                    self._aligned_duration = 0.0
            else:
                self._alignment_start_time = 0.0
                self._aligned_duration = 0.0
                self._detected_flags['11'] = False

            # è°ƒè¯•å›¾åƒå¤„ç†
            debug_img = cv2.cvtColor(mask_combined, cv2.COLOR_GRAY2BGR)
            cv2.rectangle(debug_img, (0, roi_y_start), (width, height), (255, 0, 0), 2)  # ç»˜åˆ¶ROIåŒºåŸŸ
            
            if self._detected_flags['11']:
                # 1. ç»˜åˆ¶æ‰€æœ‰åº•éƒ¨è¾¹ç¼˜ç‚¹ï¼ˆç»¿è‰²ç‚¹ï¼‰
                for point in bottom_edge_points:
                    cv2.circle(debug_img, tuple(point), 3, (0, 255, 0), -1)  # ç»¿è‰²ç‚¹è¡¨ç¤ºåº•éƒ¨è¾¹ç¼˜
                
                # 2. ç»˜åˆ¶æ‹Ÿåˆç›´çº¿ï¼ˆçº¢è‰²ç²—çº¿ï¼‰
                length = 500
                pt1 = (int(cx - vx * length), int(cy - vy * length))
                pt2 = (int(cx + vx * length), int(cy + vy * length))
                cv2.line(debug_img, pt1, pt2, (0, 0, 255), 3)
                
                # 3. æ˜¾ç¤ºè§’åº¦ä¿¡æ¯
                cv2.putText(debug_img, 
                            f"Points: {len(bottom_edge_points)} | Angle: {angle_diff:+.1f}\u00B0 | Hold: {self._aligned_duration:.1f}s", 
                            (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            
            # å¦‚æœç‚¹æ•°ä¸è¶³ï¼Œæ˜¾ç¤ºè­¦å‘Šä¿¡æ¯
            elif len(bottom_edge_points) > 0:
                cv2.putText(debug_img, 
                            f"WARNING: Only {len(bottom_edge_points)} points (min 10 needed)", 
                            (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
            else:
                cv2.putText(debug_img, 
                            "WARNING: No bottom edge detected", 
                            (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
            
            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            save_debug_image(f"detect11_{timestamp}.jpg", debug_img)
            
            # å®æ—¶è°ƒè¯•æ˜¾ç¤º
            if self.debug_mode:
                cv2.imshow("Detection Preview", debug_img)
                cv2.waitKey(1)


    def _detect_12(self, cv_image):
        hsv = cv2.cvtColor(cv_image, cv2.COLOR_BGR2HSV)
        height, width = hsv.shape[:2]
        roi_height1 = 130
        roi_height2 = roi_height1 - 10
        x_start = 0 if QR1 == 'A-1' else 15 * width // 16
        x_end = x_start + width//16
        roi = hsv[height-roi_height1:height - roi_height2, x_start:x_end]
        
        '''mask = cv2.inRange(roi, self.lower_yellow, self.upper_yellow)
        kernel = np.ones((3,3), np.uint8)
        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
        
        yellow_ratio = np.count_nonzero(mask) / (roi.size + 1e-5)  # é˜²æ­¢é™¤é›¶'''
        
        mask_combined = get_combined_color_mask(roi, YELLOW_COMBINED_KEYS)

        # === 4. å½¢æ€å­¦å»å™ª ===
        mask_combined = cv2.morphologyEx(mask_combined, cv2.MORPH_OPEN, MORPH_KERNEL)
        mask_combined = cv2.morphologyEx(mask_combined, cv2.MORPH_CLOSE, MORPH_KERNEL)

        # === 5. é»„è‰²åƒç´ å æ¯”è®¡ç®— ===
        yellow_ratio = np.count_nonzero(mask_combined) / (mask_combined.size + 1e-5)

        with self._lock:
            current_time = time.time()
            print("yr" + str(yellow_ratio))
            if yellow_ratio > self.detection_threshold:
                self._detected_flags['12'] = True
                '''if current_time - self._last_detection_time < 0.5:
                    self._detected_flags['12'] = True
                else:
                    self._detected_flags['12'] = False  # é‡ç½®çŸ­æš‚æ£€æµ‹'''
                self._last_detection_time = current_time
            else:
                self._detected_flags['12'] = False
        debug_img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
        cv2.rectangle(debug_img,
                    (x_start, height-roi_height1),           # å·¦ä¸Šè§’
                    (x_end, height - roi_height2),             # å³ä¸‹è§’
                    (0, 255, 0), 2)          # ç»¿è‰²æ¡†ï¼Œçº¿å®½ 2
        cv2.putText(debug_img, f"Yellow Ratio: {yellow_ratio:.3f}", (10, 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)
        cv2.putText(debug_img, f"Detected: {self._detected_flags['12']}", (10, 60),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255) if not self._detected_flags['12'] else (0, 255, 0), 2)
        
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S_%f")  # ç²¾ç¡®åˆ°å¾®ç§’
        save_debug_image(f"detect12_{timestamp}.jpg", debug_img)

        # è°ƒè¯•æ˜¾ç¤º
        if self.debug_mode:
            debug_img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
            cv2.rectangle(debug_img, 
                        (x_start, height-roi_height1),
                        (x_end, height-roi_height2),
                        (0,255,0), 2)
            cv2.imshow("Detection Preview", debug_img)
            cv2.waitKey(1)


    def _detect_13(self, cv_image):
        # é¢„å¤„ç†
        blurred = cv2.GaussianBlur(cv_image, (5, 5), 0)
        hsv = cv2.cvtColor(blurred, cv2.COLOR_BGR2HSV)

        # ä½¿ç”¨é…ç½®æ¨¡å—æå–é»„è‰²æ©ç 
        mask_combined = get_combined_color_mask(hsv, YELLOW_COMBINED_KEYS)
        mask_combined = cv2.morphologyEx(mask_combined, cv2.MORPH_OPEN, MORPH_KERNEL)
        mask_combined = cv2.morphologyEx(mask_combined, cv2.MORPH_CLOSE, MORPH_KERNEL)
        
        # åªä¿ç•™æœ€å¤§çš„ä¸¤ä¸ªè¿é€šåŸŸ
        num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(mask_combined, connectivity=8)
        clean_mask = np.zeros_like(mask_combined)
        if num_labels > 1:
            areas = stats[1:, cv2.CC_STAT_AREA]
            sorted_idx = np.argsort(areas)[::-1] + 1
            for i in sorted_idx[:min(2, len(sorted_idx))]:
                clean_mask[labels == i] = 255
        mask_combined = clean_mask

        # åˆ›å»ºROIèšç„¦å›¾åƒåº•éƒ¨ (é«˜åº¦1/2åŒºåŸŸ)
        height, width = mask_combined.shape[:2]
        roi_y_start = height - height // 2
        roi_mask = np.zeros_like(mask_combined)
        roi_mask[roi_y_start:, width // 5:3 * width // 5] = 255
        masked_roi = cv2.bitwise_and(mask_combined, roi_mask)

        # === ä¸“ä¸šæ–¹æ³•ï¼šæ£€æµ‹é»„è‰²è¾¹çº¿çš„å®é™…è¾¹ç•Œ ===
        # 1. æ‰¾åˆ°é»„è‰²åŒºåŸŸçš„è½®å»“
        contour_result = cv2.findContours(mask_combined, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if len(contour_result) == 3:  # OpenCV 3.x
            contours = contour_result[1]
        elif len(contour_result) == 2:  # OpenCV 4.x
            contours = contour_result[0]
        else:
            contours = contour_result
        # 2. æå–æ‰€æœ‰è¾¹ç•Œç‚¹
        boundary_points = []
        
        # 3. å¯¹æ¯ä¸ªè½®å»“ï¼Œæå–å…¶åº•éƒ¨è¾¹ç•Œç‚¹
        for contour in contours:
            # åˆ›å»ºè½®å»“çš„è¾¹ç•Œæ¡†
            x, y, w, h = cv2.boundingRect(contour)
            
            # åªå¤„ç†ROIåŒºåŸŸå†…çš„è½®å»“
            if y + h < roi_y_start:
                continue
            
            # åˆ›å»ºè½®å»“çš„æ©ç 
            contour_mask = np.zeros_like(mask_combined)
            cv2.drawContours(contour_mask, [contour], -1, 255, thickness=cv2.FILLED)
            
            # å¯¹è½®å»“è¿›è¡Œå¤šè¾¹å½¢è¿‘ä¼¼
            epsilon = 0.005 * cv2.arcLength(contour, True)
            approx = cv2.approxPolyDP(contour, epsilon, True)
            
            # æå–è½®å»“çš„åº•éƒ¨è¾¹ç¼˜ç‚¹
            for point in approx.squeeze():
                px, py = point
                # åªè€ƒè™‘ROIåŒºåŸŸå†…çš„ç‚¹
                if py < roi_y_start:
                    continue
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯åº•éƒ¨ç‚¹ï¼šè¯¥ç‚¹ä¸‹æ–¹ä¸æ˜¯é»„è‰²åŒºåŸŸ
                if py < height - 1:
                    if mask_combined[py + 1, px] == 0:  # ä¸‹æ–¹åƒç´ æ˜¯èƒŒæ™¯
                        boundary_points.append([px, py])
        
        # 4. å¦‚æœæ²¡æœ‰è¶³å¤Ÿè¾¹ç•Œç‚¹ï¼Œå°è¯•å¤‡ç”¨æ–¹æ³•
        if len(boundary_points) < 20:
            # å¤‡ç”¨æ–¹æ³•ï¼šé€åˆ—æ‰«æåº•éƒ¨è¾¹ç¼˜
            boundary_points = []
            for x in range(width // 5, 3 * width // 5):
                for y in range(height - 2, roi_y_start - 1, -1):
                    if mask_combined[y, x] == 255 and mask_combined[y + 1, x] == 0:
                        boundary_points.append([x, y])
                        break  # æ‰¾åˆ°è¯¥åˆ—çš„ç¬¬ä¸€ä¸ªè¾¹ç•Œç‚¹å³åœæ­¢
        
        # 5. ä½¿ç”¨RANSACç®—æ³•è¿›è¡Œç¨³å¥ç›´çº¿æ‹Ÿåˆ
        best_line = None
        best_inliers = []
        max_inliers = 0
        
        if len(boundary_points) >= 10:
            points_array = np.array(boundary_points)
            
            # ä½¿ç”¨RANSACå¤šæ¬¡è¿­ä»£å¯»æ‰¾æœ€ä½³æ‹Ÿåˆçº¿
            for _ in range(2):
                # éšæœºé€‰æ‹©ä¸¤ä¸ªç‚¹
                idx = np.random.choice(len(points_array), 2, replace=False)
                p1, p2 = points_array[idx[0]], points_array[idx[1]]
                
                # è®¡ç®—ç›´çº¿å‚æ•°
                dx = p2[0] - p1[0]
                dy = p2[1] - p1[1]
                if dx == 0:  # é¿å…é™¤ä»¥é›¶
                    continue
                    
                # ç›´çº¿æ–¹ç¨‹: y = mx + c
                m = dy / dx
                c = p1[1] - m * p1[0]
                
                # è®¡ç®—æ‰€æœ‰ç‚¹åˆ°ç›´çº¿çš„è·ç¦»
                distances = []
                for point in points_array:
                    px, py = point
                    # ç‚¹åˆ°ç›´çº¿çš„è·ç¦»å…¬å¼
                    dist = abs(m * px - py + c) / np.sqrt(m**2 + 1)
                    distances.append(dist)
                
                # ç»Ÿè®¡å†…ç‚¹ï¼ˆè·ç¦»å°äºé˜ˆå€¼çš„ç‚¹ï¼‰
                inlier_threshold = 2.0  # åƒç´ è·ç¦»é˜ˆå€¼
                inliers = [i for i, dist in enumerate(distances) if dist < inlier_threshold]
                
                if len(inliers) > max_inliers:
                    max_inliers = len(inliers)
                    best_inliers = inliers
                    best_line = (m, c, p1, p2)
        
        current_time = time.time()
        with self._lock:
            self._detected_flags['13'] = False
            self._line_angle = 0.0
            
            if best_line is not None and len(best_inliers) >= 10:
                m, c, p1, p2 = best_line
                
                # ä½¿ç”¨å†…ç‚¹é‡æ–°æ‹Ÿåˆç›´çº¿ï¼ˆæ›´ç²¾ç¡®ï¼‰
                inlier_points = points_array[best_inliers]
                vx, vy, cx, cy = cv2.fitLine(inlier_points, cv2.DIST_L2, 0, 0.01, 0.01)
                
                # è®¡ç®—ç›´çº¿è§’åº¦ï¼ˆç›¸å¯¹äºæ°´å¹³è½´ï¼‰
                line_angle = np.arctan2(vy, vx)[0]
                angle_deg = np.degrees(line_angle)
                target_angle = 0
                angle_diff = angle_deg - target_angle
                
                self._line_angle = np.radians(angle_diff)
                self._detected_flags['13'] = True
                
                # æŒç»­å¯¹é½è®¡æ—¶é€»è¾‘
                if abs(self._line_angle) < self._line_threshold:
                    if self._alignment_start_time == 0:
                        self._alignment_start_time = current_time
                    self._aligned_duration = current_time - self._alignment_start_time
                else:
                    self._alignment_start_time = 0.0
                    self._aligned_duration = 0.0
            else:
                self._alignment_start_time = 0.0
                self._aligned_duration = 0.0
                self._detected_flags['13'] = False

            # è°ƒè¯•å›¾åƒå¤„ç†
            debug_img = cv2.cvtColor(mask_combined, cv2.COLOR_GRAY2BGR)
            cv2.rectangle(debug_img, (0, roi_y_start), (width, height), (255, 0, 0), 2)  # ç»˜åˆ¶ROIåŒºåŸŸ
            
            # ç»˜åˆ¶æ‰€æœ‰è¾¹ç•Œç‚¹
            for point in boundary_points:
                cv2.circle(debug_img, tuple(point), 2, (0, 255, 0), -1)  # ç»¿è‰²ç‚¹è¡¨ç¤ºè¾¹ç•Œç‚¹
            
            # å¦‚æœæ£€æµ‹åˆ°ç›´çº¿ï¼Œç»˜åˆ¶æœ€ä½³æ‹Ÿåˆçº¿å’Œå†…ç‚¹
            if self._detected_flags['13']:
                # ç»˜åˆ¶å†…ç‚¹ï¼ˆè“è‰²ï¼‰
                for idx in best_inliers:
                    point = boundary_points[idx]
                    cv2.circle(debug_img, tuple(point), 3, (255, 0, 0), -1)  # è“è‰²ç‚¹è¡¨ç¤ºå†…ç‚¹
                
                # ç»˜åˆ¶æ‹Ÿåˆç›´çº¿ï¼ˆçº¢è‰²ç²—çº¿ï¼‰
                length = 500
                pt1 = (int(cx - vx * length), int(cy - vy * length))
                pt2 = (int(cx + vx * length), int(cy + vy * length))
                cv2.line(debug_img, pt1, pt2, (0, 0, 255), 3)
                
                # æ˜¾ç¤ºè§’åº¦ä¿¡æ¯
                cv2.putText(debug_img, 
                            f"Points: {len(boundary_points)} | Inliers: {len(best_inliers)} | Angle: {angle_diff:+.1f}\u00B0 | Hold: {self._aligned_duration:.1f}s", 
                            (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            
            # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°åˆé€‚çš„ç›´çº¿
            elif len(boundary_points) >= 10:
                cv2.putText(debug_img, 
                            f"WARNING: No suitable line found ({len(boundary_points)} boundary points)", 
                            (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
            else:
                cv2.putText(debug_img, 
                            f"WARNING: Not enough boundary points ({len(boundary_points)})", 
                            (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
            
            # ç»˜åˆ¶æ‰€æœ‰è½®å»“
            cv2.drawContours(debug_img, contours, -1, (255, 255, 0), 2)  # é’è‰²è½®å»“
            
            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            save_debug_image(f"detect13_{timestamp}.jpg", debug_img)
            
            # å®æ—¶è°ƒè¯•æ˜¾ç¤º
            if self.debug_mode:
                cv2.imshow("Detection Preview", debug_img)
                cv2.waitKey(1)

    def _detect_14(self, cv_image):
        # print("14")
        blurred = cv2.GaussianBlur(cv_image, (5, 5), 0)
        hsv = cv2.cvtColor(blurred, cv2.COLOR_BGR2HSV)
        height, width = hsv.shape[:2]

        # å®šä¹‰ ROI ä½ç½®ï¼šä½äºåº•éƒ¨å¾€ä¸Š 1/4 é«˜åº¦çš„ä½ç½®
        quarter_height = height // 3
        roi_center_y = height - quarter_height  # è·ç¦»åº•éƒ¨ 1/4 çš„ä½ç½®ï¼ˆå³æ•´ä½“çš„ 3/4 å¤„ï¼‰

        # å®šä¹‰ ROI é«˜åº¦ï¼ˆä¾‹å¦‚ 20 åƒç´ é«˜ï¼‰
        roi_height = height // 32

        # è®¡ç®—ä¸Šä¸‹è¾¹ç•Œ
        y_start = roi_center_y - roi_height // 2
        y_end = roi_center_y + roi_height // 2

        # ç¡®ä¿ä¸è¶Šç•Œ
        y_start = max(y_start, 0)
        y_end = min(y_end, height)

        # æ¨ªå‘ï¼šæ•´å¹…å®½åº¦
        x_start = 2 * width // 5
        x_end = 3 * width // 5  # æˆ–ç›´æ¥ç”¨ width

        # æå– ROI
        roi_hsv = hsv[y_start:y_end, x_start:x_end]

        mask_combined = get_combined_color_mask(roi_hsv, YELLOW_COMBINED_KEYS)

        # === 4. å½¢æ€å­¦å»å™ª ===
        mask_combined = cv2.morphologyEx(mask_combined, cv2.MORPH_OPEN, MORPH_KERNEL)
        mask_combined = cv2.morphologyEx(mask_combined, cv2.MORPH_CLOSE, MORPH_KERNEL)

        # === 5. é»„è‰²åƒç´ å æ¯”è®¡ç®— ===
        yellow_ratio = np.count_nonzero(mask_combined) / (mask_combined.size + 1e-5)
        
        with self._lock:
            self._alignment_start_time = 0.0
            self._aligned_duration = 0.0
            if yellow_ratio > 0.5:
                self._detected_flags['14'] = True
            else:
                self._detected_flags['14'] = False 

        debug_img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
        cv2.rectangle(debug_img,
                    (x_start, y_start),           # å·¦ä¸Šè§’
                    (x_end, y_end),             # å³ä¸‹è§’
                    (0, 255, 0), 2)          # ç»¿è‰²æ¡†ï¼Œçº¿å®½ 2
        cv2.putText(debug_img, f"Yellow Ratio: {yellow_ratio:.3f}", (10, 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)
        cv2.putText(debug_img, f"Detected: {self._detected_flags['14']}", (10, 60),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255) if not self._detected_flags['14'] else (0, 255, 0), 2)
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        save_debug_image(f"detect14_{timestamp}_{yellow_ratio}.jpg", debug_img)
        # è°ƒè¯•æ˜¾ç¤º
        if self.debug_mode:
            cv2.imshow("Detection Preview", debug_img)
            cv2.waitKey(1)

        if self.real_debug_mode:
            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S_%f")  # ç²¾ç¡®åˆ°å¾®ç§’
            filename = f"detect14_{timestamp}.jpg"

            save_debug_image(filename, debug_img)

    def _detect_15(self, cv_image):
        hsv = cv2.cvtColor(cv_image, cv2.COLOR_BGR2HSV)
        mask = cv2.inRange(hsv, self.lower_yellow, self.upper_yellow)
        
        # å½¢æ€å­¦å¤„ç†å»å™ª
        kernel = np.ones((5,5), np.uint8)
        cleaned = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
        
        # æŸ¥æ‰¾è¿é€šåŸŸ
        contour_result = cv2.findContours(cleaned, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if len(contour_result) == 3:  # OpenCV 3.x
            contours = contour_result[1]
        elif len(contour_result) == 2:  # OpenCV 4.x
            contours = contour_result[0]
        else:
            contours = contour_result
        valid_contours = [cnt for cnt in contours if cv2.contourArea(cnt) > 100]  # è¿‡æ»¤å°å™ªå£°
        
        # æ›´æ–°æ£€æµ‹çŠ¶æ€
        with self._lock:
            self._detected_flags['15'] = (len(valid_contours) == 1)  # è¿é€šåŸŸæ•°é‡ä¸º1æ—¶è§¦å‘
            
        # è°ƒè¯•æ˜¾ç¤º
        if self.debug_mode:
            debug_img = cv2.cvtColor(cv_image, cv2.COLOR_BGR2RGB)
            cv2.drawContours(debug_img, valid_contours, -1, (0,255,0), 2)
            cv2.putText(debug_img, f"Yellow Regions: {len(valid_contours)}", (10,30),
                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)
            cv2.imshow("Detection Preview", debug_img)
            cv2.waitKey(1)

    def _detect_16(self, cv_image):
        # é¢„å¤„ç†
        print(16)
        global arrow
        blurred = cv2.GaussianBlur(cv_image, (5, 5), 0)
        hsv = cv2.cvtColor(blurred, cv2.COLOR_BGR2HSV)

        # ä½¿ç”¨é…ç½®æ¨¡å—æå–é»„è‰²æ©ç 
        mask_combined = get_combined_color_mask(hsv, YELLOW_COMBINED_KEYS)
        mask_combined = cv2.morphologyEx(mask_combined, cv2.MORPH_OPEN, MORPH_KERNEL)
        mask_combined = cv2.morphologyEx(mask_combined, cv2.MORPH_CLOSE, MORPH_KERNEL)
        
        # åªä¿ç•™æœ€å¤§çš„ä¸¤ä¸ªè¿é€šåŸŸ
        num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(mask_combined, connectivity=8)
        clean_mask = np.zeros_like(mask_combined)
        if num_labels > 1:
            areas = stats[1:, cv2.CC_STAT_AREA]
            sorted_idx = np.argsort(areas)[::-1] + 1
            for i in sorted_idx[:min(2, len(sorted_idx))]:
                clean_mask[labels == i] = 255
        mask_combined = clean_mask

        # åˆ›å»ºROIèšç„¦å›¾åƒåº•éƒ¨ (é«˜åº¦1/2åŒºåŸŸ)
        height, width = mask_combined.shape[:2]
        roi_y_start = height - height // 2
        roi_mask = np.zeros_like(mask_combined)
        if arrow == Direction.Left:
            roi_mask[roi_y_start:, width // 2:] = 255
        else:
            roi_mask[roi_y_start:, :width // 2] = 255
        masked_roi = cv2.bitwise_and(mask_combined, roi_mask)

        # === ä¸“ä¸šæ–¹æ³•ï¼šæ£€æµ‹é»„è‰²è¾¹çº¿çš„å®é™…è¾¹ç•Œ ===
        # 1. æ‰¾åˆ°é»„è‰²åŒºåŸŸçš„è½®å»“
        contour_result = cv2.findContours(mask_combined, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if len(contour_result) == 3:  # OpenCV 3.x
            contours = contour_result[1]
        elif len(contour_result) == 2:  # OpenCV 4.x
            contours = contour_result[0]
        else:
            contours = contour_result
        # 2. æå–æ‰€æœ‰è¾¹ç•Œç‚¹
        boundary_points = []
        
        # 3. å¯¹æ¯ä¸ªè½®å»“ï¼Œæå–å…¶åº•éƒ¨è¾¹ç•Œç‚¹
        for contour in contours:
            # åˆ›å»ºè½®å»“çš„è¾¹ç•Œæ¡†
            x, y, w, h = cv2.boundingRect(contour)
            
            # åªå¤„ç†ROIåŒºåŸŸå†…çš„è½®å»“
            if y + h < roi_y_start:
                continue
            
            # åˆ›å»ºè½®å»“çš„æ©ç 
            contour_mask = np.zeros_like(mask_combined)
            cv2.drawContours(contour_mask, [contour], -1, 255, thickness=cv2.FILLED)
            
            # å¯¹è½®å»“è¿›è¡Œå¤šè¾¹å½¢è¿‘ä¼¼
            epsilon = 0.005 * cv2.arcLength(contour, True)
            approx = cv2.approxPolyDP(contour, epsilon, True)
            
            # æå–è½®å»“çš„åº•éƒ¨è¾¹ç¼˜ç‚¹
            for point in approx.squeeze():
                px, py = point
                # åªè€ƒè™‘ROIåŒºåŸŸå†…çš„ç‚¹
                if py < roi_y_start:
                    continue
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯åº•éƒ¨ç‚¹ï¼šè¯¥ç‚¹ä¸‹æ–¹ä¸æ˜¯é»„è‰²åŒºåŸŸ
                if py < height - 1:
                    if mask_combined[py + 1, px] == 0:  # ä¸‹æ–¹åƒç´ æ˜¯èƒŒæ™¯
                        boundary_points.append([px, py])
        
        # 4. å¦‚æœæ²¡æœ‰è¶³å¤Ÿè¾¹ç•Œç‚¹ï¼Œå°è¯•å¤‡ç”¨æ–¹æ³•
        if len(boundary_points) < 20:
            # å¤‡ç”¨æ–¹æ³•ï¼šé€åˆ—æ‰«æåº•éƒ¨è¾¹ç¼˜
            boundary_points = []
            if arrow == Direction.Right:
                for x in range(0, width // 2):
                    for y in range(height - 2, roi_y_start - 1, -1):
                        if mask_combined[y, x] == 255 and mask_combined[y + 1, x] == 0:
                            boundary_points.append([x, y])
                            break  # æ‰¾åˆ°è¯¥åˆ—çš„ç¬¬ä¸€ä¸ªè¾¹ç•Œç‚¹å³åœæ­¢
            else:
                for x in range(width // 2, width):
                    for y in range(height - 2, roi_y_start - 1, -1):
                        if mask_combined[y, x] == 255 and mask_combined[y + 1, x] == 0:
                            boundary_points.append([x, y])
                            break  # æ‰¾åˆ°è¯¥åˆ—çš„ç¬¬ä¸€ä¸ªè¾¹ç•Œç‚¹å³åœæ­¢
        
        # 5. ä½¿ç”¨RANSACç®—æ³•è¿›è¡Œç¨³å¥ç›´çº¿æ‹Ÿåˆ
        best_line = None
        best_inliers = []
        max_inliers = 0
        
        if len(boundary_points) >= 10:
            points_array = np.array(boundary_points)
            
            # ä½¿ç”¨RANSACå¤šæ¬¡è¿­ä»£å¯»æ‰¾æœ€ä½³æ‹Ÿåˆçº¿
            for _ in range(2):
                # éšæœºé€‰æ‹©ä¸¤ä¸ªç‚¹
                idx = np.random.choice(len(points_array), 2, replace=False)
                p1, p2 = points_array[idx[0]], points_array[idx[1]]
                
                # è®¡ç®—ç›´çº¿å‚æ•°
                dx = p2[0] - p1[0]
                dy = p2[1] - p1[1]
                if dx == 0:  # é¿å…é™¤ä»¥é›¶
                    continue
                    
                # ç›´çº¿æ–¹ç¨‹: y = mx + c
                m = dy / dx
                c = p1[1] - m * p1[0]
                
                # è®¡ç®—æ‰€æœ‰ç‚¹åˆ°ç›´çº¿çš„è·ç¦»
                distances = []
                for point in points_array:
                    px, py = point
                    # ç‚¹åˆ°ç›´çº¿çš„è·ç¦»å…¬å¼
                    dist = abs(m * px - py + c) / np.sqrt(m**2 + 1)
                    distances.append(dist)
                
                # ç»Ÿè®¡å†…ç‚¹ï¼ˆè·ç¦»å°äºé˜ˆå€¼çš„ç‚¹ï¼‰
                inlier_threshold = 2.0  # åƒç´ è·ç¦»é˜ˆå€¼
                inliers = [i for i, dist in enumerate(distances) if dist < inlier_threshold]
                
                if len(inliers) > max_inliers:
                    max_inliers = len(inliers)
                    best_inliers = inliers
                    best_line = (m, c, p1, p2)
        
        current_time = time.time()
        with self._lock:
            self._detected_flags['16'] = False
            self._line_angle = 0.0
            
            if best_line is not None and len(best_inliers) >= 10:
                m, c, p1, p2 = best_line
                
                # ä½¿ç”¨å†…ç‚¹é‡æ–°æ‹Ÿåˆç›´çº¿ï¼ˆæ›´ç²¾ç¡®ï¼‰
                inlier_points = points_array[best_inliers]
                vx, vy, cx, cy = cv2.fitLine(inlier_points, cv2.DIST_L2, 0, 0.01, 0.01)
                
                # è®¡ç®—ç›´çº¿è§’åº¦ï¼ˆç›¸å¯¹äºæ°´å¹³è½´ï¼‰
                line_angle = np.arctan2(vy, vx)[0]
                angle_deg = np.degrees(line_angle)
                target_angle = 0
                angle_diff = angle_deg - target_angle
                
                self._line_angle = np.radians(angle_diff)
                self._detected_flags['16'] = True
                
                # æŒç»­å¯¹é½è®¡æ—¶é€»è¾‘
                if abs(self._line_angle) < 0.05:
                    if self._alignment_start_time == 0:
                        self._alignment_start_time = current_time
                    self._aligned_duration = current_time - self._alignment_start_time
                else:
                    self._alignment_start_time = 0.0
                    self._aligned_duration = 0.0
            else:
                self._alignment_start_time = 0.0
                self._aligned_duration = 0.0
                self._detected_flags['16'] = False

            # è°ƒè¯•å›¾åƒå¤„ç†
            debug_img = cv2.cvtColor(mask_combined, cv2.COLOR_GRAY2BGR)
            cv2.rectangle(debug_img, (0, roi_y_start), (width, height), (255, 0, 0), 2)  # ç»˜åˆ¶ROIåŒºåŸŸ
            
            # ç»˜åˆ¶æ‰€æœ‰è¾¹ç•Œç‚¹
            for point in boundary_points:
                cv2.circle(debug_img, tuple(point), 2, (0, 255, 0), -1)  # ç»¿è‰²ç‚¹è¡¨ç¤ºè¾¹ç•Œç‚¹
            
            # å¦‚æœæ£€æµ‹åˆ°ç›´çº¿ï¼Œç»˜åˆ¶æœ€ä½³æ‹Ÿåˆçº¿å’Œå†…ç‚¹
            if self._detected_flags['16']:
                # ç»˜åˆ¶å†…ç‚¹ï¼ˆè“è‰²ï¼‰
                for idx in best_inliers:
                    point = boundary_points[idx]
                    cv2.circle(debug_img, tuple(point), 3, (255, 0, 0), -1)  # è“è‰²ç‚¹è¡¨ç¤ºå†…ç‚¹
                
                # ç»˜åˆ¶æ‹Ÿåˆç›´çº¿ï¼ˆçº¢è‰²ç²—çº¿ï¼‰
                length = 500
                pt1 = (int(cx - vx * length), int(cy - vy * length))
                pt2 = (int(cx + vx * length), int(cy + vy * length))
                cv2.line(debug_img, pt1, pt2, (0, 0, 255), 3)
                
                # æ˜¾ç¤ºè§’åº¦ä¿¡æ¯
                cv2.putText(debug_img, 
                            f"Points: {len(boundary_points)} | Inliers: {len(best_inliers)} | Angle: {angle_diff:+.1f}\u00B0 | Hold: {self._aligned_duration:.1f}s", 
                            (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            
            # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°åˆé€‚çš„ç›´çº¿
            elif len(boundary_points) >= 10:
                cv2.putText(debug_img, 
                            f"WARNING: No suitable line found ({len(boundary_points)} boundary points)", 
                            (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
            else:
                cv2.putText(debug_img, 
                            f"WARNING: Not enough boundary points ({len(boundary_points)})", 
                            (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
            
            # ç»˜åˆ¶æ‰€æœ‰è½®å»“
            cv2.drawContours(debug_img, contours, -1, (255, 255, 0), 2)  # é’è‰²è½®å»“
            
            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            save_debug_image(f"detect16_{timestamp}.jpg", debug_img)
            
            # å®æ—¶è°ƒè¯•æ˜¾ç¤º
            if self.debug_mode:
                cv2.imshow("Detection Preview", debug_img)
                cv2.waitKey(1)

    def _detect_17(self, cv_image):
        hsv = cv2.cvtColor(cv_image, cv2.COLOR_BGR2HSV)
        height, width = hsv.shape[:2]
        roi_height1 = height // 8
        roi_height2 = roi_height1 - 20
        x_start = 3 *width // 8
        x_end = 5 * width // 8
        roi = hsv[height-roi_height1:height - roi_height2, x_start:x_end]
        
        mask = cv2.inRange(roi, self.lower_yellow, self.upper_yellow)
        kernel = np.ones((3,3), np.uint8)
        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
        
        yellow_ratio = np.count_nonzero(mask) / (roi.size + 1e-5)  # é˜²æ­¢é™¤é›¶
        
        with self._lock:
            current_time = time.time()
            if yellow_ratio > 0.1:
                self._detected_flags['17'] = True
                '''if current_time - self._last_detection_time < 0.5:
                    self._detected_flags['17'] = True
                else:
                    self._detected_flags['17'] = False  # é‡ç½®çŸ­æš‚æ£€æµ‹'''
                self._last_detection_time = current_time
            else:
                self._detected_flags['17'] = False
        '''debug_img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
        cv2.rectangle(debug_img,
                    (x_start, height-roi_height1),           # å·¦ä¸Šè§’
                    (x_end, height - roi_height2),             # å³ä¸‹è§’
                    (0, 255, 0), 2)          # ç»¿è‰²æ¡†ï¼Œçº¿å®½ 2
        cv2.putText(debug_img, f"Yellow Ratio: {yellow_ratio:.3f}", (10, 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)
        cv2.putText(debug_img, f"Detected: {self._detected_flags['17']}", (10, 60),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255) if not self._detected_flags['17'] else (0, 255, 0), 2)
        
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S_%f")  # ç²¾ç¡®åˆ°å¾®ç§’
        cv2.imwrite(f"detect17_{timestamp}.jpg", debug_img)'''

        # è°ƒè¯•æ˜¾ç¤º
        if self.debug_mode:
            debug_img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
            cv2.rectangle(debug_img, 
                        (x_start, height-roi_height1),
                        (x_end, height-roi_height2),
                        (0,255,0), 2)
            cv2.imshow("Detection Preview", debug_img)
            cv2.waitKey(1)

    def _detect_18(self, cv_image):
        hsv = cv2.cvtColor(cv_image, cv2.COLOR_BGR2HSV)
        height, width = hsv.shape[:2]
        center_x = width // 2
        debug_img = cv_image.copy()

        def find_nearest_line(roi_x, roi_width, color):
            # ROIå‚æ•°
            roi_start_x = max(0, roi_x - roi_width//2)
            roi_end_x = min(width, roi_x + roi_width//2)
            roi = hsv[:, roi_start_x:roi_end_x]
            
            # é»„è‰²æ£€æµ‹
            mask = cv2.inRange(roi, self.lower_yellow, self.upper_yellow)
            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7,7))
            mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)
            
            # è¾¹ç¼˜æ£€æµ‹
            edges = cv2.Canny(mask, 30, 80)
            
            # çº¿æ®µæ£€æµ‹
            lines = cv2.HoughLinesP(edges, rho=1, theta=np.pi/180,
                                threshold=30, minLineLength=40, maxLineGap=30)
            
            nearest_line = None
            min_distance = float('inf')
            center_line_x = width // 2  # å…¨å±€ä¸­å¿ƒçº¿

            if lines is not None:
                for line in lines:
                    x1, y1, x2, y2 = line[0]
                    gx1 = roi_start_x + x1
                    gx2 = roi_start_x + x2
                    gy1, gy2 = y1, y2
                    mid_x = (gx1 + gx2) / 2
                    mid_y = (gy1 + gy2) / 2
                    
                    distance = abs(mid_x - center_line_x)
                    
                    if distance < min_distance:
                        min_distance = distance
                        nearest_line = ((gx1, gy1, gx2, gy2), mid_x)

            # å¯è§†åŒ–
            if nearest_line:
                (gx1, gy1, gx2, gy2), mid_x = nearest_line
                cv2.line(debug_img, (gx1, gy1), (gx2, gy2), (255,0,255), 2)
                cv2.circle(debug_img, (int(mid_x), int(mid_y)), 5, (0,255,255), -1)
                dx = gx2 - gx1
                if dx != 0:
                    return np.arctan2((gy2-gy1), dx)
            return None

        # å·¦å³æ£€æµ‹åŒºåŸŸå‚æ•°
        detect_width = width // 3  # æ¯ä¸ªæ£€æµ‹åŒºåŸŸå®½åº¦
        left_angle = find_nearest_line(center_x - width//6, detect_width, (255,0,255))  # å·¦æ£€æµ‹åŒºä¸­å¿ƒ
        right_angle = find_nearest_line(center_x + width//6, detect_width, (255,0,255)) # å³æ£€æµ‹åŒºä¸­å¿ƒ

        # è®¡ç®—åèˆªè¯¯å·®
        yaw_error = 0.0
        valid_angles = []
        if left_angle is not None: valid_angles.append(left_angle)
        if right_angle is not None: valid_angles.append(right_angle)
        
        if len(valid_angles) >= 1:
            avg_angle = np.mean(valid_angles)
            yaw_error = avg_angle

        with self._lock:
            self._detected_flags['18'] = len(valid_angles) > 0
            self._yaw_adjust = np.clip(yaw_error * 1.8, -1.5, 1.5)  # è°ƒèŠ‚ç³»æ•°

        # è°ƒè¯•æ˜¾ç¤º
        if self.debug_mode:
            # ç»˜åˆ¶ä¸­å¿ƒçº¿
            cv2.line(debug_img, (center_x,0), (center_x,height), (100,100,100), 1)
            
            # ç»˜åˆ¶æ£€æµ‹åŒºåŸŸ
            cv2.rectangle(debug_img, 
                        (center_x - width//8 - detect_width//2, 0),
                        (center_x - width//8 + detect_width//2, height),
                        (0,255,0), 1)
            cv2.rectangle(debug_img,
                        (center_x + width//8 - detect_width//2, 0),
                        (center_x + width//8 + detect_width//2, height),
                        (0,255,0), 1)
            
            # æ˜¾ç¤ºæ§åˆ¶ä¿¡æ¯
            info_text = f"Yaw: {np.degrees(self._yaw_adjust):+.1f}\u00B0"
            cv2.putText(debug_img, info_text, (10,30),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)
            cv2.imshow("Detection Preview", debug_img)
            cv2.waitKey(1)

    def _detect_18_5(self, cv_image):
        hsv = cv2.cvtColor(cv_image, cv2.COLOR_BGR2HSV)
        height, width = hsv.shape[:2]
        debug_img = cv_image.copy()
        
        # é¢œè‰²é˜ˆå€¼å®šä¹‰
        YELLOW = (self.lower_yellow, self.upper_yellow)
        GRAY = (np.array([0, 0, 40]), np.array([180, 30, 90]))  # æ·±ç°è‰²èŒƒå›´
        
        # æ‰«æå‚æ•°
        SCAN_START_Y = height // 2
        SCAN_STEP = 5              # æ°´å¹³æ‰«ææ­¥é•¿
        WINDOW_SIZE = 20           # é¢œè‰²é‡‡æ ·çª—å£å¤§å°
        
        def find_boundary(start_x, direction):
            """ä»ä¸­å¿ƒå‘æŒ‡å®šæ–¹å‘æ‰«æå¯»æ‰¾é¢œè‰²è¾¹ç•Œ"""
            boundary_x = None
            for x in range(start_x, width if direction==1 else 0, direction*SCAN_STEP):
                # å‚ç›´é‡‡æ ·çª—å£
                sample_area = hsv[SCAN_START_Y:SCAN_START_Y+WINDOW_SIZE, 
                                max(0,x-WINDOW_SIZE//2):min(width,x+WINDOW_SIZE//2)]
                
                # è®¡ç®—é¢œè‰²å æ¯”
                yellow_mask = cv2.inRange(sample_area, *YELLOW)
                gray_mask = cv2.inRange(sample_area, *GRAY)
                
                # å½“é»„è‰²å æ¯”çªå¢ä¸”ç°è‰²å‡å°‘æ—¶åˆ¤å®šä¸ºè¾¹ç•Œ
                if cv2.countNonZero(yellow_mask) > 0.5*WINDOW_SIZE**2 and \
                cv2.countNonZero(gray_mask) < 0.2*WINDOW_SIZE**2:
                    boundary_x = x
                    break
            return boundary_x

        # ä»ä¸­å¿ƒå‘å·¦å³æ‰«æ
        center_x = width//2
        left_edge = find_boundary(center_x, -1)  # å‘å·¦æ‰«æ
        right_edge = find_boundary(center_x, 1)  # å‘å³æ‰«æ

        # è®¡ç®—æ§åˆ¶å‚æ•°
        yaw_error = 0.0
        lateral_error = 0.0  # æ–°å¢æ¨ªå‘ä½ç½®è¯¯å·®
        
        if left_edge and right_edge:
            # è®¡ç®—é“è·¯ä¸­å¿ƒç‚¹
            target_center = (left_edge + right_edge) // 2
            
            # è§’åº¦è¯¯å·®ï¼ˆä¿æŒåŸæœ‰ï¼‰
            center_offset = center_x - target_center
            yaw_error = np.arctan(center_offset / (width/2))
            
            # æ–°å¢æ¨ªå‘ä½ç½®è¯¯å·®ï¼ˆå½’ä¸€åŒ–åˆ°[-1,1]ï¼‰
            lane_width = right_edge - left_edge
            lateral_error = (center_x - target_center) / (lane_width / 2)
            
            # å¯è§†åŒ–é“è·¯ä¸­å¿ƒçº¿
            cv2.line(debug_img, (target_center, SCAN_START_Y-30),
                    (target_center, SCAN_START_Y+30), (255,0,0), 2)
        elif left_edge:
            yaw_error = np.radians(-15)
            lateral_error = -0.3  # åªæœ‰å·¦è¾¹ç•Œæ—¶å‘å³è°ƒæ•´
        elif right_edge:
            yaw_error = np.radians(15)
            lateral_error = 0.3   # åªæœ‰å³è¾¹ç•Œæ—¶å‘å·¦è°ƒæ•´
        
        # å¯è§†åŒ–æ‰«æçº¿
        cv2.line(debug_img, (0, SCAN_START_Y), (width, SCAN_START_Y), (0,255,255), 2)
        if left_edge:
            cv2.line(debug_img, (left_edge, SCAN_START_Y-20),
                    (left_edge, SCAN_START_Y+20), (0,255,0), 3)
        if right_edge:
            cv2.line(debug_img, (right_edge, SCAN_START_Y-20),
                    (right_edge, SCAN_START_Y+20), (0,255,0), 3)
        
        # ä¿å­˜è¯¯å·®å€¼
        with self._lock:
            self._detected_flags['18_5'] = left_edge or right_edge
            self._yaw_adjust = np.clip(yaw_error * 0.3, -1.5, 1.5)
            self._lateral_error = np.clip(lateral_error, -1.0, 1.0)
        
        # è°ƒè¯•æ˜¾ç¤º
        # if self.debug_mode:
        info_text = f"Yaw: {np.degrees(yaw_error):+.1f}\u00B0 Lat: {lateral_error:.2f}"
        cv2.putText(debug_img, info_text, (10,30),
                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        save_debug_image(f"detect185_{timestamp}.jpg", debug_img)        
        # cv2.imshow("Detection Preview", debug_img)
        # cv2.waitKey(1)

    def _detect_19(self, cv_image):
        distance = self.LimitHeightDetector.detect_distance(cv_image)
        with self._lock:
            if distance is not None:
                self._detected_flags['19'] = True
                self._limit_height_distance = distance
            else:
                self._detected_flags['19'] = False
                self._limit_height_distance = None
        if self.debug_mode:
            debug_img = cv_image.copy()
            if distance is not None:
                cv2.putText(debug_img, f"Distance: {distance:.2f}m", (10, 30),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)

            cv2.imshow("Detection Preview", debug_img)
            cv2.waitKey(1)
    
    def _detect_19_5(self, cv_image):
        hsv = cv2.cvtColor(cv_image, cv2.COLOR_BGR2HSV)
        height, width = hsv.shape[:2]
        debug_img = cv_image.copy()
        
        # é¢œè‰²é˜ˆå€¼å®šä¹‰
        YELLOW = (self.lower_yellow, self.upper_yellow)
        GRAY = (np.array([0, 0, 40]), np.array([180, 30, 90]))  # æ·±ç°è‰²èŒƒå›´
        
        # æ‰«æå‚æ•°
        SCAN_START_Y = 3 * height // 5
        SCAN_STEP = 5              # æ°´å¹³æ‰«ææ­¥é•¿
        WINDOW_SIZE = 20           # é¢œè‰²é‡‡æ ·çª—å£å¤§å°
        
        def find_boundary(start_x, direction):
            """ä»ä¸­å¿ƒå‘æŒ‡å®šæ–¹å‘æ‰«æå¯»æ‰¾é¢œè‰²è¾¹ç•Œ"""
            boundary_x = None
            for x in range(start_x, width if direction==1 else 0, direction*SCAN_STEP):
                # å‚ç›´é‡‡æ ·çª—å£
                sample_area = hsv[SCAN_START_Y:SCAN_START_Y+WINDOW_SIZE, 
                                max(0,x-WINDOW_SIZE//2):min(width,x+WINDOW_SIZE//2)]
                
                # è®¡ç®—é¢œè‰²å æ¯”
                yellow_mask = cv2.inRange(sample_area, *YELLOW)
                gray_mask = cv2.inRange(sample_area, *GRAY)
                
                # å½“é»„è‰²å æ¯”çªå¢ä¸”ç°è‰²å‡å°‘æ—¶åˆ¤å®šä¸ºè¾¹ç•Œ
                if cv2.countNonZero(yellow_mask) > 0.5*WINDOW_SIZE**2 and \
                cv2.countNonZero(gray_mask) < 0.2*WINDOW_SIZE**2:
                    boundary_x = x
                    break
            return boundary_x

        # ä»ä¸­å¿ƒå‘å·¦å³æ‰«æ
        center_x = width//2
        left_edge = find_boundary(center_x, -1)  # å‘å·¦æ‰«æ
        right_edge = find_boundary(center_x, 1)  # å‘å³æ‰«æ

        # è®¡ç®—æ§åˆ¶å‚æ•°
        yaw_error = 0.0
        lateral_error = 0.0  # æ–°å¢æ¨ªå‘ä½ç½®è¯¯å·®
        
        if left_edge and right_edge:
            # è®¡ç®—é“è·¯ä¸­å¿ƒç‚¹
            target_center = (left_edge + right_edge) // 2
            
            # è§’åº¦è¯¯å·®ï¼ˆä¿æŒåŸæœ‰ï¼‰
            center_offset = center_x - target_center
            yaw_error = np.arctan(center_offset / (width/2 + 1e-5))
            
            # æ–°å¢æ¨ªå‘ä½ç½®è¯¯å·®ï¼ˆå½’ä¸€åŒ–åˆ°[-1,1]ï¼‰
            lane_width = right_edge - left_edge
            lateral_error = (center_x - target_center) / (lane_width / 2 + 1e-5)
            
            # å¯è§†åŒ–é“è·¯ä¸­å¿ƒçº¿
            cv2.line(debug_img, (target_center, SCAN_START_Y-30),
                    (target_center, SCAN_START_Y+30), (255,0,0), 2)
        elif left_edge:
            yaw_error = np.radians(-15)
            lateral_error = 0.1  # åªæœ‰å·¦è¾¹ç•Œæ—¶å‘å³è°ƒæ•´
        elif right_edge:
            yaw_error = np.radians(15)
            lateral_error = -0.1   # åªæœ‰å³è¾¹ç•Œæ—¶å‘å·¦è°ƒæ•´
        
        # å¯è§†åŒ–æ‰«æçº¿
        cv2.line(debug_img, (0, SCAN_START_Y), (width, SCAN_START_Y), (0,255,255), 2)
        if left_edge:
            cv2.line(debug_img, (left_edge, SCAN_START_Y-20),
                    (left_edge, SCAN_START_Y+20), (0,255,0), 3)
        if right_edge:
            cv2.line(debug_img, (right_edge, SCAN_START_Y-20),
                    (right_edge, SCAN_START_Y+20), (0,255,0), 3)
        
        # ä¿å­˜è¯¯å·®å€¼
        with self._lock:
            self._detected_flags['19_5'] = left_edge or right_edge
            self._yaw_adjust = np.clip(yaw_error * 0.3, -1.5, 1.5)
            self._lateral_error = np.clip(lateral_error, -1.0, 1.0)
        
        # è°ƒè¯•æ˜¾ç¤º
        # if self.debug_mode:
        info_text = f"Yaw: {np.degrees(yaw_error):+.1f}\u00B0 Lat: {lateral_error:.2f}"
        cv2.putText(debug_img, info_text, (10,30),
                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        save_debug_image(f"detect195_{timestamp}.jpg", debug_img)  
        # cv2.imshow("Detection Preview", debug_img)
        # cv2.waitKey(1)

    def _detect_19_6(self, cv_image):
        print("è¿›å…¥æ£€æµ‹19.6")

        global QR2
        global QR2_cnt
        if cv_image is None:
            print("QRCodeDetector Error: no frame")
            return

        # ä¿è¯å…¼å®¹ python2 å’Œ python3
        IS_PY3 = sys.version_info.major == 3
        if IS_PY3:
            from urllib.request import urlopen, Request
            from urllib.error import URLError
            from urllib.parse import urlencode
        else:
            from urllib2 import urlopen, Request, URLError
            from urllib import urlencode

        # é˜²æ­¢ https è¯ä¹¦æ ¡éªŒä¸æ­£ç¡®
        ssl._create_default_https_context = ssl._create_unverified_context

        # API Key å’Œ Secret Key
        API_KEY = 'ZyIjArFIzoRtgnT8WAUw5tCv'
        SECRET_KEY = '9JlkvkYt7r0C0GsJGcuRyoMhWaJx12yF'

        # è·å– access_token
        def fetch_token():
            url = "https://aip.baidubce.com/oauth/2.0/token"
            params = {
                "grant_type": "client_credentials",
                "client_id": API_KEY,
                "client_secret": SECRET_KEY
            }
            return str(requests.post(url, params=params).json().get("access_token"))

        def cv2_to_base64(cv_img):
            _, buffer = cv2.imencode(".jpg", cv_img)
            return base64.b64encode(buffer).decode()

        def ocr_text(img_base64, token):
            url = "https://aip.baidubce.com/rest/2.0/ocr/v1/accurate_basic?access_token=" + token
            headers = {'content-type': 'application/x-www-form-urlencoded'}
            data = {"image": img_base64}
            response = requests.post(url, data=data, headers=headers)
            result_json = response.json()
            if "words_result" in result_json:
                return "".join([item["words"] for item in result_json["words_result"]])
            else:
                return None

        def ocr_qrcode(img_base64, token):
            url = "https://aip.baidubce.com/rest/2.0/ocr/v1/qrcode?access_token=" + token
            headers = {'content-type': 'application/x-www-form-urlencoded'}
            data = {"image": img_base64}
            response = requests.post(url, data=data, headers=headers)
            result_json = response.json()
            if "codes_result" in result_json:
                codes = []
                for code in result_json["codes_result"]:
                    text = code.get("text", "")
                    if isinstance(text, list):
                        text = " ".join(text)
                    codes.append(str(text))
                return "\n".join(codes)
            else:
                return None
        
        
        # è·å– token
        token = fetch_token()

        # qr_result = cv_qrcode(cv_image)

        # å¾…è¯†åˆ«çš„å›¾ç‰‡
        img_base64 = cv2_to_base64(cv_image)

        # å…ˆå°è¯•è¯†åˆ«äºŒç»´ç 
        dir_result = None
        qr_result = ocr_qrcode(img_base64, token) ##APIè¯†åˆ«äºŒç»´ç 
        QR2_cnt = QR2_cnt + 1 
        # end_QR1_time = time.time()
        print("è¯†åˆ«æ€»æ¬¡æ•°:", QR2_cnt)

        if qr_result == "B-1" or qr_result == "B-2" :
            print("ã€äºŒç»´ç è¯†åˆ«ç»“æœã€‘\n", qr_result)
            QR2 = qr_result
            dir_result = qr_result
        
        elif (QR2_cnt % 3 == 1):
            print("ã€æœªæ£€æµ‹åˆ°äºŒç»´ç ï¼Œå°è¯•æ–‡å­—è¯†åˆ«ã€‘")
            text_result = ocr_text(img_base64, token)
            text_state = 0
            normalized_string = ""

            if not text_result:
                print("\næœªè¯†åˆ«åˆ°ä»»ä½•æœ‰æ•ˆæ–‡å­—ã€‚")
            else:
                #sorted_texts = sorted(text_result, key = lambda item: item['box'][0])
                #full_detected_string = "".join([item['text'] for item in sorted_texts])

                #æ›´ä¸¥æ ¼çš„æ¸…æ´—è§„åˆ™
                normalized_string = re.sub(r'[^AB12]', '', text_result.upper())
                print(f"ä¸¥æ ¼æ¸…æ´—å (åªä¿ç•™A,B,1,2): '{normalized_string}'")

                #æ˜ å°„é€»è¾‘
                # æ£€æŸ¥æ˜¯å¦åŒæ—¶åŒ…å« 'A' å’Œ '1'
            if 'A' in normalized_string and '1' in normalized_string:
                text_state = 1
                QR2 = "A-1"
                dir_result = "A-1"
            # æ£€æŸ¥æ˜¯å¦åŒæ—¶åŒ…å« 'A' å’Œ '2'
            elif 'A' in normalized_string and '2' in normalized_string:
                text_state = 2
                QR2 = "A-2"
                dir_result = "A-2"
            # æ£€æŸ¥æ˜¯å¦åŒæ—¶åŒ…å« 'B' å’Œ '1'
            elif 'B' in normalized_string and '1' in normalized_string:
                text_state = 3
                QR2 = "B-1"
                dir_result = "B-1"
            # æ£€æŸ¥æ˜¯å¦åŒæ—¶åŒ…å« 'B' å’Œ '2'
            elif 'B' in normalized_string and '2' in normalized_string:
                text_state = 4
                QR2 = "B-2"
                dir_result = "B-2"

            print("\n--- æœ€ç»ˆçŠ¶æ€ ---")
            if text_state == 0:
                print(f"æœªèƒ½åŒ¹é…åˆ°ç›®æ ‡çŠ¶æ€ (æ¸…æ´—åç»“æœ: '{normalized_string}')ã€‚")
                dir_result = None
            else:
                # ã€ä¿®æ”¹ã€‘æ‰“å°ä¿¡æ¯æ›´æ¸…æ™°
                print(f"æˆåŠŸåŒ¹é…åˆ°æ¨¡å¼ '{dir_result}' (æ¥è‡ª: '{normalized_string}')ï¼Œè®¾ç½®çŠ¶æ€ä¸º: {text_state}")

            print("ã€æ–‡å­—è¯†åˆ«ç»“æœã€‘\n", dir_result)
        
        with self._lock:
            self._detected_flags['19_6'] = (dir_result is not None)
            print(f"äºŒç»´ç æ£€æµ‹æ ‡è¯†ä½æ›´æ–°ä¸º: {self._detected_flags['19_6']}")

    def _detect_19_55(self, cv_image):
        # print(20)
        hsv = cv2.cvtColor(cv_image, cv2.COLOR_BGR2HSV)
        height, width = hsv.shape[:2]
        roi_height1 = height // 2
        roi_height2 = roi_height1 - 20
        x_start = 12 * width // 14 if arrow == Direction.Left else 1 * width // 14
        x_end = 13 * width // 14 if arrow == Direction.Left else 2 * width // 14
        roi = hsv[height-roi_height1:height - roi_height2, x_start:x_end]
        
        '''mask = cv2.inRange(roi, self.lower_yellow, self.upper_yellow)
        kernel = np.ones((3,3), np.uint8)
        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
        
        yellow_ratio = np.count_nonzero(mask) / (roi.size + 1e-5)  # é˜²æ­¢é™¤é›¶'''
        mask_combined = get_combined_color_mask(roi, YELLOW_COMBINED_KEYS)

        # === 4. å½¢æ€å­¦å»å™ª ===
        mask_combined = cv2.morphologyEx(mask_combined, cv2.MORPH_OPEN, MORPH_KERNEL)
        mask_combined = cv2.morphologyEx(mask_combined, cv2.MORPH_CLOSE, MORPH_KERNEL)

        # === 5. é»„è‰²åƒç´ å æ¯”è®¡ç®— ===
        yellow_ratio = np.count_nonzero(mask_combined) / (roi.size + 1e-5)
        with self._lock:
            current_time = time.time()
            if yellow_ratio > 0.1:
                self._detected_flags['19_55'] = True
                '''if current_time - self._last_detection_time < 0.1:
                    self._detected_flags['20'] = True
                else:
                    self._detected_flags['20'] = False  # é‡ç½®çŸ­æš‚æ£€æµ‹'''
                self._last_detection_time = current_time
            else:
                self._detected_flags['19_55'] = False
        debug_img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
        cv2.rectangle(debug_img, 
                    (x_start, height-roi_height1),
                    (x_end, height - roi_height2),
                    (0,255,0), 2)
        cv2.putText(debug_img, f"Yellow Ratio: {yellow_ratio:.3f}", (10, 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)
        cv2.putText(debug_img, f"Detected: {self._detected_flags['19_55']}", (10, 60),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255) if not self._detected_flags['9'] else (0, 255, 0), 2)
        
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        save_debug_image(f"detect19_55_{timestamp}_{yellow_ratio}.jpg", debug_img)
        # è°ƒè¯•æ˜¾ç¤º
        if self.debug_mode:
            debug_img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
            cv2.rectangle(debug_img, 
                        (x_start, height-roi_height1),
                        (x_end, height - roi_height2),
                        (0,255,0), 2)
            cv2.imshow("Detection Preview", debug_img)
            cv2.waitKey(1)

    def _detect_20(self, cv_image):
        # print(20)
        hsv = cv2.cvtColor(cv_image, cv2.COLOR_BGR2HSV)
        height, width = hsv.shape[:2]
        '''roi_height1 = height // 4
        roi_height2 = roi_height1 - 10
        x_start = 13 * width // 14 if arrow == Direction.Left else 0
        x_end = width if arrow == Direction.Left else width // 14'''
        roi_height1 = height // 2 
        roi_height2 = roi_height1 - 5
        x_start = 3 * width // 7
        x_end = 4 * width // 7
        roi = hsv[height-roi_height1:height - roi_height2, x_start:x_end]
        
        '''mask = cv2.inRange(roi, self.lower_yellow, self.upper_yellow)
        kernel = np.ones((3,3), np.uint8)
        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
        
        yellow_ratio = np.count_nonzero(mask) / (roi.size + 1e-5)  # é˜²æ­¢é™¤é›¶'''

        mask_combined = get_combined_color_mask(roi, YELLOW_COMBINED_KEYS)

        # === 4. å½¢æ€å­¦å»å™ª ===
        mask_combined = cv2.morphologyEx(mask_combined, cv2.MORPH_OPEN, MORPH_KERNEL)
        mask_combined = cv2.morphologyEx(mask_combined, cv2.MORPH_CLOSE, MORPH_KERNEL)

        
        # === 5. é»„è‰²åƒç´ å æ¯”è®¡ç®— ===
        yellow_ratio = np.count_nonzero(mask_combined) / (mask_combined.size + 1e-5)

        with self._lock:
            current_time = time.time()
            if yellow_ratio > self.detection_threshold:
                self._detected_flags['20'] = True
                '''if current_time - self._last_detection_time < 0.1:
                    self._detected_flags['20'] = True
                else:
                    self._detected_flags['20'] = False  # é‡ç½®çŸ­æš‚æ£€æµ‹'''
                self._last_detection_time = current_time
            else:
                self._detected_flags['20'] = False
        debug_img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
        cv2.rectangle(debug_img, 
                    (x_start, height-roi_height1),
                    (x_end, height - roi_height2),
                    (0,255,0), 2)
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        save_debug_image(f"detect20_{timestamp}_{yellow_ratio}.jpg", debug_img)
        # è°ƒè¯•æ˜¾ç¤º
        if self.debug_mode:
            debug_img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
            cv2.rectangle(debug_img, 
                        (x_start, height-roi_height1),
                        (x_end, height - roi_height2),
                        (0,255,0), 2)
            cv2.imshow("Detection Preview", debug_img)
            cv2.waitKey(1)

    def _detect_21(self, cv_image):
        # é¢„å¤„ç†
        blurred = cv2.GaussianBlur(cv_image, (5, 5), 0)
        hsv = cv2.cvtColor(blurred, cv2.COLOR_BGR2HSV)

        # ä½¿ç”¨é…ç½®æ¨¡å—æå–é»„è‰²æ©ç 
        mask_combined = get_combined_color_mask(hsv, YELLOW_COMBINED_KEYS)
        mask_combined = cv2.morphologyEx(mask_combined, cv2.MORPH_OPEN, MORPH_KERNEL)
        mask_combined = cv2.morphologyEx(mask_combined, cv2.MORPH_CLOSE, MORPH_KERNEL)
        
        # åªä¿ç•™æœ€å¤§çš„ä¸¤ä¸ªè¿é€šåŸŸ
        num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(mask_combined, connectivity=8)
        clean_mask = np.zeros_like(mask_combined)
        if num_labels > 1:
            areas = stats[1:, cv2.CC_STAT_AREA]
            sorted_idx = np.argsort(areas)[::-1] + 1
            for i in sorted_idx[:min(2, len(sorted_idx))]:
                clean_mask[labels == i] = 255
        mask_combined = clean_mask

        # åˆ›å»ºROIèšç„¦å›¾åƒåº•éƒ¨ (é«˜åº¦1/2åŒºåŸŸ)
        height, width = mask_combined.shape[:2]
        roi_y_start = height - height // 2
        roi_mask = np.zeros_like(mask_combined)
        roi_mask[roi_y_start:, :] = 255
        masked_roi = cv2.bitwise_and(mask_combined, roi_mask)

        # === ä¸“ä¸šæ–¹æ³•ï¼šæ£€æµ‹é»„è‰²è¾¹çº¿çš„å®é™…è¾¹ç•Œ ===
        # 1. æ‰¾åˆ°é»„è‰²åŒºåŸŸçš„è½®å»“
        contour_result = cv2.findContours(mask_combined, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if len(contour_result) == 3:  # OpenCV 3.x
            contours = contour_result[1]
        elif len(contour_result) == 2:  # OpenCV 4.x
            contours = contour_result[0]
        else:
            contours = contour_result
        # 2. æå–æ‰€æœ‰è¾¹ç•Œç‚¹
        boundary_points = []
        
        # 3. å¯¹æ¯ä¸ªè½®å»“ï¼Œæå–å…¶åº•éƒ¨è¾¹ç•Œç‚¹
        for contour in contours:
            # åˆ›å»ºè½®å»“çš„è¾¹ç•Œæ¡†
            x, y, w, h = cv2.boundingRect(contour)
            
            # åªå¤„ç†ROIåŒºåŸŸå†…çš„è½®å»“
            if y + h < roi_y_start:
                continue
            
            # åˆ›å»ºè½®å»“çš„æ©ç 
            contour_mask = np.zeros_like(mask_combined)
            cv2.drawContours(contour_mask, [contour], -1, 255, thickness=cv2.FILLED)
            
            # å¯¹è½®å»“è¿›è¡Œå¤šè¾¹å½¢è¿‘ä¼¼
            epsilon = 0.005 * cv2.arcLength(contour, True)
            approx = cv2.approxPolyDP(contour, epsilon, True)
            
            # æå–è½®å»“çš„åº•éƒ¨è¾¹ç¼˜ç‚¹
            for point in approx.squeeze():
                px, py = point
                # åªè€ƒè™‘ROIåŒºåŸŸå†…çš„ç‚¹
                if py < roi_y_start:
                    continue
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯åº•éƒ¨ç‚¹ï¼šè¯¥ç‚¹ä¸‹æ–¹ä¸æ˜¯é»„è‰²åŒºåŸŸ
                if py < height - 1:
                    if mask_combined[py + 1, px] == 0:  # ä¸‹æ–¹åƒç´ æ˜¯èƒŒæ™¯
                        boundary_points.append([px, py])
        
        # 4. å¦‚æœæ²¡æœ‰è¶³å¤Ÿè¾¹ç•Œç‚¹ï¼Œå°è¯•å¤‡ç”¨æ–¹æ³•
        if len(boundary_points) < 20:
            # å¤‡ç”¨æ–¹æ³•ï¼šé€åˆ—æ‰«æåº•éƒ¨è¾¹ç¼˜
            boundary_points = []
            for x in range(width):
                for y in range(height - 2, roi_y_start - 1, -1):
                    if mask_combined[y, x] == 255 and mask_combined[y + 1, x] == 0:
                        boundary_points.append([x, y])
                        break  # æ‰¾åˆ°è¯¥åˆ—çš„ç¬¬ä¸€ä¸ªè¾¹ç•Œç‚¹å³åœæ­¢
        
        # 5. ä½¿ç”¨RANSACç®—æ³•è¿›è¡Œç¨³å¥ç›´çº¿æ‹Ÿåˆ
        best_line = None
        best_inliers = []
        max_inliers = 0
        
        if len(boundary_points) >= 10:
            points_array = np.array(boundary_points)
            
            # ä½¿ç”¨RANSACå¤šæ¬¡è¿­ä»£å¯»æ‰¾æœ€ä½³æ‹Ÿåˆçº¿
            for _ in range(2):
                # éšæœºé€‰æ‹©ä¸¤ä¸ªç‚¹
                idx = np.random.choice(len(points_array), 2, replace=False)
                p1, p2 = points_array[idx[0]], points_array[idx[1]]
                
                # è®¡ç®—ç›´çº¿å‚æ•°
                dx = p2[0] - p1[0]
                dy = p2[1] - p1[1]
                if dx == 0:  # é¿å…é™¤ä»¥é›¶
                    continue
                    
                # ç›´çº¿æ–¹ç¨‹: y = mx + c
                m = dy / dx
                c = p1[1] - m * p1[0]
                
                # è®¡ç®—æ‰€æœ‰ç‚¹åˆ°ç›´çº¿çš„è·ç¦»
                distances = []
                for point in points_array:
                    px, py = point
                    # ç‚¹åˆ°ç›´çº¿çš„è·ç¦»å…¬å¼
                    dist = abs(m * px - py + c) / np.sqrt(m**2 + 1)
                    distances.append(dist)
                
                # ç»Ÿè®¡å†…ç‚¹ï¼ˆè·ç¦»å°äºé˜ˆå€¼çš„ç‚¹ï¼‰
                inlier_threshold = 2.0  # åƒç´ è·ç¦»é˜ˆå€¼
                inliers = [i for i, dist in enumerate(distances) if dist < inlier_threshold]
                
                if len(inliers) > max_inliers:
                    max_inliers = len(inliers)
                    best_inliers = inliers
                    best_line = (m, c, p1, p2)
        
        current_time = time.time()
        with self._lock:
            self._detected_flags['21'] = False
            self._line_angle = 0.0
            
            if best_line is not None and len(best_inliers) >= 10:
                m, c, p1, p2 = best_line
                
                # ä½¿ç”¨å†…ç‚¹é‡æ–°æ‹Ÿåˆç›´çº¿ï¼ˆæ›´ç²¾ç¡®ï¼‰
                inlier_points = points_array[best_inliers]
                vx, vy, cx, cy = cv2.fitLine(inlier_points, cv2.DIST_L2, 0, 0.01, 0.01)
                
                # è®¡ç®—ç›´çº¿è§’åº¦ï¼ˆç›¸å¯¹äºæ°´å¹³è½´ï¼‰
                line_angle = np.arctan2(vy, vx)[0]
                angle_deg = np.degrees(line_angle)
                target_angle = 0
                angle_diff = angle_deg - target_angle
                
                self._line_angle = np.radians(angle_diff)
                self._detected_flags['21'] = True
                
                # æŒç»­å¯¹é½è®¡æ—¶é€»è¾‘
                if abs(self._line_angle) < self._line_threshold:
                    if self._alignment_start_time == 0:
                        self._alignment_start_time = current_time
                    self._aligned_duration = current_time - self._alignment_start_time
                else:
                    self._alignment_start_time = 0.0
                    self._aligned_duration = 0.0
            else:
                self._alignment_start_time = 0.0
                self._aligned_duration = 0.0
                self._detected_flags['21'] = False

            # è°ƒè¯•å›¾åƒå¤„ç†
            debug_img = cv2.cvtColor(mask_combined, cv2.COLOR_GRAY2BGR)
            cv2.rectangle(debug_img, (0, roi_y_start), (width, height), (255, 0, 0), 2)  # ç»˜åˆ¶ROIåŒºåŸŸ
            
            # ç»˜åˆ¶æ‰€æœ‰è¾¹ç•Œç‚¹
            for point in boundary_points:
                cv2.circle(debug_img, tuple(point), 2, (0, 255, 0), -1)  # ç»¿è‰²ç‚¹è¡¨ç¤ºè¾¹ç•Œç‚¹
            
            # å¦‚æœæ£€æµ‹åˆ°ç›´çº¿ï¼Œç»˜åˆ¶æœ€ä½³æ‹Ÿåˆçº¿å’Œå†…ç‚¹
            if self._detected_flags['21']:
                # ç»˜åˆ¶å†…ç‚¹ï¼ˆè“è‰²ï¼‰
                for idx in best_inliers:
                    point = boundary_points[idx]
                    cv2.circle(debug_img, tuple(point), 3, (255, 0, 0), -1)  # è“è‰²ç‚¹è¡¨ç¤ºå†…ç‚¹
                
                # ç»˜åˆ¶æ‹Ÿåˆç›´çº¿ï¼ˆçº¢è‰²ç²—çº¿ï¼‰
                length = 500
                pt1 = (int(cx - vx * length), int(cy - vy * length))
                pt2 = (int(cx + vx * length), int(cy + vy * length))
                cv2.line(debug_img, pt1, pt2, (0, 0, 255), 3)
                
                # æ˜¾ç¤ºè§’åº¦ä¿¡æ¯
                cv2.putText(debug_img, 
                            f"Points: {len(boundary_points)} | Inliers: {len(best_inliers)} | Angle: {angle_diff:+.1f}\u00B0 | Hold: {self._aligned_duration:.1f}s", 
                            (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            
            # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°åˆé€‚çš„ç›´çº¿
            elif len(boundary_points) >= 10:
                cv2.putText(debug_img, 
                            f"WARNING: No suitable line found ({len(boundary_points)} boundary points)", 
                            (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
            else:
                cv2.putText(debug_img, 
                            f"WARNING: Not enough boundary points ({len(boundary_points)})", 
                            (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
            
            # ç»˜åˆ¶æ‰€æœ‰è½®å»“
            cv2.drawContours(debug_img, contours, -1, (255, 255, 0), 2)  # é’è‰²è½®å»“
            
            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            save_debug_image(f"detect21_{timestamp}.jpg", debug_img)
            
            # å®æ—¶è°ƒè¯•æ˜¾ç¤º
            if self.debug_mode:
                cv2.imshow("Detection Preview", debug_img)
                cv2.waitKey(1)
    
    def _detect_22(self, cv_image):
        hsv = cv2.cvtColor(cv_image, cv2.COLOR_BGR2HSV)
        height, width = hsv.shape[:2]
        roi_height1 = 50
        roi_height2 = roi_height1 - 20
        x_start = 0
        x_end = x_start + width - 1
        roi = hsv[height-roi_height1:height - roi_height2, x_start:width]
        
        '''mask = cv2.inRange(roi, self.lower_yellow, self.upper_yellow)
        kernel = np.ones((3,3), np.uint8)
        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
        
        yellow_ratio = np.count_nonzero(mask) / (roi.size + 1e-5)  # é˜²æ­¢é™¤é›¶'''
        mask_combined = get_combined_color_mask(roi, YELLOW_COMBINED_KEYS)

        # === 4. å½¢æ€å­¦å»å™ª ===
        mask_combined = cv2.morphologyEx(mask_combined, cv2.MORPH_OPEN, MORPH_KERNEL)
        mask_combined = cv2.morphologyEx(mask_combined, cv2.MORPH_CLOSE, MORPH_KERNEL)

        # === 5. é»„è‰²åƒç´ å æ¯”è®¡ç®— ===
        yellow_ratio = np.count_nonzero(mask_combined) / (roi.size + 1e-5)
        with self._lock:
            current_time = time.time()
            self._aligned_duration = 0.0
            if yellow_ratio > self.detection_threshold:
                self._detected_flags['22'] = True
                '''if current_time - self._last_detection_time < 0.5:
                    self._detected_flags['22'] = True
                else:
                    self._detected_flags['22'] = False  # é‡ç½®çŸ­æš‚æ£€æµ‹'''
                self._last_detection_time = current_time
            else:
                self._detected_flags['22'] = False
        debug_img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
        cv2.rectangle(debug_img, 
                    (x_start, height-roi_height1),
                    (x_end, height - roi_height2),
                    (0,255,0), 2)
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        save_debug_image(f"detect22_{timestamp}_{yellow_ratio}.jpg", debug_img)
        # è°ƒè¯•æ˜¾ç¤º
        if self.debug_mode:
            debug_img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
            cv2.rectangle(debug_img, 
                        (x_start, height-roi_height1),
                        (x_end, height - roi_height2),
                        (0,255,0), 2)
            cv2.imshow("Detection Preview", debug_img)
            cv2.waitKey(1)

    def _detect_23(self, cv_image):
        # é¢„å¤„ç†
        blurred = cv2.GaussianBlur(cv_image, (5, 5), 0)
        hsv = cv2.cvtColor(blurred, cv2.COLOR_BGR2HSV)

        mask = cv2.inRange(hsv, self.lower_yellow, self.upper_yellow)
        kernel = np.ones((3,3), np.uint8)
        mask_combined = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
        # ä½¿ç”¨é…ç½®æ¨¡å—æå–é»„è‰²æ©ç 
        '''mask_combined = get_combined_color_mask(hsv, YELLOW_COMBINED_KEYS)
        mask_combined = cv2.morphologyEx(mask_combined, cv2.MORPH_OPEN, MORPH_KERNEL)
        mask_combined = cv2.morphologyEx(mask_combined, cv2.MORPH_CLOSE, MORPH_KERNEL)'''
        
        # åªä¿ç•™æœ€å¤§çš„ä¸¤ä¸ªè¿é€šåŸŸ
        num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(mask_combined, connectivity=8)
        clean_mask = np.zeros_like(mask_combined)
        if num_labels > 1:
            areas = stats[1:, cv2.CC_STAT_AREA]
            sorted_idx = np.argsort(areas)[::-1] + 1
            for i in sorted_idx[:min(2, len(sorted_idx))]:
                clean_mask[labels == i] = 255
        mask_combined = clean_mask

        # åˆ›å»ºROIèšç„¦å›¾åƒåº•éƒ¨ (é«˜åº¦1/2åŒºåŸŸ)
        height, width = mask_combined.shape[:2]
        roi_y_start = height - height // 2
        roi_mask = np.zeros_like(mask_combined)
        roi_mask[roi_y_start:, 3 * width // 7:4 * width // 7] = 255
        masked_roi = cv2.bitwise_and(mask_combined, roi_mask)
        # === ä¸“ä¸šæ–¹æ³•ï¼šæ£€æµ‹é»„è‰²è¾¹çº¿çš„å®é™…è¾¹ç•Œ ===
        # 1. æ‰¾åˆ°é»„è‰²åŒºåŸŸçš„è½®å»“
        contour_result = cv2.findContours(mask_combined, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if len(contour_result) == 3:  # OpenCV 3.x
            contours = contour_result[1]
        elif len(contour_result) == 2:  # OpenCV 4.x
            contours = contour_result[0]
        else:
            contours = contour_result
        # 2. æå–æ‰€æœ‰è¾¹ç•Œç‚¹
        boundary_points = []
        
        # 3. å¯¹æ¯ä¸ªè½®å»“ï¼Œæå–å…¶åº•éƒ¨è¾¹ç•Œç‚¹
        for contour in contours:
            # åˆ›å»ºè½®å»“çš„è¾¹ç•Œæ¡†
            x, y, w, h = cv2.boundingRect(contour)
            
            # åªå¤„ç†ROIåŒºåŸŸå†…çš„è½®å»“
            if y + h < roi_y_start:
                continue
            
            # åˆ›å»ºè½®å»“çš„æ©ç 
            contour_mask = np.zeros_like(mask_combined)
            cv2.drawContours(contour_mask, [contour], -1, 255, thickness=cv2.FILLED)
            
            # å¯¹è½®å»“è¿›è¡Œå¤šè¾¹å½¢è¿‘ä¼¼
            epsilon = 0.005 * cv2.arcLength(contour, True)
            approx = cv2.approxPolyDP(contour, epsilon, True)
            
            # æå–è½®å»“çš„åº•éƒ¨è¾¹ç¼˜ç‚¹
            for point in approx.squeeze():
                px, py = point
                # åªè€ƒè™‘ROIåŒºåŸŸå†…çš„ç‚¹
                if py < roi_y_start:
                    continue
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯åº•éƒ¨ç‚¹ï¼šè¯¥ç‚¹ä¸‹æ–¹ä¸æ˜¯é»„è‰²åŒºåŸŸ
                if py < height - 1:
                    if mask_combined[py + 1, px] == 0:  # ä¸‹æ–¹åƒç´ æ˜¯èƒŒæ™¯
                        boundary_points.append([px, py])
        
        # 4. å¦‚æœæ²¡æœ‰è¶³å¤Ÿè¾¹ç•Œç‚¹ï¼Œå°è¯•å¤‡ç”¨æ–¹æ³•
        if len(boundary_points) < 20:
            # å¤‡ç”¨æ–¹æ³•ï¼šé€åˆ—æ‰«æåº•éƒ¨è¾¹ç¼˜
            boundary_points = []
            for x in range(3 * width // 7, 4 * width // 7):
                for y in range(height - 2, roi_y_start - 1, -1):
                    if mask_combined[y, x] == 255 and mask_combined[y + 1, x] == 0:
                        boundary_points.append([x, y])
                        break  # æ‰¾åˆ°è¯¥åˆ—çš„ç¬¬ä¸€ä¸ªè¾¹ç•Œç‚¹å³åœæ­¢
        
        # 5. ä½¿ç”¨RANSACç®—æ³•è¿›è¡Œç¨³å¥ç›´çº¿æ‹Ÿåˆ
        best_line = None
        best_inliers = []
        max_inliers = 0
        
        if len(boundary_points) >= 10:
            points_array = np.array(boundary_points)
            
            # ä½¿ç”¨RANSACå¤šæ¬¡è¿­ä»£å¯»æ‰¾æœ€ä½³æ‹Ÿåˆçº¿
            for _ in range(2):
                # éšæœºé€‰æ‹©ä¸¤ä¸ªç‚¹
                idx = np.random.choice(len(points_array), 2, replace=False)
                p1, p2 = points_array[idx[0]], points_array[idx[1]]
                
                # è®¡ç®—ç›´çº¿å‚æ•°
                dx = p2[0] - p1[0]
                dy = p2[1] - p1[1]
                if dx == 0:  # é¿å…é™¤ä»¥é›¶
                    continue
                    
                # ç›´çº¿æ–¹ç¨‹: y = mx + c
                m = dy / dx
                c = p1[1] - m * p1[0]
                
                # è®¡ç®—æ‰€æœ‰ç‚¹åˆ°ç›´çº¿çš„è·ç¦»
                distances = []
                for point in points_array:
                    px, py = point
                    # ç‚¹åˆ°ç›´çº¿çš„è·ç¦»å…¬å¼
                    dist = abs(m * px - py + c) / np.sqrt(m**2 + 1)
                    distances.append(dist)
                
                # ç»Ÿè®¡å†…ç‚¹ï¼ˆè·ç¦»å°äºé˜ˆå€¼çš„ç‚¹ï¼‰
                inlier_threshold = 2.0  # åƒç´ è·ç¦»é˜ˆå€¼
                inliers = [i for i, dist in enumerate(distances) if dist < inlier_threshold]
                
                if len(inliers) > max_inliers:
                    max_inliers = len(inliers)
                    best_inliers = inliers
                    best_line = (m, c, p1, p2)
        
        current_time = time.time()
        with self._lock:
            self._detected_flags['23'] = False
            self._line_angle = 0.0
            
            if best_line is not None and len(best_inliers) >= 10:
                m, c, p1, p2 = best_line
                
                # ä½¿ç”¨å†…ç‚¹é‡æ–°æ‹Ÿåˆç›´çº¿ï¼ˆæ›´ç²¾ç¡®ï¼‰
                inlier_points = points_array[best_inliers]
                vx, vy, cx, cy = cv2.fitLine(inlier_points, cv2.DIST_L2, 0, 0.01, 0.01)
                
                # è®¡ç®—ç›´çº¿è§’åº¦ï¼ˆç›¸å¯¹äºæ°´å¹³è½´ï¼‰
                line_angle = np.arctan2(vy, vx)[0]
                angle_deg = np.degrees(line_angle)
                target_angle = 0
                angle_diff = angle_deg - target_angle
                
                self._line_angle = np.radians(angle_diff)
                self._detected_flags['23'] = True
                
                # æŒç»­å¯¹é½è®¡æ—¶é€»è¾‘
                if abs(self._line_angle) < self._line_threshold:
                    if self._alignment_start_time == 0:
                        self._alignment_start_time = current_time
                    self._aligned_duration = current_time - self._alignment_start_time
                else:
                    self._alignment_start_time = 0.0
                    self._aligned_duration = 0.0
            else:
                self._alignment_start_time = 0.0
                self._aligned_duration = 0.0
                self._detected_flags['23'] = False

            # è°ƒè¯•å›¾åƒå¤„ç†
            debug_img = cv2.cvtColor(mask_combined, cv2.COLOR_GRAY2BGR)
            cv2.rectangle(debug_img, (0, roi_y_start), (width, height), (255, 0, 0), 2)  # ç»˜åˆ¶ROIåŒºåŸŸ
            
            # ç»˜åˆ¶æ‰€æœ‰è¾¹ç•Œç‚¹
            for point in boundary_points:
                cv2.circle(debug_img, tuple(point), 2, (0, 255, 0), -1)  # ç»¿è‰²ç‚¹è¡¨ç¤ºè¾¹ç•Œç‚¹
            
            # å¦‚æœæ£€æµ‹åˆ°ç›´çº¿ï¼Œç»˜åˆ¶æœ€ä½³æ‹Ÿåˆçº¿å’Œå†…ç‚¹
            if self._detected_flags['23']:
                # ç»˜åˆ¶å†…ç‚¹ï¼ˆè“è‰²ï¼‰
                for idx in best_inliers:
                    point = boundary_points[idx]
                    cv2.circle(debug_img, tuple(point), 3, (255, 0, 0), -1)  # è“è‰²ç‚¹è¡¨ç¤ºå†…ç‚¹
                
                # ç»˜åˆ¶æ‹Ÿåˆç›´çº¿ï¼ˆçº¢è‰²ç²—çº¿ï¼‰
                length = 500
                pt1 = (int(cx - vx * length), int(cy - vy * length))
                pt2 = (int(cx + vx * length), int(cy + vy * length))
                cv2.line(debug_img, pt1, pt2, (0, 0, 255), 3)
                
                # æ˜¾ç¤ºè§’åº¦ä¿¡æ¯
                cv2.putText(debug_img, 
                            f"Points: {len(boundary_points)} | Inliers: {len(best_inliers)} | Angle: {angle_diff:+.1f}\u00B0 | Hold: {self._aligned_duration:.1f}s", 
                            (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            
            # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°åˆé€‚çš„ç›´çº¿
            elif len(boundary_points) >= 10:
                cv2.putText(debug_img, 
                            f"WARNING: No suitable line found ({len(boundary_points)} boundary points)", 
                            (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
            else:
                cv2.putText(debug_img, 
                            f"WARNING: Not enough boundary points ({len(boundary_points)})", 
                            (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
            
            # ç»˜åˆ¶æ‰€æœ‰è½®å»“
            cv2.drawContours(debug_img, contours, -1, (255, 255, 0), 2)  # é’è‰²è½®å»“
            
            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            save_debug_image(f"detect23_{timestamp}.jpg", debug_img)
            
            # å®æ—¶è°ƒè¯•æ˜¾ç¤º
            if self.debug_mode:
                cv2.imshow("Detection Preview", debug_img)
                cv2.waitKey(1)

    def _detect_24(self, cv_image):
        hsv = cv2.cvtColor(cv_image, cv2.COLOR_BGR2HSV)
        height, width = hsv.shape[:2]
        roi_height1 = 50
        roi_height2 = roi_height1 - 20
        x_start = width // 3
        x_end = 2 * width // 3
        roi = hsv[height-roi_height1:height - roi_height2, x_start:x_end]
        
        mask = cv2.inRange(roi, self.lower_yellow, self.upper_yellow)
        kernel = np.ones((3,3), np.uint8)
        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
        
        yellow_ratio = np.count_nonzero(mask) / (roi.size + 1e-5)  # é˜²æ­¢é™¤é›¶
        with self._lock:
            current_time = time.time()
            self._alignment_start_time = 0
            self._aligned_duration = 0.0
            if yellow_ratio > self._state9_threshold:
                '''if current_time - self._last_detection_time < 0.3:
                    self._detected_flags['24'] = True
                else:
                    self._detected_flags['24'] = False  # é‡ç½®çŸ­æš‚æ£€æµ‹'''
                self._detected_flags['24'] = True
                self._last_detection_time = current_time
            else:
                self._detected_flags['24'] = False
        
        debug_img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
        cv2.rectangle(debug_img, 
                    (x_start, height-roi_height1),
                    (x_end, height - roi_height2),
                    (0,255,0), 2)
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        save_debug_image(f"detect24_{timestamp}_{yellow_ratio}.jpg", debug_img)

        if self.debug_mode:
            debug_img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
            cv2.rectangle(debug_img, 
                        (x_start, height-roi_height1),
                        (x_end, height - roi_height2),
                        (0,255,0), 2)
            cv2.imshow("Detection Preview", debug_img)
            cv2.waitKey(1)

    def _detect_26(self, cv_image):
        hsv = cv2.cvtColor(cv_image, cv2.COLOR_BGR2HSV)
        height, width = hsv.shape[:2]
        roi_height1 = height // 2 - 20
        roi_height2 = roi_height1 - 5
        x_start = 13 * width // 14
        x_end = width
        roi = hsv[height-roi_height1:height - roi_height2, x_start:width]
        
        '''mask = cv2.inRange(roi, self.lower_yellow, self.upper_yellow)
        kernel = np.ones((3,3), np.uint8)
        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
        
        yellow_ratio = np.count_nonzero(mask) / (roi.size + 1e-5)  # é˜²æ­¢é™¤é›¶'''
        mask_combined = get_combined_color_mask(roi, YELLOW_COMBINED_KEYS)

        # === 4. å½¢æ€å­¦å»å™ª ===
        mask_combined = cv2.morphologyEx(mask_combined, cv2.MORPH_OPEN, MORPH_KERNEL)
        mask_combined = cv2.morphologyEx(mask_combined, cv2.MORPH_CLOSE, MORPH_KERNEL)

        # === 5. é»„è‰²åƒç´ å æ¯”è®¡ç®— ===
        yellow_ratio = np.count_nonzero(mask_combined) / (mask_combined.size + 1e-5)
        with self._lock:
            current_time = time.time()
            self._alignment_start_time = 0
            self._aligned_duration = 0.0
            if yellow_ratio > 0.15:
                self._detected_flags['26'] = True
                '''if current_time - self._last_detection_time < 0.3:
                    self._detected_flags['26'] = True
                else:
                    self._detected_flags['26'] = False  # é‡ç½®çŸ­æš‚æ£€æµ‹'''
                self._last_detection_time = current_time
            else:
                self._detected_flags['26'] = False

        debug_img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
        cv2.rectangle(debug_img, 
                    (x_start, height-roi_height1),
                    (x_end, height - roi_height2),
                    (0,255,0), 2)
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        save_debug_image(f"detect26_{timestamp}_{yellow_ratio}.jpg", debug_img)

        # è°ƒè¯•æ˜¾ç¤º
        if self.debug_mode:
            debug_img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
            cv2.rectangle(debug_img, 
                        (x_start, height-roi_height1),
                        (x_end, height - roi_height2),
                        (0,255,0), 2)
            cv2.imshow("Detection Preview", debug_img)
            cv2.waitKey(1)
    
    def _detect_27(self, cv_image):
        # é¢„å¤„ç†
        blurred = cv2.GaussianBlur(cv_image, (5, 5), 0)
        hsv = cv2.cvtColor(blurred, cv2.COLOR_BGR2HSV)

        # ä½¿ç”¨é…ç½®æ¨¡å—æå–é»„è‰²æ©ç 
        mask_combined = get_combined_color_mask(hsv, YELLOW_COMBINED_KEYS)
        mask_combined = cv2.morphologyEx(mask_combined, cv2.MORPH_OPEN, MORPH_KERNEL)
        mask_combined = cv2.morphologyEx(mask_combined, cv2.MORPH_CLOSE, MORPH_KERNEL)
        
        # åªä¿ç•™æœ€å¤§çš„ä¸¤ä¸ªè¿é€šåŸŸ
        num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(mask_combined, connectivity=8)
        clean_mask = np.zeros_like(mask_combined)
        if num_labels > 1:
            areas = stats[1:, cv2.CC_STAT_AREA]
            sorted_idx = np.argsort(areas)[::-1] + 1
            for i in sorted_idx[:min(2, len(sorted_idx))]:
                clean_mask[labels == i] = 255
        mask_combined = clean_mask

        # åˆ›å»ºROIèšç„¦å›¾åƒåº•éƒ¨ (é«˜åº¦1/2åŒºåŸŸ)
        height, width = mask_combined.shape[:2]
        roi_y_start = height - height // 2
        roi_mask = np.zeros_like(mask_combined)
        roi_mask[roi_y_start:, :] = 255
        masked_roi = cv2.bitwise_and(mask_combined, roi_mask)

        # === ä¸“ä¸šæ–¹æ³•ï¼šæ£€æµ‹é»„è‰²è¾¹çº¿çš„å®é™…è¾¹ç•Œ ===
        # 1. æ‰¾åˆ°é»„è‰²åŒºåŸŸçš„è½®å»“
        contour_result = cv2.findContours(mask_combined, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if len(contour_result) == 3:  # OpenCV 3.x
            contours = contour_result[1]
        elif len(contour_result) == 2:  # OpenCV 4.x
            contours = contour_result[0]
        else:
            contours = contour_result
        # 2. æå–æ‰€æœ‰è¾¹ç•Œç‚¹
        boundary_points = []
        
        # 3. å¯¹æ¯ä¸ªè½®å»“ï¼Œæå–å…¶åº•éƒ¨è¾¹ç•Œç‚¹
        for contour in contours:
            # åˆ›å»ºè½®å»“çš„è¾¹ç•Œæ¡†
            x, y, w, h = cv2.boundingRect(contour)
            
            # åªå¤„ç†ROIåŒºåŸŸå†…çš„è½®å»“
            if y + h < roi_y_start:
                continue
            
            # åˆ›å»ºè½®å»“çš„æ©ç 
            contour_mask = np.zeros_like(mask_combined)
            cv2.drawContours(contour_mask, [contour], -1, 255, thickness=cv2.FILLED)
            
            # å¯¹è½®å»“è¿›è¡Œå¤šè¾¹å½¢è¿‘ä¼¼
            epsilon = 0.005 * cv2.arcLength(contour, True)
            approx = cv2.approxPolyDP(contour, epsilon, True)
            
            # æå–è½®å»“çš„åº•éƒ¨è¾¹ç¼˜ç‚¹
            for point in approx.squeeze():
                px, py = point
                # åªè€ƒè™‘ROIåŒºåŸŸå†…çš„ç‚¹
                if py < roi_y_start:
                    continue
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯åº•éƒ¨ç‚¹ï¼šè¯¥ç‚¹ä¸‹æ–¹ä¸æ˜¯é»„è‰²åŒºåŸŸ
                if py < height - 1:
                    if mask_combined[py + 1, px] == 0:  # ä¸‹æ–¹åƒç´ æ˜¯èƒŒæ™¯
                        boundary_points.append([px, py])
        
        # 4. å¦‚æœæ²¡æœ‰è¶³å¤Ÿè¾¹ç•Œç‚¹ï¼Œå°è¯•å¤‡ç”¨æ–¹æ³•
        if len(boundary_points) < 20:
            # å¤‡ç”¨æ–¹æ³•ï¼šé€åˆ—æ‰«æåº•éƒ¨è¾¹ç¼˜
            boundary_points = []
            for x in range(width):
                for y in range(height - 2, roi_y_start - 1, -1):
                    if mask_combined[y, x] == 255 and mask_combined[y + 1, x] == 0:
                        boundary_points.append([x, y])
                        break  # æ‰¾åˆ°è¯¥åˆ—çš„ç¬¬ä¸€ä¸ªè¾¹ç•Œç‚¹å³åœæ­¢
        
        # 5. ä½¿ç”¨RANSACç®—æ³•è¿›è¡Œç¨³å¥ç›´çº¿æ‹Ÿåˆ
        best_line = None
        best_inliers = []
        max_inliers = 0
        
        if len(boundary_points) >= 10:
            points_array = np.array(boundary_points)
            
            # ä½¿ç”¨RANSACå¤šæ¬¡è¿­ä»£å¯»æ‰¾æœ€ä½³æ‹Ÿåˆçº¿
            for _ in range(2):
                # éšæœºé€‰æ‹©ä¸¤ä¸ªç‚¹
                idx = np.random.choice(len(points_array), 2, replace=False)
                p1, p2 = points_array[idx[0]], points_array[idx[1]]
                
                # è®¡ç®—ç›´çº¿å‚æ•°
                dx = p2[0] - p1[0]
                dy = p2[1] - p1[1]
                if dx == 0:  # é¿å…é™¤ä»¥é›¶
                    continue
                    
                # ç›´çº¿æ–¹ç¨‹: y = mx + c
                m = dy / dx
                c = p1[1] - m * p1[0]
                
                # è®¡ç®—æ‰€æœ‰ç‚¹åˆ°ç›´çº¿çš„è·ç¦»
                distances = []
                for point in points_array:
                    px, py = point
                    # ç‚¹åˆ°ç›´çº¿çš„è·ç¦»å…¬å¼
                    dist = abs(m * px - py + c) / np.sqrt(m**2 + 1)
                    distances.append(dist)
                
                # ç»Ÿè®¡å†…ç‚¹ï¼ˆè·ç¦»å°äºé˜ˆå€¼çš„ç‚¹ï¼‰
                inlier_threshold = 2.0  # åƒç´ è·ç¦»é˜ˆå€¼
                inliers = [i for i, dist in enumerate(distances) if dist < inlier_threshold]
                
                if len(inliers) > max_inliers:
                    max_inliers = len(inliers)
                    best_inliers = inliers
                    best_line = (m, c, p1, p2)
        
        current_time = time.time()
        with self._lock:
            self._detected_flags['27'] = False
            self._line_angle = 0.0
            
            if best_line is not None and len(best_inliers) >= 10:
                m, c, p1, p2 = best_line
                
                # ä½¿ç”¨å†…ç‚¹é‡æ–°æ‹Ÿåˆç›´çº¿ï¼ˆæ›´ç²¾ç¡®ï¼‰
                inlier_points = points_array[best_inliers]
                vx, vy, cx, cy = cv2.fitLine(inlier_points, cv2.DIST_L2, 0, 0.01, 0.01)
                
                # è®¡ç®—ç›´çº¿è§’åº¦ï¼ˆç›¸å¯¹äºæ°´å¹³è½´ï¼‰
                line_angle = np.arctan2(vy, vx)[0]
                angle_deg = np.degrees(line_angle)
                target_angle = 0
                angle_diff = angle_deg - target_angle
                
                self._line_angle = np.radians(angle_diff)
                self._detected_flags['27'] = True
                
                # æŒç»­å¯¹é½è®¡æ—¶é€»è¾‘
                if abs(self._line_angle) < self._line_threshold:
                    if self._alignment_start_time == 0:
                        self._alignment_start_time = current_time
                    self._aligned_duration = current_time - self._alignment_start_time
                else:
                    self._alignment_start_time = 0.0
                    self._aligned_duration = 0.0
            else:
                self._alignment_start_time = 0.0
                self._aligned_duration = 0.0
                self._detected_flags['27'] = False

            # è°ƒè¯•å›¾åƒå¤„ç†
            debug_img = cv2.cvtColor(mask_combined, cv2.COLOR_GRAY2BGR)
            cv2.rectangle(debug_img, (0, roi_y_start), (width, height), (255, 0, 0), 2)  # ç»˜åˆ¶ROIåŒºåŸŸ
            
            # ç»˜åˆ¶æ‰€æœ‰è¾¹ç•Œç‚¹
            for point in boundary_points:
                cv2.circle(debug_img, tuple(point), 2, (0, 255, 0), -1)  # ç»¿è‰²ç‚¹è¡¨ç¤ºè¾¹ç•Œç‚¹
            
            # å¦‚æœæ£€æµ‹åˆ°ç›´çº¿ï¼Œç»˜åˆ¶æœ€ä½³æ‹Ÿåˆçº¿å’Œå†…ç‚¹
            if self._detected_flags['27']:
                # ç»˜åˆ¶å†…ç‚¹ï¼ˆè“è‰²ï¼‰
                for idx in best_inliers:
                    point = boundary_points[idx]
                    cv2.circle(debug_img, tuple(point), 3, (255, 0, 0), -1)  # è“è‰²ç‚¹è¡¨ç¤ºå†…ç‚¹
                
                # ç»˜åˆ¶æ‹Ÿåˆç›´çº¿ï¼ˆçº¢è‰²ç²—çº¿ï¼‰
                length = 500
                pt1 = (int(cx - vx * length), int(cy - vy * length))
                pt2 = (int(cx + vx * length), int(cy + vy * length))
                cv2.line(debug_img, pt1, pt2, (0, 0, 255), 3)
                
                # æ˜¾ç¤ºè§’åº¦ä¿¡æ¯
                cv2.putText(debug_img, 
                            f"Points: {len(boundary_points)} | Inliers: {len(best_inliers)} | Angle: {angle_diff:+.1f}\u00B0 | Hold: {self._aligned_duration:.1f}s", 
                            (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            
            # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°åˆé€‚çš„ç›´çº¿
            elif len(boundary_points) >= 10:
                cv2.putText(debug_img, 
                            f"WARNING: No suitable line found ({len(boundary_points)} boundary points)", 
                            (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
            else:
                cv2.putText(debug_img, 
                            f"WARNING: Not enough boundary points ({len(boundary_points)})", 
                            (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
            
            # ç»˜åˆ¶æ‰€æœ‰è½®å»“
            cv2.drawContours(debug_img, contours, -1, (255, 255, 0), 2)  # é’è‰²è½®å»“
            
            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            save_debug_image(f"detect27_{timestamp}.jpg", debug_img)
            
            # å®æ—¶è°ƒè¯•æ˜¾ç¤º
            if self.debug_mode:
                cv2.imshow("Detection Preview", debug_img)
                cv2.waitKey(1)
    
    def _detect_28(self, cv_image):
        hsv = cv2.cvtColor(cv_image, cv2.COLOR_BGR2HSV)
        height, width = hsv.shape[:2]
        roi_height1 = height // 7
        roi_height2 = roi_height1 - 20
        x_start = width // 3
        x_end = 2 * width // 3
        roi = hsv[height-roi_height1:height - roi_height2, x_start:x_end]
        
        mask = cv2.inRange(roi, self.lower_yellow, self.upper_yellow)
        kernel = np.ones((3,3), np.uint8)
        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
        
        yellow_ratio = np.count_nonzero(mask) / (roi.size + 1e-5)  # é˜²æ­¢é™¤é›¶
        with self._lock:
            current_time = time.time()
            self._alignment_start_time = 0
            self._aligned_duration = 0.0
            if yellow_ratio > self.detection_threshold:
                self._detected_flags['28'] = True
                '''if current_time - self._last_detection_time < 0.5:
                    self._detected_flags['28'] = True
                else:
                    self._detected_flags['28'] = False  # é‡ç½®çŸ­æš‚æ£€æµ‹'''
                self._last_detection_time = current_time
            else:
                self._detected_flags['28'] = False

        debug_img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
        cv2.rectangle(debug_img, 
                    (x_start, height-roi_height1),
                    (x_end, height - roi_height2),
                    (0,255,0), 2)
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        save_debug_image(f"detect28_{timestamp}_{yellow_ratio}.jpg", debug_img)

        # è°ƒè¯•æ˜¾ç¤º
        if self.debug_mode:
            debug_img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
            cv2.rectangle(debug_img, 
                        (x_start, height-roi_height1),
                        (x_end, height - roi_height2),
                        (0,255,0), 2)
            cv2.imshow("Detection Preview", debug_img)
            cv2.waitKey(1)

    def _detect_29(self, cv_image):
        # é¢„å¤„ç†
        blurred = cv2.GaussianBlur(cv_image, (5, 5), 0)
        hsv = cv2.cvtColor(blurred, cv2.COLOR_BGR2HSV)

        # !!!!!!!!!
        mask = cv2.inRange(hsv, self.lower_yellow, self.upper_yellow)
        kernel = np.ones((3,3), np.uint8)
        mask_combined = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
        

        # ä½¿ç”¨é…ç½®æ¨¡å—æå–é»„è‰²æ©ç 
        '''mask_combined = get_combined_color_mask(hsv, YELLOW_COMBINED_KEYS)
        mask_combined = cv2.morphologyEx(mask_combined, cv2.MORPH_OPEN, MORPH_KERNEL)
        mask_combined = cv2.morphologyEx(mask_combined, cv2.MORPH_CLOSE, MORPH_KERNEL)'''
        
        # åªä¿ç•™æœ€å¤§çš„ä¸¤ä¸ªè¿é€šåŸŸ
        num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(mask_combined, connectivity=8)
        clean_mask = np.zeros_like(mask_combined)
        if num_labels > 1:
            areas = stats[1:, cv2.CC_STAT_AREA]
            sorted_idx = np.argsort(areas)[::-1] + 1
            for i in sorted_idx[:min(2, len(sorted_idx))]:
                clean_mask[labels == i] = 255
        mask_combined = clean_mask

        # åˆ›å»ºROIèšç„¦å›¾åƒåº•éƒ¨ (é«˜åº¦1/2åŒºåŸŸ)
        height, width = mask_combined.shape[:2]
        roi_y_start = height - height // 2
        roi_mask = np.zeros_like(mask_combined)
        roi_mask[roi_y_start:, 3 * width // 7:4 * width // 7] = 255
        masked_roi = cv2.bitwise_and(mask_combined, roi_mask)

        # === ä¸“ä¸šæ–¹æ³•ï¼šæ£€æµ‹é»„è‰²è¾¹çº¿çš„å®é™…è¾¹ç•Œ ===
        # 1. æ‰¾åˆ°é»„è‰²åŒºåŸŸçš„è½®å»“
        contour_result = cv2.findContours(mask_combined, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if len(contour_result) == 3:  # OpenCV 3.x
            contours = contour_result[1]
        elif len(contour_result) == 2:  # OpenCV 4.x
            contours = contour_result[0]
        else:
            contours = contour_result
        # 2. æå–æ‰€æœ‰è¾¹ç•Œç‚¹
        boundary_points = []
        
        # 3. å¯¹æ¯ä¸ªè½®å»“ï¼Œæå–å…¶åº•éƒ¨è¾¹ç•Œç‚¹
        for contour in contours:
            # åˆ›å»ºè½®å»“çš„è¾¹ç•Œæ¡†
            x, y, w, h = cv2.boundingRect(contour)
            
            # åªå¤„ç†ROIåŒºåŸŸå†…çš„è½®å»“
            if y + h < roi_y_start:
                continue
            
            # åˆ›å»ºè½®å»“çš„æ©ç 
            contour_mask = np.zeros_like(mask_combined)
            cv2.drawContours(contour_mask, [contour], -1, 255, thickness=cv2.FILLED)
            
            # å¯¹è½®å»“è¿›è¡Œå¤šè¾¹å½¢è¿‘ä¼¼
            epsilon = 0.005 * cv2.arcLength(contour, True)
            approx = cv2.approxPolyDP(contour, epsilon, True)
            
            # æå–è½®å»“çš„åº•éƒ¨è¾¹ç¼˜ç‚¹
            for point in approx.squeeze():
                px, py = point
                # åªè€ƒè™‘ROIåŒºåŸŸå†…çš„ç‚¹
                if py < roi_y_start:
                    continue
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯åº•éƒ¨ç‚¹ï¼šè¯¥ç‚¹ä¸‹æ–¹ä¸æ˜¯é»„è‰²åŒºåŸŸ
                if py < height - 1:
                    if mask_combined[py + 1, px] == 0:  # ä¸‹æ–¹åƒç´ æ˜¯èƒŒæ™¯
                        boundary_points.append([px, py])
        
        # 4. å¦‚æœæ²¡æœ‰è¶³å¤Ÿè¾¹ç•Œç‚¹ï¼Œå°è¯•å¤‡ç”¨æ–¹æ³•
        if len(boundary_points) < 10:
            # å¤‡ç”¨æ–¹æ³•ï¼šé€åˆ—æ‰«æåº•éƒ¨è¾¹ç¼˜
            boundary_points = []
            for x in range(3 * width // 8, 5 * width // 8):
                for y in range(height - 2, roi_y_start - 1, -1):
                    if mask_combined[y, x] == 255 and mask_combined[y + 1, x] == 0:
                        boundary_points.append([x, y])
                        break  # æ‰¾åˆ°è¯¥åˆ—çš„ç¬¬ä¸€ä¸ªè¾¹ç•Œç‚¹å³åœæ­¢
        
        # 5. ä½¿ç”¨RANSACç®—æ³•è¿›è¡Œç¨³å¥ç›´çº¿æ‹Ÿåˆ
        best_line = None
        best_inliers = []
        max_inliers = 0
        
        if len(boundary_points) >= 10:
            points_array = np.array(boundary_points)
            
            # ä½¿ç”¨RANSACå¤šæ¬¡è¿­ä»£å¯»æ‰¾æœ€ä½³æ‹Ÿåˆçº¿
            for _ in range(2):
                # éšæœºé€‰æ‹©ä¸¤ä¸ªç‚¹
                idx = np.random.choice(len(points_array), 2, replace=False)
                p1, p2 = points_array[idx[0]], points_array[idx[1]]
                
                # è®¡ç®—ç›´çº¿å‚æ•°
                dx = p2[0] - p1[0]
                dy = p2[1] - p1[1]
                if dx == 0:  # é¿å…é™¤ä»¥é›¶
                    continue
                    
                # ç›´çº¿æ–¹ç¨‹: y = mx + c
                m = dy / dx
                c = p1[1] - m * p1[0]
                
                # è®¡ç®—æ‰€æœ‰ç‚¹åˆ°ç›´çº¿çš„è·ç¦»
                distances = []
                for point in points_array:
                    px, py = point
                    # ç‚¹åˆ°ç›´çº¿çš„è·ç¦»å…¬å¼
                    dist = abs(m * px - py + c) / np.sqrt(m**2 + 1)
                    distances.append(dist)
                
                # ç»Ÿè®¡å†…ç‚¹ï¼ˆè·ç¦»å°äºé˜ˆå€¼çš„ç‚¹ï¼‰
                inlier_threshold = 6.0  # åƒç´ è·ç¦»é˜ˆå€¼
                inliers = [i for i, dist in enumerate(distances) if dist < inlier_threshold]
                
                if len(inliers) > max_inliers:
                    max_inliers = len(inliers)
                    best_inliers = inliers
                    best_line = (m, c, p1, p2)
        
        current_time = time.time()
        with self._lock:
            self._detected_flags['29'] = False
            self._line_angle = 0.0
            
            if best_line is not None and len(best_inliers) >= 10:
                m, c, p1, p2 = best_line
                
                # ä½¿ç”¨å†…ç‚¹é‡æ–°æ‹Ÿåˆç›´çº¿ï¼ˆæ›´ç²¾ç¡®ï¼‰
                inlier_points = points_array[best_inliers]
                vx, vy, cx, cy = cv2.fitLine(inlier_points, cv2.DIST_L2, 0, 0.01, 0.01)
                
                # è®¡ç®—ç›´çº¿è§’åº¦ï¼ˆç›¸å¯¹äºæ°´å¹³è½´ï¼‰
                line_angle = np.arctan2(vy, vx)[0]
                angle_deg = np.degrees(line_angle)
                target_angle = 0
                angle_diff = angle_deg - target_angle
                
                self._line_angle = np.radians(angle_diff)
                self._detected_flags['29'] = True
                
                # æŒç»­å¯¹é½è®¡æ—¶é€»è¾‘
                if abs(self._line_angle) < 0.05:
                    if self._alignment_start_time == 0:
                        self._alignment_start_time = current_time
                    self._aligned_duration = current_time - self._alignment_start_time
                else:
                    self._alignment_start_time = 0.0
                    self._aligned_duration = 0.0
            else:
                self._alignment_start_time = 0.0
                self._aligned_duration = 0.0
                self._detected_flags['29'] = False

            # è°ƒè¯•å›¾åƒå¤„ç†
            debug_img = cv2.cvtColor(mask_combined, cv2.COLOR_GRAY2BGR)
            cv2.rectangle(debug_img, (0, roi_y_start), (width, height), (255, 0, 0), 2)  # ç»˜åˆ¶ROIåŒºåŸŸ
            
            # ç»˜åˆ¶æ‰€æœ‰è¾¹ç•Œç‚¹
            for point in boundary_points:
                cv2.circle(debug_img, tuple(point), 2, (0, 255, 0), -1)  # ç»¿è‰²ç‚¹è¡¨ç¤ºè¾¹ç•Œç‚¹
            
            # å¦‚æœæ£€æµ‹åˆ°ç›´çº¿ï¼Œç»˜åˆ¶æœ€ä½³æ‹Ÿåˆçº¿å’Œå†…ç‚¹
            if self._detected_flags['29']:
                # ç»˜åˆ¶å†…ç‚¹ï¼ˆè“è‰²ï¼‰
                for idx in best_inliers:
                    point = boundary_points[idx]
                    cv2.circle(debug_img, tuple(point), 3, (255, 0, 0), -1)  # è“è‰²ç‚¹è¡¨ç¤ºå†…ç‚¹
                
                # ç»˜åˆ¶æ‹Ÿåˆç›´çº¿ï¼ˆçº¢è‰²ç²—çº¿ï¼‰
                length = 500
                pt1 = (int(cx - vx * length), int(cy - vy * length))
                pt2 = (int(cx + vx * length), int(cy + vy * length))
                cv2.line(debug_img, pt1, pt2, (0, 0, 255), 3)
                
                # æ˜¾ç¤ºè§’åº¦ä¿¡æ¯
                cv2.putText(debug_img, 
                            f"Points: {len(boundary_points)} | Inliers: {len(best_inliers)} | Angle: {angle_diff:+.1f}\u00B0 | Hold: {self._aligned_duration:.1f}s", 
                            (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            
            # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°åˆé€‚çš„ç›´çº¿
            elif len(boundary_points) >= 10:
                cv2.putText(debug_img, 
                            f"WARNING: No suitable line found ({len(boundary_points)} boundary points)", 
                            (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
            else:
                cv2.putText(debug_img, 
                            f"WARNING: Not enough boundary points ({len(boundary_points)})", 
                            (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
            
            # ç»˜åˆ¶æ‰€æœ‰è½®å»“
            cv2.drawContours(debug_img, contours, -1, (255, 255, 0), 2)  # é’è‰²è½®å»“
            
            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            save_debug_image(f"detect29_{timestamp}.jpg", debug_img)
            
            # å®æ—¶è°ƒè¯•æ˜¾ç¤º
            if self.debug_mode:
                cv2.imshow("Detection Preview", debug_img)
                cv2.waitKey(1)

    def _detect_30(self, cv_image):
        hsv = cv2.cvtColor(cv_image, cv2.COLOR_BGR2HSV)
        height, width = hsv.shape[:2]
        roi_height1 = 50
        roi_height2 = roi_height1 - 20
        x_start = width // 3
        x_end = 2 * width // 3
        roi = hsv[height-roi_height1:height - roi_height2, x_start:x_end]
        
        mask = cv2.inRange(roi, self.lower_yellow, self.upper_yellow)
        kernel = np.ones((3,3), np.uint8)
        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
        
        yellow_ratio = np.count_nonzero(mask) / (roi.size + 1e-5)  # é˜²æ­¢é™¤é›¶
        with self._lock:
            current_time = time.time()
            self._alignment_start_time = 0
            self._aligned_duration = 0.0
            if yellow_ratio > self._state9_threshold:
                self._detected_flags['30'] = True
                '''if current_time - self._last_detection_time < 0.3:
                    self._detected_flags['30'] = True
                else:
                    self._detected_flags['30'] = False  # é‡ç½®çŸ­æš‚æ£€æµ‹'''
                self._last_detection_time = current_time
            else:
                self._detected_flags['30'] = False

        debug_img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
        cv2.rectangle(debug_img, 
                    (x_start, height-roi_height1),
                    (x_end, height - roi_height2),
                    (0,255,0), 2)
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        save_debug_image(f"detect30_{timestamp}_{yellow_ratio}.jpg", debug_img)

        if self.debug_mode:
            debug_img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
            cv2.rectangle(debug_img, 
                        (x_start, height-roi_height1),
                        (x_end, height - roi_height2),
                        (0,255,0), 2)
            cv2.imshow("Detection Preview", debug_img)
            cv2.waitKey(1)
    
    def _detect_32(self, cv_image):
        hsv = cv2.cvtColor(cv_image, cv2.COLOR_BGR2HSV)
        height, width = hsv.shape[:2]
        roi_height1 = height // 2 - 20
        roi_height2 = roi_height1 - 5
        x_start = width // 20
        x_end = width // 12
        roi = hsv[height-roi_height1:height - roi_height2, x_start:width]
        
        '''mask = cv2.inRange(roi, self.lower_yellow, self.upper_yellow)
        kernel = np.ones((3,3), np.uint8)
        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
        
        yellow_ratio = np.count_nonzero(mask) / (roi.size + 1e-5)  # é˜²æ­¢é™¤é›¶'''
        mask_combined = get_combined_color_mask(roi, YELLOW_COMBINED_KEYS)

        # === 4. å½¢æ€å­¦å»å™ª ===
        mask_combined = cv2.morphologyEx(mask_combined, cv2.MORPH_OPEN, MORPH_KERNEL)
        mask_combined = cv2.morphologyEx(mask_combined, cv2.MORPH_CLOSE, MORPH_KERNEL)

        # === 5. é»„è‰²åƒç´ å æ¯”è®¡ç®— ===
        yellow_ratio = np.count_nonzero(mask_combined) / (mask_combined.size + 1e-5)
        with self._lock:
            current_time = time.time()
            if yellow_ratio > 0.15:
                '''if current_time - self._last_detection_time < 0.2:
                    self._detected_flags['32'] = True
                else:
                    self._detected_flags['32'] = False  # é‡ç½®çŸ­æš‚æ£€æµ‹'''
                self._detected_flags['32'] = True
                self._last_detection_time = current_time
            else:
                self._detected_flags['32'] = False

        debug_img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
        cv2.rectangle(debug_img, 
                    (x_start, height-roi_height1),
                    (x_end, height - roi_height2),
                    (0,255,0), 2)
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        save_debug_image(f"detect32_{timestamp}_{yellow_ratio}.jpg", debug_img)

        # è°ƒè¯•æ˜¾ç¤º
        if self.debug_mode:
            debug_img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
            cv2.rectangle(debug_img, 
                        (x_start, height-roi_height1),
                        (x_end, height - roi_height2),
                        (0,255,0), 2)
            cv2.imshow("Detection Preview", debug_img)
            cv2.waitKey(1)

    
    def _detect_33(self, cv_image):
        # é¢„å¤„ç†
        blurred = cv2.GaussianBlur(cv_image, (5, 5), 0)
        hsv = cv2.cvtColor(blurred, cv2.COLOR_BGR2HSV)

        # ä½¿ç”¨é…ç½®æ¨¡å—æå–é»„è‰²æ©ç 
        mask_combined = get_combined_color_mask(hsv, YELLOW_COMBINED_KEYS)
        mask_combined = cv2.morphologyEx(mask_combined, cv2.MORPH_OPEN, MORPH_KERNEL)
        mask_combined = cv2.morphologyEx(mask_combined, cv2.MORPH_CLOSE, MORPH_KERNEL)
        
        # åªä¿ç•™æœ€å¤§çš„ä¸¤ä¸ªè¿é€šåŸŸ
        num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(mask_combined, connectivity=8)
        clean_mask = np.zeros_like(mask_combined)
        if num_labels > 1:
            areas = stats[1:, cv2.CC_STAT_AREA]
            sorted_idx = np.argsort(areas)[::-1] + 1
            for i in sorted_idx[:min(2, len(sorted_idx))]:
                clean_mask[labels == i] = 255
        mask_combined = clean_mask

        # åˆ›å»ºROIèšç„¦å›¾åƒåº•éƒ¨ (é«˜åº¦1/2åŒºåŸŸ)
        height, width = mask_combined.shape[:2]
        roi_y_start = height - height // 2
        roi_mask = np.zeros_like(mask_combined)
        roi_mask[roi_y_start:, :] = 255
        masked_roi = cv2.bitwise_and(mask_combined, roi_mask)

        # === ä¸“ä¸šæ–¹æ³•ï¼šæ£€æµ‹é»„è‰²è¾¹çº¿çš„å®é™…è¾¹ç•Œ ===
        # 1. æ‰¾åˆ°é»„è‰²åŒºåŸŸçš„è½®å»“
        contour_result = cv2.findContours(mask_combined, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if len(contour_result) == 3:  # OpenCV 3.x
            contours = contour_result[1]
        elif len(contour_result) == 2:  # OpenCV 4.x
            contours = contour_result[0]
        else:
            contours = contour_result
        # 2. æå–æ‰€æœ‰è¾¹ç•Œç‚¹
        boundary_points = []
        
        # 3. å¯¹æ¯ä¸ªè½®å»“ï¼Œæå–å…¶åº•éƒ¨è¾¹ç•Œç‚¹
        for contour in contours:
            # åˆ›å»ºè½®å»“çš„è¾¹ç•Œæ¡†
            x, y, w, h = cv2.boundingRect(contour)
            
            # åªå¤„ç†ROIåŒºåŸŸå†…çš„è½®å»“
            if y + h < roi_y_start:
                continue
            
            # åˆ›å»ºè½®å»“çš„æ©ç 
            contour_mask = np.zeros_like(mask_combined)
            cv2.drawContours(contour_mask, [contour], -1, 255, thickness=cv2.FILLED)
            
            # å¯¹è½®å»“è¿›è¡Œå¤šè¾¹å½¢è¿‘ä¼¼
            epsilon = 0.005 * cv2.arcLength(contour, True)
            approx = cv2.approxPolyDP(contour, epsilon, True)
            
            # æå–è½®å»“çš„åº•éƒ¨è¾¹ç¼˜ç‚¹
            for point in approx.squeeze():
                px, py = point
                # åªè€ƒè™‘ROIåŒºåŸŸå†…çš„ç‚¹
                if py < roi_y_start:
                    continue
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯åº•éƒ¨ç‚¹ï¼šè¯¥ç‚¹ä¸‹æ–¹ä¸æ˜¯é»„è‰²åŒºåŸŸ
                if py < height - 1:
                    if mask_combined[py + 1, px] == 0:  # ä¸‹æ–¹åƒç´ æ˜¯èƒŒæ™¯
                        boundary_points.append([px, py])
        
        # 4. å¦‚æœæ²¡æœ‰è¶³å¤Ÿè¾¹ç•Œç‚¹ï¼Œå°è¯•å¤‡ç”¨æ–¹æ³•
        if len(boundary_points) < 20:
            # å¤‡ç”¨æ–¹æ³•ï¼šé€åˆ—æ‰«æåº•éƒ¨è¾¹ç¼˜
            boundary_points = []
            for x in range(width):
                for y in range(height - 2, roi_y_start - 1, -1):
                    if mask_combined[y, x] == 255 and mask_combined[y + 1, x] == 0:
                        boundary_points.append([x, y])
                        break  # æ‰¾åˆ°è¯¥åˆ—çš„ç¬¬ä¸€ä¸ªè¾¹ç•Œç‚¹å³åœæ­¢
        
        # 5. ä½¿ç”¨RANSACç®—æ³•è¿›è¡Œç¨³å¥ç›´çº¿æ‹Ÿåˆ
        best_line = None
        best_inliers = []
        max_inliers = 0
        
        if len(boundary_points) >= 10:
            points_array = np.array(boundary_points)
            
            # ä½¿ç”¨RANSACå¤šæ¬¡è¿­ä»£å¯»æ‰¾æœ€ä½³æ‹Ÿåˆçº¿
            for _ in range(2):
                # éšæœºé€‰æ‹©ä¸¤ä¸ªç‚¹
                idx = np.random.choice(len(points_array), 2, replace=False)
                p1, p2 = points_array[idx[0]], points_array[idx[1]]
                
                # è®¡ç®—ç›´çº¿å‚æ•°
                dx = p2[0] - p1[0]
                dy = p2[1] - p1[1]
                if dx == 0:  # é¿å…é™¤ä»¥é›¶
                    continue
                    
                # ç›´çº¿æ–¹ç¨‹: y = mx + c
                m = dy / dx
                c = p1[1] - m * p1[0]
                
                # è®¡ç®—æ‰€æœ‰ç‚¹åˆ°ç›´çº¿çš„è·ç¦»
                distances = []
                for point in points_array:
                    px, py = point
                    # ç‚¹åˆ°ç›´çº¿çš„è·ç¦»å…¬å¼
                    dist = abs(m * px - py + c) / np.sqrt(m**2 + 1)
                    distances.append(dist)
                
                # ç»Ÿè®¡å†…ç‚¹ï¼ˆè·ç¦»å°äºé˜ˆå€¼çš„ç‚¹ï¼‰
                inlier_threshold = 2.0  # åƒç´ è·ç¦»é˜ˆå€¼
                inliers = [i for i, dist in enumerate(distances) if dist < inlier_threshold]
                
                if len(inliers) > max_inliers:
                    max_inliers = len(inliers)
                    best_inliers = inliers
                    best_line = (m, c, p1, p2)
        
        current_time = time.time()
        with self._lock:
            self._detected_flags['33'] = False
            self._line_angle = 0.0
            
            if best_line is not None and len(best_inliers) >= 10:
                m, c, p1, p2 = best_line
                
                # ä½¿ç”¨å†…ç‚¹é‡æ–°æ‹Ÿåˆç›´çº¿ï¼ˆæ›´ç²¾ç¡®ï¼‰
                inlier_points = points_array[best_inliers]
                vx, vy, cx, cy = cv2.fitLine(inlier_points, cv2.DIST_L2, 0, 0.01, 0.01)
                
                # è®¡ç®—ç›´çº¿è§’åº¦ï¼ˆç›¸å¯¹äºæ°´å¹³è½´ï¼‰
                line_angle = np.arctan2(vy, vx)[0]
                angle_deg = np.degrees(line_angle)
                target_angle = 0
                angle_diff = angle_deg - target_angle
                
                self._line_angle = np.radians(angle_diff)
                self._detected_flags['33'] = True
                
                # æŒç»­å¯¹é½è®¡æ—¶é€»è¾‘
                if abs(self._line_angle) < self._line_threshold:
                    if self._alignment_start_time == 0:
                        self._alignment_start_time = current_time
                    self._aligned_duration = current_time - self._alignment_start_time
                else:
                    self._alignment_start_time = 0.0
                    self._aligned_duration = 0.0
            else:
                self._alignment_start_time = 0.0
                self._aligned_duration = 0.0
                self._detected_flags['33'] = False

            # è°ƒè¯•å›¾åƒå¤„ç†
            debug_img = cv2.cvtColor(mask_combined, cv2.COLOR_GRAY2BGR)
            cv2.rectangle(debug_img, (0, roi_y_start), (width, height), (255, 0, 0), 2)  # ç»˜åˆ¶ROIåŒºåŸŸ
            
            # ç»˜åˆ¶æ‰€æœ‰è¾¹ç•Œç‚¹
            for point in boundary_points:
                cv2.circle(debug_img, tuple(point), 2, (0, 255, 0), -1)  # ç»¿è‰²ç‚¹è¡¨ç¤ºè¾¹ç•Œç‚¹
            
            # å¦‚æœæ£€æµ‹åˆ°ç›´çº¿ï¼Œç»˜åˆ¶æœ€ä½³æ‹Ÿåˆçº¿å’Œå†…ç‚¹
            if self._detected_flags['33']:
                # ç»˜åˆ¶å†…ç‚¹ï¼ˆè“è‰²ï¼‰
                for idx in best_inliers:
                    point = boundary_points[idx]
                    cv2.circle(debug_img, tuple(point), 3, (255, 0, 0), -1)  # è“è‰²ç‚¹è¡¨ç¤ºå†…ç‚¹
                
                # ç»˜åˆ¶æ‹Ÿåˆç›´çº¿ï¼ˆçº¢è‰²ç²—çº¿ï¼‰
                length = 500
                pt1 = (int(cx - vx * length), int(cy - vy * length))
                pt2 = (int(cx + vx * length), int(cy + vy * length))
                cv2.line(debug_img, pt1, pt2, (0, 0, 255), 3)
                
                # æ˜¾ç¤ºè§’åº¦ä¿¡æ¯
                cv2.putText(debug_img, 
                            f"Points: {len(boundary_points)} | Inliers: {len(best_inliers)} | Angle: {angle_diff:+.1f}\u00B0 | Hold: {self._aligned_duration:.1f}s", 
                            (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            
            # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°åˆé€‚çš„ç›´çº¿
            elif len(boundary_points) >= 10:
                cv2.putText(debug_img, 
                            f"WARNING: No suitable line found ({len(boundary_points)} boundary points)", 
                            (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
            else:
                cv2.putText(debug_img, 
                            f"WARNING: Not enough boundary points ({len(boundary_points)})", 
                            (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
            
            # ç»˜åˆ¶æ‰€æœ‰è½®å»“
            cv2.drawContours(debug_img, contours, -1, (255, 255, 0), 2)  # é’è‰²è½®å»“
            
            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            save_debug_image(f"detect33_{timestamp}.jpg", debug_img)
            
            # å®æ—¶è°ƒè¯•æ˜¾ç¤º
            if self.debug_mode:
                cv2.imshow("Detection Preview", debug_img)
                cv2.waitKey(1)
    
    def _detect_34(self, cv_image):
        # print(34)
        hsv = cv2.cvtColor(cv_image, cv2.COLOR_BGR2HSV)
        height, width = hsv.shape[:2]
        roi_height1 = 30
        roi_height2 = roi_height1 - 20
        x_start = width // 4
        x_end = 3 * width // 4
        roi = hsv[height-roi_height1:height - roi_height2, x_start:width]
        
        '''mask = cv2.inRange(roi, self.lower_yellow, self.upper_yellow)
        kernel = np.ones((3,3), np.uint8)
        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
        
        yellow_ratio = np.count_nonzero(mask) / (roi.size + 1e-5)  # é˜²æ­¢é™¤é›¶'''
        mask_combined = get_combined_color_mask(hsv, YELLOW_COMBINED_KEYS)
        mask_combined = cv2.morphologyEx(mask_combined, cv2.MORPH_OPEN, MORPH_KERNEL)
        mask_combined = cv2.morphologyEx(mask_combined, cv2.MORPH_CLOSE, MORPH_KERNEL)
        yellow_ratio = np.count_nonzero(mask_combined) / (mask_combined.size + 1e-5)  # é˜²æ­¢é™¤é›¶
        with self._lock:
            current_time = time.time()
            if yellow_ratio > 0.1:
                self._detected_flags['34'] = True
                '''if current_time - self._last_detection_time < 0.5:
                    self._detected_flags['34'] = True
                else:
                    self._detected_flags['34'] = False  # é‡ç½®çŸ­æš‚æ£€æµ‹'''
                self._last_detection_time = current_time
            else:
                self._detected_flags['34'] = False
        debug_img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
        cv2.rectangle(debug_img, 
                    (x_start, height-roi_height1),
                    (x_end, height - roi_height2),
                    (0,255,0), 2)
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        save_debug_image(f"detect34_{timestamp}_{yellow_ratio}.jpg", debug_img)
        # è°ƒè¯•æ˜¾ç¤º
        if self.debug_mode:
            debug_img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
            cv2.rectangle(debug_img, 
                        (x_start, height-roi_height1),
                        (x_end, height - roi_height2),
                        (0,255,0), 2)
            cv2.imshow("Detection Preview", debug_img)
            cv2.waitKey(1)

    def _detect_34_5(self, cv_image):
        hsv = cv2.cvtColor(cv_image, cv2.COLOR_BGR2HSV)
        height, width = hsv.shape[:2]
        debug_img = cv_image.copy()
        
        # é¢œè‰²é˜ˆå€¼å®šä¹‰
        YELLOW = (self.lower_yellow, self.upper_yellow)
        GRAY = (np.array([0, 0, 40]), np.array([180, 30, 90]))  # æ·±ç°è‰²èŒƒå›´
        
        # æ‰«æå‚æ•°
        SCAN_START_Y = height // 2
        SCAN_STEP = 5              # æ°´å¹³æ‰«ææ­¥é•¿
        WINDOW_SIZE = 20           # é¢œè‰²é‡‡æ ·çª—å£å¤§å°
        
        def find_boundary(start_x, direction):
            """ä»ä¸­å¿ƒå‘æŒ‡å®šæ–¹å‘æ‰«æå¯»æ‰¾é¢œè‰²è¾¹ç•Œ"""
            boundary_x = None
            for x in range(start_x, width if direction==1 else 0, direction*SCAN_STEP):
                # å‚ç›´é‡‡æ ·çª—å£
                sample_area = hsv[SCAN_START_Y:SCAN_START_Y+WINDOW_SIZE, 
                                max(0,x-WINDOW_SIZE//2):min(width,x+WINDOW_SIZE//2)]
                
                # è®¡ç®—é¢œè‰²å æ¯”
                yellow_mask = cv2.inRange(sample_area, *YELLOW)
                gray_mask = cv2.inRange(sample_area, *GRAY)
                
                # å½“é»„è‰²å æ¯”çªå¢ä¸”ç°è‰²å‡å°‘æ—¶åˆ¤å®šä¸ºè¾¹ç•Œ
                if cv2.countNonZero(yellow_mask) > 0.5*WINDOW_SIZE**2 and \
                cv2.countNonZero(gray_mask) < 0.2*WINDOW_SIZE**2:
                    boundary_x = x
                    break
            return boundary_x

        # ä»ä¸­å¿ƒå‘å·¦å³æ‰«æ
        center_x = width//2
        left_edge = find_boundary(center_x, -1)  # å‘å·¦æ‰«æ
        right_edge = find_boundary(center_x, 1)  # å‘å³æ‰«æ

        # è®¡ç®—æ§åˆ¶å‚æ•°
        yaw_error = 0.0
        lateral_error = 0.0  # æ–°å¢æ¨ªå‘ä½ç½®è¯¯å·®
        
        if left_edge and right_edge:
            # è®¡ç®—é“è·¯ä¸­å¿ƒç‚¹
            target_center = (left_edge + right_edge) // 2
            
            # è§’åº¦è¯¯å·®ï¼ˆä¿æŒåŸæœ‰ï¼‰
            center_offset = center_x - target_center
            yaw_error = np.arctan(center_offset / (width/2))
            
            # æ–°å¢æ¨ªå‘ä½ç½®è¯¯å·®ï¼ˆå½’ä¸€åŒ–åˆ°[-1,1]ï¼‰
            lane_width = right_edge - left_edge
            lateral_error = (center_x - target_center) / (lane_width / 2)
            
            # å¯è§†åŒ–é“è·¯ä¸­å¿ƒçº¿
            cv2.line(debug_img, (target_center, SCAN_START_Y-30),
                    (target_center, SCAN_START_Y+30), (255,0,0), 2)
        elif left_edge:
            yaw_error = np.radians(-15)
            lateral_error = -0.1  # åªæœ‰å·¦è¾¹ç•Œæ—¶å‘å³è°ƒæ•´
        elif right_edge:
            yaw_error = np.radians(15)
            lateral_error = 0.1   # åªæœ‰å³è¾¹ç•Œæ—¶å‘å·¦è°ƒæ•´
        
        # å¯è§†åŒ–æ‰«æçº¿
        cv2.line(debug_img, (0, SCAN_START_Y), (width, SCAN_START_Y), (0,255,255), 2)
        if left_edge:
            cv2.line(debug_img, (left_edge, SCAN_START_Y-20),
                    (left_edge, SCAN_START_Y+20), (0,255,0), 3)
        if right_edge:
            cv2.line(debug_img, (right_edge, SCAN_START_Y-20),
                    (right_edge, SCAN_START_Y+20), (0,255,0), 3)
        
        # ä¿å­˜è¯¯å·®å€¼
        with self._lock:
            self._detected_flags['34_5'] = left_edge or right_edge
            self._yaw_adjust = np.clip(yaw_error * 0.3, -1.5, 1.5)
            self._lateral_error = np.clip(lateral_error, -1.0, 1.0)
        
        # è°ƒè¯•æ˜¾ç¤º
        info_text = f"Yaw: {np.degrees(yaw_error):+.1f}\u00B0 Lat: {lateral_error:.2f}"
        cv2.putText(debug_img, info_text, (10,30),
                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        save_debug_image(f"detect345_{timestamp}.jpg", debug_img)    

    def _detect_35(self, cv_image):
        pass
        '''distance = self.YellowLightDetector.detect_distance(cv_image)
        with self._lock:
            if distance is not None:
                self._detected_flags['35'] = True
                self._yellow_light_distance = distance
            else:
                self._detected_flags['35'] = False
                self._yellow_light_distance = None
        if self.debug_mode:
            debug_img = cv_image.copy()
            if distance is not None:
                cv2.putText(debug_img, f"Yellow: {distance:.2f}m", (10,30), 
                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,255),2)
            cv2.imshow("Detection Preview", debug_img)
            cv2.waitKey(1)'''
    
    def _detect_35_5(self, cv_image):
        hsv = cv2.cvtColor(cv_image, cv2.COLOR_BGR2HSV)
        height, width = hsv.shape[:2]
        debug_img = cv_image.copy()
        
        # é¢œè‰²é˜ˆå€¼å®šä¹‰
        # YELLOW = YELLOW_COMBINED_KEYS
        YELLOW = (self.lower_yellow, self.upper_yellow)
        GRAY = (np.array([0, 0, 40]), np.array([180, 30, 90]))  # æ·±ç°è‰²èŒƒå›´
        
        # æ‰«æå‚æ•°
        SCAN_START_Y = height // 2
        SCAN_STEP = 5              # æ°´å¹³æ‰«ææ­¥é•¿
        WINDOW_SIZE = 20           # é¢œè‰²é‡‡æ ·çª—å£å¤§å°
        
        def find_boundary(start_x, direction):
            """ä»ä¸­å¿ƒå‘æŒ‡å®šæ–¹å‘æ‰«æå¯»æ‰¾é¢œè‰²è¾¹ç•Œ"""
            boundary_x = None
            for x in range(start_x, width if direction==1 else 0, direction*SCAN_STEP):
                # å‚ç›´é‡‡æ ·çª—å£
                sample_area = hsv[SCAN_START_Y:SCAN_START_Y+WINDOW_SIZE, 
                                max(0,x-WINDOW_SIZE//2):min(width,x+WINDOW_SIZE//2)]
                
                # è®¡ç®—é¢œè‰²å æ¯”
                yellow_mask = cv2.inRange(sample_area, *YELLOW)
                gray_mask = cv2.inRange(sample_area, *GRAY)
                
                # å½“é»„è‰²å æ¯”çªå¢ä¸”ç°è‰²å‡å°‘æ—¶åˆ¤å®šä¸ºè¾¹ç•Œ
                if cv2.countNonZero(yellow_mask) > 0.5*WINDOW_SIZE**2 and \
                cv2.countNonZero(gray_mask) < 0.2*WINDOW_SIZE**2:
                    boundary_x = x
                    break
            return boundary_x

        # ä»ä¸­å¿ƒå‘å·¦å³æ‰«æ
        center_x = width//2
        left_edge = find_boundary(center_x, -1)  # å‘å·¦æ‰«æ
        right_edge = find_boundary(center_x, 1)  # å‘å³æ‰«æ

        # è®¡ç®—æ§åˆ¶å‚æ•°
        yaw_error = 0.0
        lateral_error = 0.0  # æ–°å¢æ¨ªå‘ä½ç½®è¯¯å·®
        
        if left_edge and right_edge:
            # è®¡ç®—é“è·¯ä¸­å¿ƒç‚¹
            target_center = (left_edge + right_edge) // 2
            
            # è§’åº¦è¯¯å·®ï¼ˆä¿æŒåŸæœ‰ï¼‰
            center_offset = center_x - target_center
            yaw_error = np.arctan(center_offset / (width/2))
            
            # æ–°å¢æ¨ªå‘ä½ç½®è¯¯å·®ï¼ˆå½’ä¸€åŒ–åˆ°[-1,1]ï¼‰
            lane_width = right_edge - left_edge
            lateral_error = (center_x - target_center) / (lane_width / 2)
            
            # å¯è§†åŒ–é“è·¯ä¸­å¿ƒçº¿
            cv2.line(debug_img, (target_center, SCAN_START_Y-30),
                    (target_center, SCAN_START_Y+30), (255,0,0), 2)
        elif left_edge:
            yaw_error = np.radians(-15)
            lateral_error = -0.1  # åªæœ‰å·¦è¾¹ç•Œæ—¶å‘å³è°ƒæ•´
        elif right_edge:
            yaw_error = np.radians(15)
            lateral_error = 0.1   # åªæœ‰å³è¾¹ç•Œæ—¶å‘å·¦è°ƒæ•´
        
        # å¯è§†åŒ–æ‰«æçº¿
        cv2.line(debug_img, (0, SCAN_START_Y), (width, SCAN_START_Y), (0,255,255), 2)
        if left_edge:
            cv2.line(debug_img, (left_edge, SCAN_START_Y-20),
                    (left_edge, SCAN_START_Y+20), (0,255,0), 3)
        if right_edge:
            cv2.line(debug_img, (right_edge, SCAN_START_Y-20),
                    (right_edge, SCAN_START_Y+20), (0,255,0), 3)
        
        # ä¿å­˜è¯¯å·®å€¼
        with self._lock:
            self._detected_flags['35_5'] = left_edge or right_edge
            self._yaw_adjust = np.clip(yaw_error * 0.3, -1.5, 1.5)
            self._lateral_error = np.clip(lateral_error, -1.0, 1.0)
        
        # è°ƒè¯•æ˜¾ç¤º
        info_text = f"Yaw: {np.degrees(yaw_error):+.1f}\u00B0 Lat: {lateral_error:.2f}"
        cv2.putText(debug_img, info_text, (10,30),
                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        save_debug_image(f"detect355_{timestamp}.jpg", debug_img)  

    def _detect_36(self, cv_image):
        hsv = cv2.cvtColor(cv_image, cv2.COLOR_BGR2HSV)
        mask = cv2.inRange(hsv, self.lower_slope, self.upper_slope)
        
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5,5))
        cleaned = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)
        
        contours, _ = cv2.findContours(cleaned, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        height, width = cv_image.shape[:2]
        image_center = (width // 2, height // 2)

        closest_contour = None
        min_distance_sq = float('inf')
        slope_top_y = None

        for cnt in contours:
            area = cv2.contourArea(cnt)
            if area < self.min_slope_area:
                continue
                
            M = cv2.moments(cnt)
            if M["m00"] == 0:
                continue
            cX = int(M["m10"] / M["m00"])
            cY = int(M["m01"] / M["m00"])
            
            dx = cX - image_center[0]
            dy = cY - image_center[1]
            distance_sq = dx**2 + dy**2
            
            if distance_sq < min_distance_sq:
                min_distance_sq = distance_sq
                closest_contour = cnt

        # å¤„ç†æœ€ä¼˜è½®å»“
        if closest_contour is not None:
            top_point = tuple(closest_contour[closest_contour[:,:,1].argmin()][0])
            slope_top_y = top_point[1]
            
            if self.debug_mode:
                debug_img = cv_image.copy()
                cv2.drawContours(debug_img, [closest_contour], -1, (0,255,0), 2)
                M = cv2.moments(closest_contour)
                cX = int(M["m10"]/M["m00"])
                cY = int(M["m01"]/M["m00"])
                cv2.circle(debug_img, (cX, cY), 5, (0,0,255), -1)
                cv2.circle(debug_img, image_center, 5, (255,0,0), -1)
                cv2.imshow("Detection Preview", debug_img)
                cv2.waitKey(1)
            
            if slope_top_y <= image_center[1]:
                self._detected_flags['36'] = True
            else:
                self._detected_flags['36'] = False
        else:
            self._detected_flags['36'] = False

        with self._lock:
            self.slope_top_y = slope_top_y
    
    def _detect_36_5(self, cv_image):
        # é¢„å¤„ç†
        global arrow
        blurred = cv2.GaussianBlur(cv_image, (5, 5), 0)
        hsv = cv2.cvtColor(blurred, cv2.COLOR_BGR2HSV)

        # ä½¿ç”¨é…ç½®æ¨¡å—æå–é»„è‰²æ©ç 
        mask_combined = get_combined_color_mask(hsv, YELLOW_COMBINED_KEYS)
        mask_combined = cv2.morphologyEx(mask_combined, cv2.MORPH_OPEN, MORPH_KERNEL)
        mask_combined = cv2.morphologyEx(mask_combined, cv2.MORPH_CLOSE, MORPH_KERNEL)
        
        # åªä¿ç•™æœ€å¤§çš„ä¸¤ä¸ªè¿é€šåŸŸ
        num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(mask_combined, connectivity=8)
        clean_mask = np.zeros_like(mask_combined)
        if num_labels > 1:
            areas = stats[1:, cv2.CC_STAT_AREA]
            sorted_idx = np.argsort(areas)[::-1] + 1
            for i in sorted_idx[:min(2, len(sorted_idx))]:
                clean_mask[labels == i] = 255
        mask_combined = clean_mask

        # åˆ›å»ºROIèšç„¦å›¾åƒåº•éƒ¨ (é«˜åº¦1/2åŒºåŸŸ)
        height, width = mask_combined.shape[:2]
        roi_y_start = height - height // 2
        roi_mask = np.zeros_like(mask_combined)
        if arrow == Direction.Left:
            roi_mask[roi_y_start:, width // 2:] = 255
        else:
            roi_mask[roi_y_start:, :width // 2] = 255
        masked_roi = cv2.bitwise_and(mask_combined, roi_mask)

        # === ä¸“ä¸šæ–¹æ³•ï¼šæ£€æµ‹é»„è‰²è¾¹çº¿çš„å®é™…è¾¹ç•Œ ===
        # 1. æ‰¾åˆ°é»„è‰²åŒºåŸŸçš„è½®å»“
        contour_result = cv2.findContours(mask_combined, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if len(contour_result) == 3:  # OpenCV 3.x
            contours = contour_result[1]
        elif len(contour_result) == 2:  # OpenCV 4.x
            contours = contour_result[0]
        else:
            contours = contour_result
        # 2. æå–æ‰€æœ‰è¾¹ç•Œç‚¹
        boundary_points = []
        
        # 3. å¯¹æ¯ä¸ªè½®å»“ï¼Œæå–å…¶åº•éƒ¨è¾¹ç•Œç‚¹
        for contour in contours:
            # åˆ›å»ºè½®å»“çš„è¾¹ç•Œæ¡†
            x, y, w, h = cv2.boundingRect(contour)
            
            # åªå¤„ç†ROIåŒºåŸŸå†…çš„è½®å»“
            if y + h < roi_y_start:
                continue
            
            # åˆ›å»ºè½®å»“çš„æ©ç 
            contour_mask = np.zeros_like(mask_combined)
            cv2.drawContours(contour_mask, [contour], -1, 255, thickness=cv2.FILLED)
            
            # å¯¹è½®å»“è¿›è¡Œå¤šè¾¹å½¢è¿‘ä¼¼
            epsilon = 0.005 * cv2.arcLength(contour, True)
            approx = cv2.approxPolyDP(contour, epsilon, True)
            
            # æå–è½®å»“çš„åº•éƒ¨è¾¹ç¼˜ç‚¹
            for point in approx.squeeze():
                px, py = point
                # åªè€ƒè™‘ROIåŒºåŸŸå†…çš„ç‚¹
                if py < roi_y_start:
                    continue
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯åº•éƒ¨ç‚¹ï¼šè¯¥ç‚¹ä¸‹æ–¹ä¸æ˜¯é»„è‰²åŒºåŸŸ
                if py < height - 1:
                    if mask_combined[py + 1, px] == 0:  # ä¸‹æ–¹åƒç´ æ˜¯èƒŒæ™¯
                        boundary_points.append([px, py])
        
        # 4. å¦‚æœæ²¡æœ‰è¶³å¤Ÿè¾¹ç•Œç‚¹ï¼Œå°è¯•å¤‡ç”¨æ–¹æ³•
        if len(boundary_points) < 20:
            # å¤‡ç”¨æ–¹æ³•ï¼šé€åˆ—æ‰«æåº•éƒ¨è¾¹ç¼˜
            boundary_points = []
            for x in range(width):
                for y in range(height - 2, roi_y_start - 1, -1):
                    if mask_combined[y, x] == 255 and mask_combined[y + 1, x] == 0:
                        boundary_points.append([x, y])
                        break  # æ‰¾åˆ°è¯¥åˆ—çš„ç¬¬ä¸€ä¸ªè¾¹ç•Œç‚¹å³åœæ­¢
        
        # 5. ä½¿ç”¨RANSACç®—æ³•è¿›è¡Œç¨³å¥ç›´çº¿æ‹Ÿåˆ
        best_line = None
        best_inliers = []
        max_inliers = 0
        
        if len(boundary_points) >= 10:
            points_array = np.array(boundary_points)
            
            # ä½¿ç”¨RANSACå¤šæ¬¡è¿­ä»£å¯»æ‰¾æœ€ä½³æ‹Ÿåˆçº¿
            for _ in range(2):
                # éšæœºé€‰æ‹©ä¸¤ä¸ªç‚¹
                idx = np.random.choice(len(points_array), 2, replace=False)
                p1, p2 = points_array[idx[0]], points_array[idx[1]]
                
                # è®¡ç®—ç›´çº¿å‚æ•°
                dx = p2[0] - p1[0]
                dy = p2[1] - p1[1]
                if dx == 0:  # é¿å…é™¤ä»¥é›¶
                    continue
                    
                # ç›´çº¿æ–¹ç¨‹: y = mx + c
                m = dy / dx
                c = p1[1] - m * p1[0]
                
                # è®¡ç®—æ‰€æœ‰ç‚¹åˆ°ç›´çº¿çš„è·ç¦»
                distances = []
                for point in points_array:
                    px, py = point
                    # ç‚¹åˆ°ç›´çº¿çš„è·ç¦»å…¬å¼
                    dist = abs(m * px - py + c) / np.sqrt(m**2 + 1)
                    distances.append(dist)
                
                # ç»Ÿè®¡å†…ç‚¹ï¼ˆè·ç¦»å°äºé˜ˆå€¼çš„ç‚¹ï¼‰
                inlier_threshold = 2.0  # åƒç´ è·ç¦»é˜ˆå€¼
                inliers = [i for i, dist in enumerate(distances) if dist < inlier_threshold]
                
                if len(inliers) > max_inliers:
                    max_inliers = len(inliers)
                    best_inliers = inliers
                    best_line = (m, c, p1, p2)
        
        current_time = time.time()
        with self._lock:
            self._detected_flags['36_5'] = False
            self._line_angle = 0.0
            
            if best_line is not None and len(best_inliers) >= 10:
                m, c, p1, p2 = best_line
                
                # ä½¿ç”¨å†…ç‚¹é‡æ–°æ‹Ÿåˆç›´çº¿ï¼ˆæ›´ç²¾ç¡®ï¼‰
                inlier_points = points_array[best_inliers]
                vx, vy, cx, cy = cv2.fitLine(inlier_points, cv2.DIST_L2, 0, 0.01, 0.01)
                
                # è®¡ç®—ç›´çº¿è§’åº¦ï¼ˆç›¸å¯¹äºæ°´å¹³è½´ï¼‰
                line_angle = np.arctan2(vy, vx)[0]
                angle_deg = np.degrees(line_angle)
                target_angle = 0
                angle_diff = angle_deg - target_angle
                
                self._line_angle = np.radians(angle_diff)
                self._detected_flags['36_5'] = True
                
                # æŒç»­å¯¹é½è®¡æ—¶é€»è¾‘
                if abs(self._line_angle) < self._line_threshold:
                    if self._alignment_start_time == 0:
                        self._alignment_start_time = current_time
                    self._aligned_duration = current_time - self._alignment_start_time
                else:
                    self._alignment_start_time = 0.0
                    self._aligned_duration = 0.0
            else:
                self._alignment_start_time = 0.0
                self._aligned_duration = 0.0
                self._detected_flags['36_5'] = False

            # è°ƒè¯•å›¾åƒå¤„ç†
            debug_img = cv2.cvtColor(mask_combined, cv2.COLOR_GRAY2BGR)
            cv2.rectangle(debug_img, (0, roi_y_start), (width, height), (255, 0, 0), 2)  # ç»˜åˆ¶ROIåŒºåŸŸ
            
            # ç»˜åˆ¶æ‰€æœ‰è¾¹ç•Œç‚¹
            for point in boundary_points:
                cv2.circle(debug_img, tuple(point), 2, (0, 255, 0), -1)  # ç»¿è‰²ç‚¹è¡¨ç¤ºè¾¹ç•Œç‚¹
            
            # å¦‚æœæ£€æµ‹åˆ°ç›´çº¿ï¼Œç»˜åˆ¶æœ€ä½³æ‹Ÿåˆçº¿å’Œå†…ç‚¹
            if self._detected_flags['36_5']:
                # ç»˜åˆ¶å†…ç‚¹ï¼ˆè“è‰²ï¼‰
                for idx in best_inliers:
                    point = boundary_points[idx]
                    cv2.circle(debug_img, tuple(point), 3, (255, 0, 0), -1)  # è“è‰²ç‚¹è¡¨ç¤ºå†…ç‚¹
                
                # ç»˜åˆ¶æ‹Ÿåˆç›´çº¿ï¼ˆçº¢è‰²ç²—çº¿ï¼‰
                length = 500
                pt1 = (int(cx - vx * length), int(cy - vy * length))
                pt2 = (int(cx + vx * length), int(cy + vy * length))
                cv2.line(debug_img, pt1, pt2, (0, 0, 255), 3)
                
                # æ˜¾ç¤ºè§’åº¦ä¿¡æ¯
                cv2.putText(debug_img, 
                            f"Points: {len(boundary_points)} | Inliers: {len(best_inliers)} | Angle: {angle_diff:+.1f}\u00B0 | Hold: {self._aligned_duration:.1f}s", 
                            (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            
            # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°åˆé€‚çš„ç›´çº¿
            elif len(boundary_points) >= 10:
                cv2.putText(debug_img, 
                            f"WARNING: No suitable line found ({len(boundary_points)} boundary points)", 
                            (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
            else:
                cv2.putText(debug_img, 
                            f"WARNING: Not enough boundary points ({len(boundary_points)})", 
                            (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
            
            # ç»˜åˆ¶æ‰€æœ‰è½®å»“
            cv2.drawContours(debug_img, contours, -1, (255, 255, 0), 2)  # é’è‰²è½®å»“
            
            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            save_debug_image(f"detect365_{timestamp}.jpg", debug_img)
            
            # å®æ—¶è°ƒè¯•æ˜¾ç¤º
            if self.debug_mode:
                cv2.imshow("Detection Preview", debug_img)
                cv2.waitKey(1)

    def _detect_37(self, cv_image):
        hsv = cv2.cvtColor(cv_image, cv2.COLOR_BGR2HSV)
        height, width = hsv.shape[:2]
        roi_height1 = 20
        roi_height2 = roi_height1 - 20
        x_start = width // 3
        x_end = width - x_start
        roi = hsv[height-roi_height1:height - roi_height2, x_start:width]
        
        mask = cv2.inRange(roi, self.lower_yellow, self.upper_yellow)
        kernel = np.ones((3,3), np.uint8)
        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
        
        yellow_ratio = np.count_nonzero(mask) / (roi.size + 1e-5)
        
        with self._lock:
            current_time = time.time()
            if yellow_ratio < self._state10_threshold:
                self._detected_flags['37'] = True
                '''if current_time - self._last_detection_time < 0.5:
                    self._detected_flags['37'] = True
                else:
                    self._detected_flags['37'] = False
                self._last_detection_time = current_time'''
            else:
                self._detected_flags['37'] = False
        debug_img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
        cv2.rectangle(debug_img, 
                    (x_start, height-roi_height1),
                    (x_end, height - roi_height2),
                    (0,255,0), 2)
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        save_debug_image(f"detect37_{timestamp}_{yellow_ratio}.jpg", debug_img)
        # è°ƒè¯•æ˜¾ç¤º
        if self.debug_mode:
            debug_img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
            cv2.rectangle(debug_img, 
                        (x_start, height-roi_height1),
                        (x_end, height-roi_height2),
                        (0,255,0), 2)
            cv2.putText(debug_img, f"Y10: {yellow_ratio:.2f}", (x_start+10, height-10),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,0), 2)
            cv2.imshow("Detection Preview", debug_img)
            cv2.waitKey(1)

    def _detect_38(self, cv_image):
        # é¢„å¤„ç†
        blurred = cv2.GaussianBlur(cv_image, (5, 5), 0)
        hsv = cv2.cvtColor(blurred, cv2.COLOR_BGR2HSV)

        # ä½¿ç”¨é…ç½®æ¨¡å—æå–é»„è‰²æ©ç 
        mask_combined = get_combined_color_mask(hsv, YELLOW_COMBINED_KEYS)
        mask_combined = cv2.morphologyEx(mask_combined, cv2.MORPH_OPEN, MORPH_KERNEL)
        mask_combined = cv2.morphologyEx(mask_combined, cv2.MORPH_CLOSE, MORPH_KERNEL)
        
        # åªä¿ç•™æœ€å¤§çš„ä¸¤ä¸ªè¿é€šåŸŸ
        num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(mask_combined, connectivity=8)
        clean_mask = np.zeros_like(mask_combined)
        if num_labels > 1:
            areas = stats[1:, cv2.CC_STAT_AREA]
            sorted_idx = np.argsort(areas)[::-1] + 1
            for i in sorted_idx[:min(2, len(sorted_idx))]:
                clean_mask[labels == i] = 255
        mask_combined = clean_mask

        # åˆ›å»ºROIèšç„¦å›¾åƒåº•éƒ¨ (é«˜åº¦1/2åŒºåŸŸ)
        height, width = mask_combined.shape[:2]
        roi_y_start = height - height // 2
        roi_mask = np.zeros_like(mask_combined)
        roi_mask[roi_y_start:, :] = 255
        masked_roi = cv2.bitwise_and(mask_combined, roi_mask)

        # === ä¸“ä¸šæ–¹æ³•ï¼šæ£€æµ‹é»„è‰²è¾¹çº¿çš„å®é™…è¾¹ç•Œ ===
        # 1. æ‰¾åˆ°é»„è‰²åŒºåŸŸçš„è½®å»“
        contour_result = cv2.findContours(mask_combined, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if len(contour_result) == 3:  # OpenCV 3.x
            contours = contour_result[1]
        elif len(contour_result) == 2:  # OpenCV 4.x
            contours = contour_result[0]
        else:
            contours = contour_result
        # 2. æå–æ‰€æœ‰è¾¹ç•Œç‚¹
        boundary_points = []
        
        # 3. å¯¹æ¯ä¸ªè½®å»“ï¼Œæå–å…¶åº•éƒ¨è¾¹ç•Œç‚¹
        for contour in contours:
            # åˆ›å»ºè½®å»“çš„è¾¹ç•Œæ¡†
            x, y, w, h = cv2.boundingRect(contour)
            
            # åªå¤„ç†ROIåŒºåŸŸå†…çš„è½®å»“
            if y + h < roi_y_start:
                continue
            
            # åˆ›å»ºè½®å»“çš„æ©ç 
            contour_mask = np.zeros_like(mask_combined)
            cv2.drawContours(contour_mask, [contour], -1, 255, thickness=cv2.FILLED)
            
            # å¯¹è½®å»“è¿›è¡Œå¤šè¾¹å½¢è¿‘ä¼¼
            epsilon = 0.005 * cv2.arcLength(contour, True)
            approx = cv2.approxPolyDP(contour, epsilon, True)
            
            # æå–è½®å»“çš„åº•éƒ¨è¾¹ç¼˜ç‚¹
            for point in approx.squeeze():
                px, py = point
                # åªè€ƒè™‘ROIåŒºåŸŸå†…çš„ç‚¹
                if py < roi_y_start:
                    continue
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯åº•éƒ¨ç‚¹ï¼šè¯¥ç‚¹ä¸‹æ–¹ä¸æ˜¯é»„è‰²åŒºåŸŸ
                if py < height - 1:
                    if mask_combined[py + 1, px] == 0:  # ä¸‹æ–¹åƒç´ æ˜¯èƒŒæ™¯
                        boundary_points.append([px, py])
        
        # 4. å¦‚æœæ²¡æœ‰è¶³å¤Ÿè¾¹ç•Œç‚¹ï¼Œå°è¯•å¤‡ç”¨æ–¹æ³•
        if len(boundary_points) < 20:
            # å¤‡ç”¨æ–¹æ³•ï¼šé€åˆ—æ‰«æåº•éƒ¨è¾¹ç¼˜
            boundary_points = []
            for x in range(width):
                for y in range(height - 2, roi_y_start - 1, -1):
                    if mask_combined[y, x] == 255 and mask_combined[y + 1, x] == 0:
                        boundary_points.append([x, y])
                        break  # æ‰¾åˆ°è¯¥åˆ—çš„ç¬¬ä¸€ä¸ªè¾¹ç•Œç‚¹å³åœæ­¢
        
        # 5. ä½¿ç”¨RANSACç®—æ³•è¿›è¡Œç¨³å¥ç›´çº¿æ‹Ÿåˆ
        best_line = None
        best_inliers = []
        max_inliers = 0
        
        if len(boundary_points) >= 10:
            points_array = np.array(boundary_points)
            
            # ä½¿ç”¨RANSACå¤šæ¬¡è¿­ä»£å¯»æ‰¾æœ€ä½³æ‹Ÿåˆçº¿
            for _ in range(5):
                # éšæœºé€‰æ‹©ä¸¤ä¸ªç‚¹
                idx = np.random.choice(len(points_array), 2, replace=False)
                p1, p2 = points_array[idx[0]], points_array[idx[1]]
                
                # è®¡ç®—ç›´çº¿å‚æ•°
                dx = p2[0] - p1[0]
                dy = p2[1] - p1[1]
                if dx == 0:  # é¿å…é™¤ä»¥é›¶
                    continue
                    
                # ç›´çº¿æ–¹ç¨‹: y = mx + c
                m = dy / dx
                c = p1[1] - m * p1[0]
                
                # è®¡ç®—æ‰€æœ‰ç‚¹åˆ°ç›´çº¿çš„è·ç¦»
                distances = []
                for point in points_array:
                    px, py = point
                    # ç‚¹åˆ°ç›´çº¿çš„è·ç¦»å…¬å¼
                    dist = abs(m * px - py + c) / np.sqrt(m**2 + 1)
                    distances.append(dist)
                
                # ç»Ÿè®¡å†…ç‚¹ï¼ˆè·ç¦»å°äºé˜ˆå€¼çš„ç‚¹ï¼‰
                inlier_threshold = 2.0  # åƒç´ è·ç¦»é˜ˆå€¼
                inliers = [i for i, dist in enumerate(distances) if dist < inlier_threshold]
                
                if len(inliers) > max_inliers:
                    max_inliers = len(inliers)
                    best_inliers = inliers
                    best_line = (m, c, p1, p2)
        
        current_time = time.time()
        with self._lock:
            self._detected_flags['38'] = False
            self._line_angle = 0.0
            
            if best_line is not None and len(best_inliers) >= 10:
                m, c, p1, p2 = best_line
                
                # ä½¿ç”¨å†…ç‚¹é‡æ–°æ‹Ÿåˆç›´çº¿ï¼ˆæ›´ç²¾ç¡®ï¼‰
                inlier_points = points_array[best_inliers]
                vx, vy, cx, cy = cv2.fitLine(inlier_points, cv2.DIST_L2, 0, 0.01, 0.01)
                
                # è®¡ç®—ç›´çº¿è§’åº¦ï¼ˆç›¸å¯¹äºæ°´å¹³è½´ï¼‰
                line_angle = np.arctan2(vy, vx)[0]
                angle_deg = np.degrees(line_angle)
                target_angle = 0
                angle_diff = angle_deg - target_angle
                
                self._line_angle = np.radians(angle_diff)
                self._detected_flags['38'] = True
                
                # æŒç»­å¯¹é½è®¡æ—¶é€»è¾‘
                if abs(self._line_angle) < self._line_threshold:
                    if self._alignment_start_time == 0:
                        self._alignment_start_time = current_time
                    self._aligned_duration = current_time - self._alignment_start_time
                else:
                    self._alignment_start_time = 0.0
                    self._aligned_duration = 0.0
            else:
                self._alignment_start_time = 0.0
                self._aligned_duration = 0.0
                self._detected_flags['38'] = False

            # è°ƒè¯•å›¾åƒå¤„ç†
            debug_img = cv2.cvtColor(mask_combined, cv2.COLOR_GRAY2BGR)
            cv2.rectangle(debug_img, (0, roi_y_start), (width, height), (255, 0, 0), 2)  # ç»˜åˆ¶ROIåŒºåŸŸ
            
            # ç»˜åˆ¶æ‰€æœ‰è¾¹ç•Œç‚¹
            for point in boundary_points:
                cv2.circle(debug_img, tuple(point), 2, (0, 255, 0), -1)  # ç»¿è‰²ç‚¹è¡¨ç¤ºè¾¹ç•Œç‚¹
            
            # å¦‚æœæ£€æµ‹åˆ°ç›´çº¿ï¼Œç»˜åˆ¶æœ€ä½³æ‹Ÿåˆçº¿å’Œå†…ç‚¹
            if self._detected_flags['38']:
                # ç»˜åˆ¶å†…ç‚¹ï¼ˆè“è‰²ï¼‰
                for idx in best_inliers:
                    point = boundary_points[idx]
                    cv2.circle(debug_img, tuple(point), 3, (255, 0, 0), -1)  # è“è‰²ç‚¹è¡¨ç¤ºå†…ç‚¹
                
                # ç»˜åˆ¶æ‹Ÿåˆç›´çº¿ï¼ˆçº¢è‰²ç²—çº¿ï¼‰
                length = 500
                pt1 = (int(cx - vx * length), int(cy - vy * length))
                pt2 = (int(cx + vx * length), int(cy + vy * length))
                cv2.line(debug_img, pt1, pt2, (0, 0, 255), 3)
                
                # æ˜¾ç¤ºè§’åº¦ä¿¡æ¯
                cv2.putText(debug_img, 
                            f"Points: {len(boundary_points)} | Inliers: {len(best_inliers)} | Angle: {angle_diff:+.1f}\u00B0 | Hold: {self._aligned_duration:.1f}s", 
                            (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            
            # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°åˆé€‚çš„ç›´çº¿
            elif len(boundary_points) >= 10:
                cv2.putText(debug_img, 
                            f"WARNING: No suitable line found ({len(boundary_points)} boundary points)", 
                            (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
            else:
                cv2.putText(debug_img, 
                            f"WARNING: Not enough boundary points ({len(boundary_points)})", 
                            (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
            
            # ç»˜åˆ¶æ‰€æœ‰è½®å»“
            cv2.drawContours(debug_img, contours, -1, (255, 255, 0), 2)  # é’è‰²è½®å»“
            
            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            save_debug_image(f"detect38_{timestamp}.jpg", debug_img)
            
            # å®æ—¶è°ƒè¯•æ˜¾ç¤º
            if self.debug_mode:
                cv2.imshow("Detection Preview", debug_img)
                cv2.waitKey(1)
    
    def _detect_39(self, cv_image):
        hsv = cv2.cvtColor(cv_image, cv2.COLOR_BGR2HSV)
        height, width = hsv.shape[:2]
        roi_height1 = height // 2 + height // 10
        roi_height2 = roi_height1 - 5
        '''x_start = width // 5 if arrow == Direction.Right else 4 * width // 5
        x_end = 2 * width // 5 if arrow == Direction.Right else width'''
        x_start = 3 * width // 7
        x_end = 4 * width // 7
        roi = hsv[height-roi_height1:height - roi_height2, x_start:x_end]
        
        mask = cv2.inRange(roi, self.lower_yellow, self.upper_yellow)
        kernel = np.ones((3,3), np.uint8)
        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
        
        yellow_ratio = np.count_nonzero(mask) / (roi.size + 1e-5)
        
        with self._lock:
            current_time = time.time()
            if yellow_ratio > 0.05:
                if current_time - self._last_detection_time < 0.5:
                    self._detected_flags['39'] = True
                else:
                    self._detected_flags['39'] = False
                self._last_detection_time = current_time
            else:
                self._detected_flags['39'] = False
        debug_img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
        cv2.rectangle(debug_img, 
                    (x_start, height-roi_height1),
                    (x_end, height - roi_height2),
                    (0,255,0), 2)
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        save_debug_image(f"detect39_{timestamp}_{yellow_ratio}.jpg", debug_img)

        # è°ƒè¯•æ˜¾ç¤º
        if self.debug_mode:
            debug_img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
            cv2.rectangle(debug_img, 
                        (x_start, height-roi_height1),
                        (x_end, height-roi_height2),
                        (0,255,0), 2)
            cv2.putText(debug_img, f"Y10: {yellow_ratio:.2f}", (x_start+10, height-10),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,0), 2)
            cv2.imshow("Detection Preview", debug_img)
            cv2.waitKey(1)
    
    def _detect_39_55(self, cv_image):
        hsv = cv2.cvtColor(cv_image, cv2.COLOR_BGR2HSV)
        height, width = hsv.shape[:2]
        debug_img = cv_image.copy()
        
        # é¢œè‰²é˜ˆå€¼å®šä¹‰
        YELLOW = (self.lower_yellow, self.upper_yellow)
        GRAY = (np.array([0, 0, 40]), np.array([180, 30, 90]))  # æ·±ç°è‰²èŒƒå›´
        
        # æ‰«æå‚æ•°
        SCAN_START_Y = height // 2 - height // 8
        SCAN_STEP = 5              # æ°´å¹³æ‰«ææ­¥é•¿
        WINDOW_SIZE = 20           # é¢œè‰²é‡‡æ ·çª—å£å¤§å°
        
        def find_boundary(start_x, direction):
            """ä»ä¸­å¿ƒå‘æŒ‡å®šæ–¹å‘æ‰«æå¯»æ‰¾é¢œè‰²è¾¹ç•Œ"""
            boundary_x = None
            for x in range(start_x, width if direction==1 else 0, direction*SCAN_STEP):
                # å‚ç›´é‡‡æ ·çª—å£
                sample_area = hsv[SCAN_START_Y:SCAN_START_Y+WINDOW_SIZE, 
                                max(0,x-WINDOW_SIZE//2):min(width,x+WINDOW_SIZE//2)]
                
                # è®¡ç®—é¢œè‰²å æ¯”
                yellow_mask = cv2.inRange(sample_area, *YELLOW)
                gray_mask = cv2.inRange(sample_area, *GRAY)
                
                # å½“é»„è‰²å æ¯”çªå¢ä¸”ç°è‰²å‡å°‘æ—¶åˆ¤å®šä¸ºè¾¹ç•Œ
                if cv2.countNonZero(yellow_mask) > 0.5*WINDOW_SIZE**2 and \
                cv2.countNonZero(gray_mask) < 0.2*WINDOW_SIZE**2:
                    boundary_x = x
                    break
            return boundary_x

        # ä»ä¸­å¿ƒå‘å·¦å³æ‰«æ
        center_x = width//2
        left_edge = find_boundary(center_x, -1)  # å‘å·¦æ‰«æ
        right_edge = find_boundary(center_x, 1)  # å‘å³æ‰«æ

        # è®¡ç®—æ§åˆ¶å‚æ•°
        yaw_error = 0.0
        lateral_error = 0.0  # æ–°å¢æ¨ªå‘ä½ç½®è¯¯å·®
        
        if left_edge and right_edge:
            # è®¡ç®—é“è·¯ä¸­å¿ƒç‚¹
            target_center = (left_edge + right_edge) // 2
            
            # è§’åº¦è¯¯å·®ï¼ˆä¿æŒåŸæœ‰ï¼‰
            center_offset = center_x - target_center
            yaw_error = np.arctan(center_offset / (width/2))
            
            # æ–°å¢æ¨ªå‘ä½ç½®è¯¯å·®ï¼ˆå½’ä¸€åŒ–åˆ°[-1,1]ï¼‰
            lane_width = right_edge - left_edge
            lateral_error = (center_x - target_center) / (lane_width / 2)
            
            # å¯è§†åŒ–é“è·¯ä¸­å¿ƒçº¿
            cv2.line(debug_img, (target_center, SCAN_START_Y-30),
                    (target_center, SCAN_START_Y+30), (255,0,0), 2)
        elif left_edge:
            yaw_error = np.radians(-15)
            lateral_error = -0.1  # åªæœ‰å·¦è¾¹ç•Œæ—¶å‘å³è°ƒæ•´
        elif right_edge:
            yaw_error = np.radians(15)
            lateral_error = 0.1   # åªæœ‰å³è¾¹ç•Œæ—¶å‘å·¦è°ƒæ•´
        
        # å¯è§†åŒ–æ‰«æçº¿
        cv2.line(debug_img, (0, SCAN_START_Y), (width, SCAN_START_Y), (0,255,255), 2)
        if left_edge:
            cv2.line(debug_img, (left_edge, SCAN_START_Y-20),
                    (left_edge, SCAN_START_Y+20), (0,255,0), 3)
        if right_edge:
            cv2.line(debug_img, (right_edge, SCAN_START_Y-20),
                    (right_edge, SCAN_START_Y+20), (0,255,0), 3)
        
        # ä¿å­˜è¯¯å·®å€¼
        with self._lock:
            self._detected_flags['39_55'] = left_edge or right_edge
            self._yaw_adjust = np.clip(yaw_error * 0.3, -1.5, 1.5)
            self._lateral_error = np.clip(lateral_error, -1.0, 1.0)
        
        # è°ƒè¯•æ˜¾ç¤º
        info_text = f"Yaw: {np.degrees(yaw_error):+.1f}\u00B0 Lat: {lateral_error:.2f}"
        cv2.putText(debug_img, info_text, (10,30),
                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        save_debug_image(f"detect3955_{timestamp}.jpg", debug_img)  

    def _detect_40(self, cv_image):
        # é¢„å¤„ç†
        blurred = cv2.GaussianBlur(cv_image, (5, 5), 0)
        hsv = cv2.cvtColor(blurred, cv2.COLOR_BGR2HSV)

        # ä½¿ç”¨é…ç½®æ¨¡å—æå–é»„è‰²æ©ç 
        mask_combined = get_combined_color_mask(hsv, YELLOW_COMBINED_KEYS)
        mask_combined = cv2.morphologyEx(mask_combined, cv2.MORPH_OPEN, MORPH_KERNEL)
        mask_combined = cv2.morphologyEx(mask_combined, cv2.MORPH_CLOSE, MORPH_KERNEL)
        
        # åªä¿ç•™æœ€å¤§çš„ä¸¤ä¸ªè¿é€šåŸŸ
        num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(mask_combined, connectivity=8)
        clean_mask = np.zeros_like(mask_combined)
        if num_labels > 1:
            areas = stats[1:, cv2.CC_STAT_AREA]
            sorted_idx = np.argsort(areas)[::-1] + 1
            for i in sorted_idx[:min(2, len(sorted_idx))]:
                clean_mask[labels == i] = 255
        mask_combined = clean_mask

        # åˆ›å»ºROIèšç„¦å›¾åƒåº•éƒ¨ (é«˜åº¦1/2åŒºåŸŸ)
        height, width = mask_combined.shape[:2]
        roi_y_start = height - height // 2
        roi_x_start =2 * width // 5
        roi_x_end = 3 * width // 5
        roi_mask = np.zeros_like(mask_combined)
        roi_mask[roi_y_start:, roi_x_start:roi_x_end] = 255
        masked_roi = cv2.bitwise_and(mask_combined, roi_mask)

        # === ä¸“ä¸šæ–¹æ³•ï¼šæ£€æµ‹é»„è‰²è¾¹çº¿çš„å®é™…è¾¹ç•Œ ===
        # 1. æ‰¾åˆ°é»„è‰²åŒºåŸŸçš„è½®å»“
        contour_result = cv2.findContours(mask_combined, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if len(contour_result) == 3:  # OpenCV 3.x
            contours = contour_result[1]
        elif len(contour_result) == 2:  # OpenCV 4.x
            contours = contour_result[0]
        else:
            contours = contour_result
        # 2. æå–æ‰€æœ‰è¾¹ç•Œç‚¹
        boundary_points = []
        
        # 3. å¯¹æ¯ä¸ªè½®å»“ï¼Œæå–å…¶åº•éƒ¨è¾¹ç•Œç‚¹
        for contour in contours:
            # åˆ›å»ºè½®å»“çš„è¾¹ç•Œæ¡†
            x, y, w, h = cv2.boundingRect(contour)
            
            # åªå¤„ç†ROIåŒºåŸŸå†…çš„è½®å»“
            if y + h < roi_y_start:
                continue
            
            # åˆ›å»ºè½®å»“çš„æ©ç 
            contour_mask = np.zeros_like(mask_combined)
            cv2.drawContours(contour_mask, [contour], -1, 255, thickness=cv2.FILLED)
            
            # å¯¹è½®å»“è¿›è¡Œå¤šè¾¹å½¢è¿‘ä¼¼
            epsilon = 0.005 * cv2.arcLength(contour, True)
            approx = cv2.approxPolyDP(contour, epsilon, True)
            
            # æå–è½®å»“çš„åº•éƒ¨è¾¹ç¼˜ç‚¹
            for point in approx.squeeze():
                px, py = point
                # åªè€ƒè™‘ROIåŒºåŸŸå†…çš„ç‚¹
                if py < roi_y_start:
                    continue
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯åº•éƒ¨ç‚¹ï¼šè¯¥ç‚¹ä¸‹æ–¹ä¸æ˜¯é»„è‰²åŒºåŸŸ
                if py < height - 1:
                    if mask_combined[py + 1, px] == 0:  # ä¸‹æ–¹åƒç´ æ˜¯èƒŒæ™¯
                        boundary_points.append([px, py])
        
        # 4. å¦‚æœæ²¡æœ‰è¶³å¤Ÿè¾¹ç•Œç‚¹ï¼Œå°è¯•å¤‡ç”¨æ–¹æ³•
        if len(boundary_points) < 20:
            # å¤‡ç”¨æ–¹æ³•ï¼šé€åˆ—æ‰«æåº•éƒ¨è¾¹ç¼˜
            boundary_points = []
            for x in range(2 * width // 5, 3 * width // 5):
                for y in range(height - 2, roi_y_start - 1, -1):
                    if mask_combined[y, x] == 255 and mask_combined[y + 1, x] == 0:
                        boundary_points.append([x, y])
                        break  # æ‰¾åˆ°è¯¥åˆ—çš„ç¬¬ä¸€ä¸ªè¾¹ç•Œç‚¹å³åœæ­¢
        
        # 5. ä½¿ç”¨RANSACç®—æ³•è¿›è¡Œç¨³å¥ç›´çº¿æ‹Ÿåˆ
        best_line = None
        best_inliers = []
        max_inliers = 0
        
        if len(boundary_points) >= 10:
            points_array = np.array(boundary_points)
            
            # ä½¿ç”¨RANSACå¤šæ¬¡è¿­ä»£å¯»æ‰¾æœ€ä½³æ‹Ÿåˆçº¿
            for _ in range(2):
                # éšæœºé€‰æ‹©ä¸¤ä¸ªç‚¹
                idx = np.random.choice(len(points_array), 2, replace=False)
                p1, p2 = points_array[idx[0]], points_array[idx[1]]
                
                # è®¡ç®—ç›´çº¿å‚æ•°
                dx = p2[0] - p1[0]
                dy = p2[1] - p1[1]
                if dx == 0:  # é¿å…é™¤ä»¥é›¶
                    continue
                    
                # ç›´çº¿æ–¹ç¨‹: y = mx + c
                m = dy / dx
                c = p1[1] - m * p1[0]
                
                # è®¡ç®—æ‰€æœ‰ç‚¹åˆ°ç›´çº¿çš„è·ç¦»
                distances = []
                for point in points_array:
                    px, py = point
                    # ç‚¹åˆ°ç›´çº¿çš„è·ç¦»å…¬å¼
                    dist = abs(m * px - py + c) / np.sqrt(m**2 + 1)
                    distances.append(dist)
                
                # ç»Ÿè®¡å†…ç‚¹ï¼ˆè·ç¦»å°äºé˜ˆå€¼çš„ç‚¹ï¼‰
                inlier_threshold = 2.0  # åƒç´ è·ç¦»é˜ˆå€¼
                inliers = [i for i, dist in enumerate(distances) if dist < inlier_threshold]
                
                if len(inliers) > max_inliers:
                    max_inliers = len(inliers)
                    best_inliers = inliers
                    best_line = (m, c, p1, p2)
        
        current_time = time.time()
        with self._lock:
            self._detected_flags['40'] = False
            self._line_angle = 0.0
            
            if best_line is not None and len(best_inliers) >= 10:
                m, c, p1, p2 = best_line
                
                # ä½¿ç”¨å†…ç‚¹é‡æ–°æ‹Ÿåˆç›´çº¿ï¼ˆæ›´ç²¾ç¡®ï¼‰
                inlier_points = points_array[best_inliers]
                vx, vy, cx, cy = cv2.fitLine(inlier_points, cv2.DIST_L2, 0, 0.01, 0.01)
                
                # è®¡ç®—ç›´çº¿è§’åº¦ï¼ˆç›¸å¯¹äºæ°´å¹³è½´ï¼‰
                line_angle = np.arctan2(vy, vx)[0]
                angle_deg = np.degrees(line_angle)
                target_angle = 0
                angle_diff = angle_deg - target_angle
                
                self._line_angle = np.radians(angle_diff)
                self._detected_flags['40'] = True
                
                # æŒç»­å¯¹é½è®¡æ—¶é€»è¾‘
                if abs(self._line_angle) < self._line_threshold:
                    if self._alignment_start_time == 0:
                        self._alignment_start_time = current_time
                    self._aligned_duration = current_time - self._alignment_start_time
                else:
                    self._alignment_start_time = 0.0
                    self._aligned_duration = 0.0
            else:
                self._alignment_start_time = 0.0
                self._aligned_duration = 0.0
                self._detected_flags['40'] = False

            # è°ƒè¯•å›¾åƒå¤„ç†
            debug_img = cv2.cvtColor(mask_combined, cv2.COLOR_GRAY2BGR)
            cv2.rectangle(debug_img, (0, roi_y_start), (width, height), (255, 0, 0), 2)  # ç»˜åˆ¶ROIåŒºåŸŸ
            
            # ç»˜åˆ¶æ‰€æœ‰è¾¹ç•Œç‚¹
            for point in boundary_points:
                cv2.circle(debug_img, tuple(point), 2, (0, 255, 0), -1)  # ç»¿è‰²ç‚¹è¡¨ç¤ºè¾¹ç•Œç‚¹
            
            # å¦‚æœæ£€æµ‹åˆ°ç›´çº¿ï¼Œç»˜åˆ¶æœ€ä½³æ‹Ÿåˆçº¿å’Œå†…ç‚¹
            if self._detected_flags['40']:
                # ç»˜åˆ¶å†…ç‚¹ï¼ˆè“è‰²ï¼‰
                for idx in best_inliers:
                    point = boundary_points[idx]
                    cv2.circle(debug_img, tuple(point), 3, (255, 0, 0), -1)  # è“è‰²ç‚¹è¡¨ç¤ºå†…ç‚¹
                
                # ç»˜åˆ¶æ‹Ÿåˆç›´çº¿ï¼ˆçº¢è‰²ç²—çº¿ï¼‰
                length = 500
                pt1 = (int(cx - vx * length), int(cy - vy * length))
                pt2 = (int(cx + vx * length), int(cy + vy * length))
                cv2.line(debug_img, pt1, pt2, (0, 0, 255), 3)
                
                # æ˜¾ç¤ºè§’åº¦ä¿¡æ¯
                cv2.putText(debug_img, 
                            f"Points: {len(boundary_points)} | Inliers: {len(best_inliers)} | Angle: {angle_diff:+.1f}\u00B0 | Hold: {self._aligned_duration:.1f}s", 
                            (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            
            # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°åˆé€‚çš„ç›´çº¿
            elif len(boundary_points) >= 10:
                cv2.putText(debug_img, 
                            f"WARNING: No suitable line found ({len(boundary_points)} boundary points)", 
                            (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
            else:
                cv2.putText(debug_img, 
                            f"WARNING: Not enough boundary points ({len(boundary_points)})", 
                            (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
            
            # ç»˜åˆ¶æ‰€æœ‰è½®å»“
            cv2.drawContours(debug_img, contours, -1, (255, 255, 0), 2)  # é’è‰²è½®å»“
            
            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            save_debug_image(f"detect40_{timestamp}.jpg", debug_img)
            
            # å®æ—¶è°ƒè¯•æ˜¾ç¤º
            if self.debug_mode:
                cv2.imshow("Detection Preview", debug_img)
                cv2.waitKey(1)
    
    def _detect_41(self, cv_image):
        # === 1. é¢„å¤„ç†å¹¶è½¬æ¢ä¸º HSV ===
        blurred = cv2.GaussianBlur(cv_image, (5, 5), 0)
        hsv = cv2.cvtColor(blurred, cv2.COLOR_BGR2HSV)
        height, width = hsv.shape[:2]

       # å®šä¹‰ ROI ä½ç½®ï¼šä½äºåº•éƒ¨å¾€ä¸Š 1/4 é«˜åº¦çš„ä½ç½®
        quarter_height = height // 6
        roi_center_y = height - quarter_height  # è·ç¦»åº•éƒ¨ 1/4 çš„ä½ç½®ï¼ˆå³æ•´ä½“çš„ 3/4 å¤„ï¼‰

        # å®šä¹‰ ROI é«˜åº¦ï¼ˆä¾‹å¦‚ 20 åƒç´ é«˜ï¼‰
        roi_height = height // 32

        # è®¡ç®—ä¸Šä¸‹è¾¹ç•Œ
        y_start = roi_center_y - roi_height // 2
        y_end = roi_center_y + roi_height // 2

        # ç¡®ä¿ä¸è¶Šç•Œ
        y_start = max(y_start, 0)
        y_end = min(y_end, height)

        # æ¨ªå‘ï¼šæ•´å¹…å®½åº¦
        x_start = width // 5 * 2
        x_end = width //5 * 3 # æˆ–ç›´æ¥ç”¨ width

        # æå– ROI
        roi_hsv = hsv[y_start:y_end, x_start:x_end]

        # === 3. ä½¿ç”¨æ¨¡å—å‡½æ•°ç”Ÿæˆâ€œé»„+æ³›ç™½é»„â€æ©ç  ===
        mask_combined = get_combined_color_mask(roi_hsv, YELLOW_COMBINED_KEYS)

        # === 4. å½¢æ€å­¦å»å™ª ===
        mask_combined = cv2.morphologyEx(mask_combined, cv2.MORPH_OPEN, MORPH_KERNEL)
        mask_combined = cv2.morphologyEx(mask_combined, cv2.MORPH_CLOSE, MORPH_KERNEL)

        # === 5. é»„è‰²åƒç´ å æ¯”è®¡ç®— ===
        yellow_ratio = np.count_nonzero(mask_combined) / (mask_combined.size + 1e-5)

        with self._lock:
            if yellow_ratio > 0.5:
                self._detected_flags['41'] = True
            else:
                self._detected_flags['41'] = False

        debug_img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
        cv2.rectangle(debug_img,
                    (x_start, y_start),           # å·¦ä¸Šè§’
                    (x_end, y_end),             # å³ä¸‹è§’
                    (0, 255, 0), 2)          # ç»¿è‰²æ¡†ï¼Œçº¿å®½ 2
        cv2.putText(debug_img, f"Yellow Ratio: {yellow_ratio:.3f}", (10, 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)
        cv2.putText(debug_img, f"Detected: {self._detected_flags['9']}", (10, 60),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255) if not self._detected_flags['9'] else (0, 255, 0), 2)
        
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S_%f")  # ç²¾ç¡®åˆ°å¾®ç§’
        save_debug_image(f"detect41_{timestamp}.jpg", debug_img)
        # è°ƒè¯•æ˜¾ç¤º
        if self.debug_mode:
            cv2.imshow("Detection Preview", debug_img)
            cv2.waitKey(1)

        if self.real_debug_mode:
            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S_%f")  # ç²¾ç¡®åˆ°å¾®ç§’
            filename = f"detect41_{timestamp}.jpg"

            save_debug_image(filename, debug_img)
    
    def _detect_42(self, cv_image):
        # é¢„å¤„ç†
        blurred = cv2.GaussianBlur(cv_image, (5, 5), 0)
        hsv = cv2.cvtColor(blurred, cv2.COLOR_BGR2HSV)

        # ä½¿ç”¨é…ç½®æ¨¡å—æå–é»„è‰²æ©ç 
        mask_combined = get_combined_color_mask(hsv, YELLOW_COMBINED_KEYS)
        mask_combined = cv2.morphologyEx(mask_combined, cv2.MORPH_OPEN, MORPH_KERNEL)
        mask_combined = cv2.morphologyEx(mask_combined, cv2.MORPH_CLOSE, MORPH_KERNEL)
        
        # åªä¿ç•™æœ€å¤§çš„ä¸¤ä¸ªè¿é€šåŸŸ
        num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(mask_combined, connectivity=8)
        clean_mask = np.zeros_like(mask_combined)
        if num_labels > 1:
            areas = stats[1:, cv2.CC_STAT_AREA]
            sorted_idx = np.argsort(areas)[::-1] + 1
            for i in sorted_idx[:min(2, len(sorted_idx))]:
                clean_mask[labels == i] = 255
        mask_combined = clean_mask

        # åˆ›å»ºROIèšç„¦å›¾åƒåº•éƒ¨ (é«˜åº¦1/2åŒºåŸŸ)
        height, width = mask_combined.shape[:2]
        roi_y_start = height - height // 2
        roi_x_start = width // 2
        roi_mask = np.zeros_like(mask_combined)
        roi_mask[roi_y_start:, :width // 2] = 255
        if QR1 == 'A-2':
            roi_mask[roi_y_start:, roi_x_start:3 * width // 4] = 255
        else:
            roi_mask[roi_y_start:, width // 4:roi_x_start] = 255
        masked_roi = cv2.bitwise_and(mask_combined, roi_mask)

        # === ä¸“ä¸šæ–¹æ³•ï¼šæ£€æµ‹é»„è‰²è¾¹çº¿çš„å®é™…è¾¹ç•Œ ===
        # 1. æ‰¾åˆ°é»„è‰²åŒºåŸŸçš„è½®å»“
        contour_result = cv2.findContours(mask_combined, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if len(contour_result) == 3:  # OpenCV 3.x
            contours = contour_result[1]
        elif len(contour_result) == 2:  # OpenCV 4.x
            contours = contour_result[0]
        else:
            contours = contour_result
        # 2. æå–æ‰€æœ‰è¾¹ç•Œç‚¹
        boundary_points = []
        
        # 3. å¯¹æ¯ä¸ªè½®å»“ï¼Œæå–å…¶åº•éƒ¨è¾¹ç•Œç‚¹
        for contour in contours:
            # åˆ›å»ºè½®å»“çš„è¾¹ç•Œæ¡†
            x, y, w, h = cv2.boundingRect(contour)
            
            # åªå¤„ç†ROIåŒºåŸŸå†…çš„è½®å»“
            if y + h < roi_y_start:
                continue
            
            # åˆ›å»ºè½®å»“çš„æ©ç 
            contour_mask = np.zeros_like(mask_combined)
            cv2.drawContours(contour_mask, [contour], -1, 255, thickness=cv2.FILLED)
            
            # å¯¹è½®å»“è¿›è¡Œå¤šè¾¹å½¢è¿‘ä¼¼
            epsilon = 0.005 * cv2.arcLength(contour, True)
            approx = cv2.approxPolyDP(contour, epsilon, True)
            
            # æå–è½®å»“çš„åº•éƒ¨è¾¹ç¼˜ç‚¹
            for point in approx.squeeze():
                px, py = point
                # åªè€ƒè™‘ROIåŒºåŸŸå†…çš„ç‚¹
                if py < roi_y_start:
                    continue
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯åº•éƒ¨ç‚¹ï¼šè¯¥ç‚¹ä¸‹æ–¹ä¸æ˜¯é»„è‰²åŒºåŸŸ
                if py < height - 1:
                    if mask_combined[py + 1, px] == 0:  # ä¸‹æ–¹åƒç´ æ˜¯èƒŒæ™¯
                        boundary_points.append([px, py])
        
        # 4. å¦‚æœæ²¡æœ‰è¶³å¤Ÿè¾¹ç•Œç‚¹ï¼Œå°è¯•å¤‡ç”¨æ–¹æ³•
        if len(boundary_points) < 20:
            # å¤‡ç”¨æ–¹æ³•ï¼šé€åˆ—æ‰«æåº•éƒ¨è¾¹ç¼˜
            boundary_points = []
            for x in range(width // 4, 3 * width // 4):
                for y in range(height - 2, roi_y_start - 1, -1):
                    if mask_combined[y, x] == 255 and mask_combined[y + 1, x] == 0:
                        boundary_points.append([x, y])
                        break  # æ‰¾åˆ°è¯¥åˆ—çš„ç¬¬ä¸€ä¸ªè¾¹ç•Œç‚¹å³åœæ­¢
        
        # 5. ä½¿ç”¨RANSACç®—æ³•è¿›è¡Œç¨³å¥ç›´çº¿æ‹Ÿåˆ
        best_line = None
        best_inliers = []
        max_inliers = 0
        
        if len(boundary_points) >= 10:
            points_array = np.array(boundary_points)
            
            # ä½¿ç”¨RANSACå¤šæ¬¡è¿­ä»£å¯»æ‰¾æœ€ä½³æ‹Ÿåˆçº¿
            for _ in range(2):
                # éšæœºé€‰æ‹©ä¸¤ä¸ªç‚¹
                idx = np.random.choice(len(points_array), 2, replace=False)
                p1, p2 = points_array[idx[0]], points_array[idx[1]]
                
                # è®¡ç®—ç›´çº¿å‚æ•°
                dx = p2[0] - p1[0]
                dy = p2[1] - p1[1]
                if dx == 0:  # é¿å…é™¤ä»¥é›¶
                    continue
                    
                # ç›´çº¿æ–¹ç¨‹: y = mx + c
                m = dy / dx
                c = p1[1] - m * p1[0]
                
                # è®¡ç®—æ‰€æœ‰ç‚¹åˆ°ç›´çº¿çš„è·ç¦»
                distances = []
                for point in points_array:
                    px, py = point
                    # ç‚¹åˆ°ç›´çº¿çš„è·ç¦»å…¬å¼
                    dist = abs(m * px - py + c) / np.sqrt(m**2 + 1)
                    distances.append(dist)
                
                # ç»Ÿè®¡å†…ç‚¹ï¼ˆè·ç¦»å°äºé˜ˆå€¼çš„ç‚¹ï¼‰
                inlier_threshold = 2.0  # åƒç´ è·ç¦»é˜ˆå€¼
                inliers = [i for i, dist in enumerate(distances) if dist < inlier_threshold]
                
                if len(inliers) > max_inliers:
                    max_inliers = len(inliers)
                    best_inliers = inliers
                    best_line = (m, c, p1, p2)
        
        current_time = time.time()
        with self._lock:
            self._detected_flags['42'] = False
            self._line_angle = 0.0
            
            if best_line is not None and len(best_inliers) >= 10:
                m, c, p1, p2 = best_line
                
                # ä½¿ç”¨å†…ç‚¹é‡æ–°æ‹Ÿåˆç›´çº¿ï¼ˆæ›´ç²¾ç¡®ï¼‰
                inlier_points = points_array[best_inliers]
                vx, vy, cx, cy = cv2.fitLine(inlier_points, cv2.DIST_L2, 0, 0.01, 0.01)
                
                # è®¡ç®—ç›´çº¿è§’åº¦ï¼ˆç›¸å¯¹äºæ°´å¹³è½´ï¼‰
                line_angle = np.arctan2(vy, vx)[0]
                angle_deg = np.degrees(line_angle)
                target_angle = 0
                angle_diff = angle_deg - target_angle
                
                self._line_angle = np.radians(angle_diff)
                self._detected_flags['42'] = True
                
                # æŒç»­å¯¹é½è®¡æ—¶é€»è¾‘
                if abs(self._line_angle) < self._line_threshold:
                    if self._alignment_start_time == 0:
                        self._alignment_start_time = current_time
                    self._aligned_duration = current_time - self._alignment_start_time
                else:
                    self._alignment_start_time = 0.0
                    self._aligned_duration = 0.0
            else:
                self._alignment_start_time = 0.0
                self._aligned_duration = 0.0
                self._detected_flags['42'] = False

            # è°ƒè¯•å›¾åƒå¤„ç†
            debug_img = cv2.cvtColor(mask_combined, cv2.COLOR_GRAY2BGR)
            cv2.rectangle(debug_img, (0, roi_y_start), (width, height), (255, 0, 0), 2)  # ç»˜åˆ¶ROIåŒºåŸŸ
            
            # ç»˜åˆ¶æ‰€æœ‰è¾¹ç•Œç‚¹
            for point in boundary_points:
                cv2.circle(debug_img, tuple(point), 2, (0, 255, 0), -1)  # ç»¿è‰²ç‚¹è¡¨ç¤ºè¾¹ç•Œç‚¹
            
            # å¦‚æœæ£€æµ‹åˆ°ç›´çº¿ï¼Œç»˜åˆ¶æœ€ä½³æ‹Ÿåˆçº¿å’Œå†…ç‚¹
            if self._detected_flags['42']:
                # ç»˜åˆ¶å†…ç‚¹ï¼ˆè“è‰²ï¼‰
                for idx in best_inliers:
                    point = boundary_points[idx]
                    cv2.circle(debug_img, tuple(point), 3, (255, 0, 0), -1)  # è“è‰²ç‚¹è¡¨ç¤ºå†…ç‚¹
                
                # ç»˜åˆ¶æ‹Ÿåˆç›´çº¿ï¼ˆçº¢è‰²ç²—çº¿ï¼‰
                length = 500
                pt1 = (int(cx - vx * length), int(cy - vy * length))
                pt2 = (int(cx + vx * length), int(cy + vy * length))
                cv2.line(debug_img, pt1, pt2, (0, 0, 255), 3)
                
                # æ˜¾ç¤ºè§’åº¦ä¿¡æ¯
                cv2.putText(debug_img, 
                            f"Points: {len(boundary_points)} | Inliers: {len(best_inliers)} | Angle: {angle_diff:+.1f}\u00B0 | Hold: {self._aligned_duration:.1f}s", 
                            (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            
            # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°åˆé€‚çš„ç›´çº¿
            elif len(boundary_points) >= 10:
                cv2.putText(debug_img, 
                            f"WARNING: No suitable line found ({len(boundary_points)} boundary points)", 
                            (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
            else:
                cv2.putText(debug_img, 
                            f"WARNING: Not enough boundary points ({len(boundary_points)})", 
                            (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
            
            # ç»˜åˆ¶æ‰€æœ‰è½®å»“
            cv2.drawContours(debug_img, contours, -1, (255, 255, 0), 2)  # é’è‰²è½®å»“
            
            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            save_debug_image(f"detect42_{timestamp}.jpg", debug_img)
            
            # å®æ—¶è°ƒè¯•æ˜¾ç¤º
            if self.debug_mode:
                cv2.imshow("Detection Preview", debug_img)
                cv2.waitKey(1)

    def _detect_43(self, cv_image):
        hsv = cv2.cvtColor(cv_image, cv2.COLOR_BGR2HSV)
        height, width = hsv.shape[:2]
        roi_height1 = 20
        roi_height2 = roi_height1 - 20
        x_start = width // 4
        x_end = 3 * width // 4
        roi = hsv[height-roi_height1:height - roi_height2, x_start:x_end]
        
        mask = cv2.inRange(roi, self.lower_yellow, self.upper_yellow)
        kernel = np.ones((3,3), np.uint8)
        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
        
        yellow_ratio = np.count_nonzero(mask) / (roi.size + 1e-5)  # é˜²æ­¢é™¤é›¶
        with self._lock:
            current_time = time.time()
            if yellow_ratio > self.detection_threshold:
                self._detected_flags['43'] = True
                '''if current_time - self._last_detection_time < 0.5:
                    self._detected_flags['43'] = True
                else:
                    self._detected_flags['43'] = False  # é‡ç½®çŸ­æš‚æ£€æµ‹'''
                self._last_detection_time = current_time
            else:
                self._detected_flags['43'] = False

        # è°ƒè¯•æ˜¾ç¤º
        if self.debug_mode:
            debug_img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
            cv2.rectangle(debug_img, 
                        (x_start, height-roi_height1),
                        (x_end, height - roi_height2),
                        (0,255,0), 2)
            cv2.imshow("Detection Preview", debug_img)
            cv2.waitKey(1)

    def _detect_45(self, cv_image):
        # é¢„å¤„ç†
        blurred = cv2.GaussianBlur(cv_image, (5, 5), 0)
        hsv = cv2.cvtColor(blurred, cv2.COLOR_BGR2HSV)

        # ä½¿ç”¨é…ç½®æ¨¡å—æå–é»„è‰²æ©ç 
        mask_combined = get_combined_color_mask(hsv, YELLOW_COMBINED_KEYS)
        mask_combined = cv2.morphologyEx(mask_combined, cv2.MORPH_OPEN, MORPH_KERNEL)
        mask_combined = cv2.morphologyEx(mask_combined, cv2.MORPH_CLOSE, MORPH_KERNEL)
        
        # åªä¿ç•™æœ€å¤§çš„ä¸¤ä¸ªè¿é€šåŸŸ
        num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(mask_combined, connectivity=8)
        clean_mask = np.zeros_like(mask_combined)
        if num_labels > 1:
            areas = stats[1:, cv2.CC_STAT_AREA]
            sorted_idx = np.argsort(areas)[::-1] + 1
            for i in sorted_idx[:min(2, len(sorted_idx))]:
                clean_mask[labels == i] = 255
        mask_combined = clean_mask

        # åˆ›å»ºROIèšç„¦å›¾åƒåº•éƒ¨ (é«˜åº¦1/2åŒºåŸŸ)
        height, width = mask_combined.shape[:2]
        roi_y_start = height - height // 2
        roi_x_start =2 * width // 5
        roi_x_end = 3 * width // 5
        roi_mask = np.zeros_like(mask_combined)
        roi_mask[roi_y_start:, roi_x_start:roi_x_end] = 255
        masked_roi = cv2.bitwise_and(mask_combined, roi_mask)

        # === ä¸“ä¸šæ–¹æ³•ï¼šæ£€æµ‹é»„è‰²è¾¹çº¿çš„å®é™…è¾¹ç•Œ ===
        # 1. æ‰¾åˆ°é»„è‰²åŒºåŸŸçš„è½®å»“
        contour_result = cv2.findContours(mask_combined, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if len(contour_result) == 3:  # OpenCV 3.x
            contours = contour_result[1]
        elif len(contour_result) == 2:  # OpenCV 4.x
            contours = contour_result[0]
        else:
            contours = contour_result
        # 2. æå–æ‰€æœ‰è¾¹ç•Œç‚¹
        boundary_points = []
        
        # 3. å¯¹æ¯ä¸ªè½®å»“ï¼Œæå–å…¶åº•éƒ¨è¾¹ç•Œç‚¹
        for contour in contours:
            # åˆ›å»ºè½®å»“çš„è¾¹ç•Œæ¡†
            x, y, w, h = cv2.boundingRect(contour)
            
            # åªå¤„ç†ROIåŒºåŸŸå†…çš„è½®å»“
            if y + h < roi_y_start:
                continue
            
            # åˆ›å»ºè½®å»“çš„æ©ç 
            contour_mask = np.zeros_like(mask_combined)
            cv2.drawContours(contour_mask, [contour], -1, 255, thickness=cv2.FILLED)
            
            # å¯¹è½®å»“è¿›è¡Œå¤šè¾¹å½¢è¿‘ä¼¼
            epsilon = 0.005 * cv2.arcLength(contour, True)
            approx = cv2.approxPolyDP(contour, epsilon, True)
            
            # æå–è½®å»“çš„åº•éƒ¨è¾¹ç¼˜ç‚¹
            for point in approx.squeeze():
                px, py = point
                # åªè€ƒè™‘ROIåŒºåŸŸå†…çš„ç‚¹
                if py < roi_y_start:
                    continue
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯åº•éƒ¨ç‚¹ï¼šè¯¥ç‚¹ä¸‹æ–¹ä¸æ˜¯é»„è‰²åŒºåŸŸ
                if py < height - 1:
                    if mask_combined[py + 1, px] == 0:  # ä¸‹æ–¹åƒç´ æ˜¯èƒŒæ™¯
                        boundary_points.append([px, py])
        
        # 4. å¦‚æœæ²¡æœ‰è¶³å¤Ÿè¾¹ç•Œç‚¹ï¼Œå°è¯•å¤‡ç”¨æ–¹æ³•
        if len(boundary_points) < 20:
            # å¤‡ç”¨æ–¹æ³•ï¼šé€åˆ—æ‰«æåº•éƒ¨è¾¹ç¼˜
            boundary_points = []
            for x in range(2 * width // 5, 3 * width // 5):
                for y in range(height - 2, roi_y_start - 1, -1):
                    if mask_combined[y, x] == 255 and mask_combined[y + 1, x] == 0:
                        boundary_points.append([x, y])
                        break  # æ‰¾åˆ°è¯¥åˆ—çš„ç¬¬ä¸€ä¸ªè¾¹ç•Œç‚¹å³åœæ­¢
        
        # 5. ä½¿ç”¨RANSACç®—æ³•è¿›è¡Œç¨³å¥ç›´çº¿æ‹Ÿåˆ
        best_line = None
        best_inliers = []
        max_inliers = 0
        
        if len(boundary_points) >= 10:
            points_array = np.array(boundary_points)
            
            # ä½¿ç”¨RANSACå¤šæ¬¡è¿­ä»£å¯»æ‰¾æœ€ä½³æ‹Ÿåˆçº¿
            for _ in range(2):
                # éšæœºé€‰æ‹©ä¸¤ä¸ªç‚¹
                idx = np.random.choice(len(points_array), 2, replace=False)
                p1, p2 = points_array[idx[0]], points_array[idx[1]]
                
                # è®¡ç®—ç›´çº¿å‚æ•°
                dx = p2[0] - p1[0]
                dy = p2[1] - p1[1]
                if dx == 0:  # é¿å…é™¤ä»¥é›¶
                    continue
                    
                # ç›´çº¿æ–¹ç¨‹: y = mx + c
                m = dy / dx
                c = p1[1] - m * p1[0]
                
                # è®¡ç®—æ‰€æœ‰ç‚¹åˆ°ç›´çº¿çš„è·ç¦»
                distances = []
                for point in points_array:
                    px, py = point
                    # ç‚¹åˆ°ç›´çº¿çš„è·ç¦»å…¬å¼
                    dist = abs(m * px - py + c) / np.sqrt(m**2 + 1)
                    distances.append(dist)
                
                # ç»Ÿè®¡å†…ç‚¹ï¼ˆè·ç¦»å°äºé˜ˆå€¼çš„ç‚¹ï¼‰
                inlier_threshold = 2.0  # åƒç´ è·ç¦»é˜ˆå€¼
                inliers = [i for i, dist in enumerate(distances) if dist < inlier_threshold]
                
                if len(inliers) > max_inliers:
                    max_inliers = len(inliers)
                    best_inliers = inliers
                    best_line = (m, c, p1, p2)
        
        current_time = time.time()
        with self._lock:
            self._detected_flags['45'] = False
            self._line_angle = 0.0
            
            if best_line is not None and len(best_inliers) >= 10:
                m, c, p1, p2 = best_line
                
                # ä½¿ç”¨å†…ç‚¹é‡æ–°æ‹Ÿåˆç›´çº¿ï¼ˆæ›´ç²¾ç¡®ï¼‰
                inlier_points = points_array[best_inliers]
                vx, vy, cx, cy = cv2.fitLine(inlier_points, cv2.DIST_L2, 0, 0.01, 0.01)
                
                # è®¡ç®—ç›´çº¿è§’åº¦ï¼ˆç›¸å¯¹äºæ°´å¹³è½´ï¼‰
                line_angle = np.arctan2(vy, vx)[0]
                angle_deg = np.degrees(line_angle)
                target_angle = 0
                angle_diff = angle_deg - target_angle
                
                self._line_angle = np.radians(angle_diff)
                self._detected_flags['45'] = True
                
                # æŒç»­å¯¹é½è®¡æ—¶é€»è¾‘
                if abs(self._line_angle) < self._line_threshold:
                    if self._alignment_start_time == 0:
                        self._alignment_start_time = current_time
                    self._aligned_duration = current_time - self._alignment_start_time
                else:
                    self._alignment_start_time = 0.0
                    self._aligned_duration = 0.0
            else:
                self._alignment_start_time = 0.0
                self._aligned_duration = 0.0
                self._detected_flags['45'] = False

            # è°ƒè¯•å›¾åƒå¤„ç†
            debug_img = cv2.cvtColor(mask_combined, cv2.COLOR_GRAY2BGR)
            cv2.rectangle(debug_img, (0, roi_y_start), (width, height), (255, 0, 0), 2)  # ç»˜åˆ¶ROIåŒºåŸŸ
            
            # ç»˜åˆ¶æ‰€æœ‰è¾¹ç•Œç‚¹
            for point in boundary_points:
                cv2.circle(debug_img, tuple(point), 2, (0, 255, 0), -1)  # ç»¿è‰²ç‚¹è¡¨ç¤ºè¾¹ç•Œç‚¹
            
            # å¦‚æœæ£€æµ‹åˆ°ç›´çº¿ï¼Œç»˜åˆ¶æœ€ä½³æ‹Ÿåˆçº¿å’Œå†…ç‚¹
            if self._detected_flags['45']:
                # ç»˜åˆ¶å†…ç‚¹ï¼ˆè“è‰²ï¼‰
                for idx in best_inliers:
                    point = boundary_points[idx]
                    cv2.circle(debug_img, tuple(point), 3, (255, 0, 0), -1)  # è“è‰²ç‚¹è¡¨ç¤ºå†…ç‚¹
                
                # ç»˜åˆ¶æ‹Ÿåˆç›´çº¿ï¼ˆçº¢è‰²ç²—çº¿ï¼‰
                length = 500
                pt1 = (int(cx - vx * length), int(cy - vy * length))
                pt2 = (int(cx + vx * length), int(cy + vy * length))
                cv2.line(debug_img, pt1, pt2, (0, 0, 255), 3)
                
                # æ˜¾ç¤ºè§’åº¦ä¿¡æ¯
                cv2.putText(debug_img, 
                            f"Points: {len(boundary_points)} | Inliers: {len(best_inliers)} | Angle: {angle_diff:+.1f}\u00B0 | Hold: {self._aligned_duration:.1f}s", 
                            (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            
            # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°åˆé€‚çš„ç›´çº¿
            elif len(boundary_points) >= 10:
                cv2.putText(debug_img, 
                            f"WARNING: No suitable line found ({len(boundary_points)} boundary points)", 
                            (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
            else:
                cv2.putText(debug_img, 
                            f"WARNING: Not enough boundary points ({len(boundary_points)})", 
                            (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
            
            # ç»˜åˆ¶æ‰€æœ‰è½®å»“
            cv2.drawContours(debug_img, contours, -1, (255, 255, 0), 2)  # é’è‰²è½®å»“
            
            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            save_debug_image(f"detect45_{timestamp}.jpg", debug_img)
            
            # å®æ—¶è°ƒè¯•æ˜¾ç¤º
            if self.debug_mode:
                cv2.imshow("Detection Preview", debug_img)
                cv2.waitKey(1)

    def _detect_46(self, cv_image):
        # === 1. é¢„å¤„ç†å¹¶è½¬æ¢ä¸º HSV ===
        blurred = cv2.GaussianBlur(cv_image, (5, 5), 0)
        hsv = cv2.cvtColor(blurred, cv2.COLOR_BGR2HSV)
        height, width = hsv.shape[:2]

       # å®šä¹‰ ROI ä½ç½®ï¼šä½äºåº•éƒ¨å¾€ä¸Š 1/4 é«˜åº¦çš„ä½ç½®
        quarter_height = height // 6
        roi_center_y = height - quarter_height  # è·ç¦»åº•éƒ¨ 1/4 çš„ä½ç½®ï¼ˆå³æ•´ä½“çš„ 3/4 å¤„ï¼‰

        # å®šä¹‰ ROI é«˜åº¦ï¼ˆä¾‹å¦‚ 20 åƒç´ é«˜ï¼‰
        roi_height = height // 32

        # è®¡ç®—ä¸Šä¸‹è¾¹ç•Œ
        y_start = roi_center_y - roi_height // 2
        y_end = roi_center_y + roi_height // 2

        # ç¡®ä¿ä¸è¶Šç•Œ
        y_start = max(y_start, 0)
        y_end = min(y_end, height)

        # æ¨ªå‘ï¼šæ•´å¹…å®½åº¦
        x_start = width // 5 * 2
        x_end = width //5 * 3 # æˆ–ç›´æ¥ç”¨ width

        # æå– ROI
        roi_hsv = hsv[y_start:y_end, x_start:x_end]

        # === 3. ä½¿ç”¨æ¨¡å—å‡½æ•°ç”Ÿæˆâ€œé»„+æ³›ç™½é»„â€æ©ç  ===
        mask_combined = get_combined_color_mask(roi_hsv, YELLOW_COMBINED_KEYS)

        # === 4. å½¢æ€å­¦å»å™ª ===
        mask_combined = cv2.morphologyEx(mask_combined, cv2.MORPH_OPEN, MORPH_KERNEL)
        mask_combined = cv2.morphologyEx(mask_combined, cv2.MORPH_CLOSE, MORPH_KERNEL)

        # === 5. é»„è‰²åƒç´ å æ¯”è®¡ç®— ===
        yellow_ratio = np.count_nonzero(mask_combined) / (mask_combined.size + 1e-5)

        with self._lock:
            if yellow_ratio > 0.5:
                self._detected_flags['46'] = True
            else:
                self._detected_flags['46'] = False

        debug_img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
        cv2.rectangle(debug_img,
                    (x_start, y_start),           # å·¦ä¸Šè§’
                    (x_end, y_end),             # å³ä¸‹è§’
                    (0, 255, 0), 2)          # ç»¿è‰²æ¡†ï¼Œçº¿å®½ 2
        cv2.putText(debug_img, f"Yellow Ratio: {yellow_ratio:.3f}", (10, 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)
        cv2.putText(debug_img, f"Detected: {self._detected_flags['9']}", (10, 60),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255) if not self._detected_flags['9'] else (0, 255, 0), 2)
        
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S_%f")  # ç²¾ç¡®åˆ°å¾®ç§’
        save_debug_image(f"detect46_{timestamp}.jpg", debug_img)
        # è°ƒè¯•æ˜¾ç¤º
        if self.debug_mode:
            cv2.imshow("Detection Preview", debug_img)
            cv2.waitKey(1)

        if self.real_debug_mode:
            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S_%f")  # ç²¾ç¡®åˆ°å¾®ç§’
            filename = f"detect46_{timestamp}.jpg"

            save_debug_image(filename, debug_img)

    def _detect_47(self, cv_image):
        hsv = cv2.cvtColor(cv_image, cv2.COLOR_BGR2HSV)
        height, width = hsv.shape[:2]
        
        roi_height = height // 5
        roi_height1 = roi_height - 20
        x_start = 2 * width // 5
        x_end = 3 * width // 5
        roi = hsv[height-roi_height:height-roi_height1, x_start:x_end]
        
        mask = cv2.inRange(roi, self.lower_yellow, self.upper_yellow)
        kernel = np.ones((3,3), np.uint8)
        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
        yellow_ratio = np.count_nonzero(mask) / (roi.size + 1e-5)
        debug_img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
        cv2.rectangle(debug_img, 
                    (x_start, height-roi_height),
                    (x_end, height),
                    (0,255,0), 2)
        cv2.putText(debug_img, f"Y10: {yellow_ratio:.2f}", (x_start+10, height-10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,0), 2)
        
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S_%f")  # ç²¾ç¡®åˆ°å¾®ç§’
        save_debug_image(f"detect47_{timestamp}_{yellow_ratio}.jpg", debug_img)

        with self._lock:
            current_time = time.time()
            if yellow_ratio < 0.01:
                if current_time - self._last_detection_time < 0.5:
                    self._detected_flags['47'] = True
                else:
                    self._detected_flags['47'] = False
                self._last_detection_time = current_time
            else:
                self._detected_flags['47'] = False

        # è°ƒè¯•æ˜¾ç¤º
        if self.debug_mode:
            debug_img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
            cv2.rectangle(debug_img, 
                        (x_start, height-roi_height),
                        (x_end, height),
                        (0,255,0), 2)
            cv2.putText(debug_img, f"Y10: {yellow_ratio:.2f}", (x_start+10, height-10),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,0), 2)
            cv2.imshow("Detection Preview", debug_img)
            cv2.waitKey(1)

    def _detect_49(self, cv_image):
        hsv = cv2.cvtColor(cv_image, cv2.COLOR_BGR2HSV)
        height, width = hsv.shape[:2]
        roi_height1 = 130
        roi_height2 = roi_height1 - 10
        x_start = 0 if QR1 == 'A-2' else 15 * width // 16
        x_end = x_start + width//16
        roi = hsv[height-roi_height1:height - roi_height2, x_start:x_end]
        
        '''mask = cv2.inRange(roi, self.lower_yellow, self.upper_yellow)
        kernel = np.ones((3,3), np.uint8)
        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
        
        yellow_ratio = np.count_nonzero(mask) / (roi.size + 1e-5)  # é˜²æ­¢é™¤é›¶'''
        
        mask_combined = get_combined_color_mask(roi, YELLOW_COMBINED_KEYS)

        # === 4. å½¢æ€å­¦å»å™ª ===
        mask_combined = cv2.morphologyEx(mask_combined, cv2.MORPH_OPEN, MORPH_KERNEL)
        mask_combined = cv2.morphologyEx(mask_combined, cv2.MORPH_CLOSE, MORPH_KERNEL)

        # === 5. é»„è‰²åƒç´ å æ¯”è®¡ç®— ===
        yellow_ratio = np.count_nonzero(mask_combined) / (mask_combined.size + 1e-5)

        with self._lock:
            current_time = time.time()
            if yellow_ratio > self.detection_threshold:
                self._detected_flags['49'] = True
                '''if current_time - self._last_detection_time < 0.5:
                    self._detected_flags['49'] = True
                else:
                    self._detected_flags['49'] = False  # é‡ç½®çŸ­æš‚æ£€æµ‹'''
                self._last_detection_time = current_time
            else:
                self._detected_flags['49'] = False
        debug_img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
        cv2.rectangle(debug_img,
                    (x_start, height-roi_height1),           # å·¦ä¸Šè§’
                    (x_end, height - roi_height2),             # å³ä¸‹è§’
                    (0, 255, 0), 2)          # ç»¿è‰²æ¡†ï¼Œçº¿å®½ 2
        cv2.putText(debug_img, f"Yellow Ratio: {yellow_ratio:.3f}", (10, 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)
        cv2.putText(debug_img, f"Detected: {self._detected_flags['49']}", (10, 60),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255) if not self._detected_flags['9'] else (0, 255, 0), 2)
        
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S_%f")  # ç²¾ç¡®åˆ°å¾®ç§’
        save_debug_image(f"detect49_{timestamp}.jpg", debug_img)

        # è°ƒè¯•æ˜¾ç¤º
        if self.debug_mode:
            debug_img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
            cv2.rectangle(debug_img, 
                        (x_start, height-roi_height1),
                        (x_end, height-roi_height2),
                        (0,255,0), 2)
            cv2.imshow("Detection Preview", debug_img)
            cv2.waitKey(1)

    def _detect_50(self, cv_image):
        # é¢„å¤„ç†
        blurred = cv2.GaussianBlur(cv_image, (5, 5), 0)
        hsv = cv2.cvtColor(blurred, cv2.COLOR_BGR2HSV)

        # ä½¿ç”¨é…ç½®æ¨¡å—æå–é»„è‰²æ©ç 
        mask_combined = get_combined_color_mask(hsv, YELLOW_COMBINED_KEYS)
        mask_combined = cv2.morphologyEx(mask_combined, cv2.MORPH_OPEN, MORPH_KERNEL)
        mask_combined = cv2.morphologyEx(mask_combined, cv2.MORPH_CLOSE, MORPH_KERNEL)
        
        # åªä¿ç•™æœ€å¤§çš„ä¸¤ä¸ªè¿é€šåŸŸ
        num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(mask_combined, connectivity=8)
        clean_mask = np.zeros_like(mask_combined)
        if num_labels > 1:
            areas = stats[1:, cv2.CC_STAT_AREA]
            sorted_idx = np.argsort(areas)[::-1] + 1
            for i in sorted_idx[:min(2, len(sorted_idx))]:
                clean_mask[labels == i] = 255
        mask_combined = clean_mask

        # åˆ›å»ºROIèšç„¦å›¾åƒåº•éƒ¨ (é«˜åº¦1/2åŒºåŸŸ)
        height, width = mask_combined.shape[:2]
        roi_y_start = height - height // 2
        roi_mask = np.zeros_like(mask_combined)
        roi_mask[roi_y_start:, width // 5:3 * width // 5] = 255
        masked_roi = cv2.bitwise_and(mask_combined, roi_mask)

        # === ä¸“ä¸šæ–¹æ³•ï¼šæ£€æµ‹é»„è‰²è¾¹çº¿çš„å®é™…è¾¹ç•Œ ===
        # 1. æ‰¾åˆ°é»„è‰²åŒºåŸŸçš„è½®å»“
        contour_result = cv2.findContours(mask_combined, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if len(contour_result) == 3:  # OpenCV 3.x
            contours = contour_result[1]
        elif len(contour_result) == 2:  # OpenCV 4.x
            contours = contour_result[0]
        else:
            contours = contour_result
        # 2. æå–æ‰€æœ‰è¾¹ç•Œç‚¹
        boundary_points = []
        
        # 3. å¯¹æ¯ä¸ªè½®å»“ï¼Œæå–å…¶åº•éƒ¨è¾¹ç•Œç‚¹
        for contour in contours:
            # åˆ›å»ºè½®å»“çš„è¾¹ç•Œæ¡†
            x, y, w, h = cv2.boundingRect(contour)
            
            # åªå¤„ç†ROIåŒºåŸŸå†…çš„è½®å»“
            if y + h < roi_y_start:
                continue
            
            # åˆ›å»ºè½®å»“çš„æ©ç 
            contour_mask = np.zeros_like(mask_combined)
            cv2.drawContours(contour_mask, [contour], -1, 255, thickness=cv2.FILLED)
            
            # å¯¹è½®å»“è¿›è¡Œå¤šè¾¹å½¢è¿‘ä¼¼
            epsilon = 0.005 * cv2.arcLength(contour, True)
            approx = cv2.approxPolyDP(contour, epsilon, True)
            
            # æå–è½®å»“çš„åº•éƒ¨è¾¹ç¼˜ç‚¹
            for point in approx.squeeze():
                px, py = point
                # åªè€ƒè™‘ROIåŒºåŸŸå†…çš„ç‚¹
                if py < roi_y_start:
                    continue
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯åº•éƒ¨ç‚¹ï¼šè¯¥ç‚¹ä¸‹æ–¹ä¸æ˜¯é»„è‰²åŒºåŸŸ
                if py < height - 1:
                    if mask_combined[py + 1, px] == 0:  # ä¸‹æ–¹åƒç´ æ˜¯èƒŒæ™¯
                        boundary_points.append([px, py])
        
        # 4. å¦‚æœæ²¡æœ‰è¶³å¤Ÿè¾¹ç•Œç‚¹ï¼Œå°è¯•å¤‡ç”¨æ–¹æ³•
        if len(boundary_points) < 20:
            # å¤‡ç”¨æ–¹æ³•ï¼šé€åˆ—æ‰«æåº•éƒ¨è¾¹ç¼˜
            boundary_points = []
            for x in range(width // 5, 3 * width // 5):
                for y in range(height - 2, roi_y_start - 1, -1):
                    if mask_combined[y, x] == 255 and mask_combined[y + 1, x] == 0:
                        boundary_points.append([x, y])
                        break  # æ‰¾åˆ°è¯¥åˆ—çš„ç¬¬ä¸€ä¸ªè¾¹ç•Œç‚¹å³åœæ­¢
        
        # 5. ä½¿ç”¨RANSACç®—æ³•è¿›è¡Œç¨³å¥ç›´çº¿æ‹Ÿåˆ
        best_line = None
        best_inliers = []
        max_inliers = 0
        
        if len(boundary_points) >= 10:
            points_array = np.array(boundary_points)
            
            # ä½¿ç”¨RANSACå¤šæ¬¡è¿­ä»£å¯»æ‰¾æœ€ä½³æ‹Ÿåˆçº¿
            for _ in range(5):
                # éšæœºé€‰æ‹©ä¸¤ä¸ªç‚¹
                idx = np.random.choice(len(points_array), 2, replace=False)
                p1, p2 = points_array[idx[0]], points_array[idx[1]]
                
                # è®¡ç®—ç›´çº¿å‚æ•°
                dx = p2[0] - p1[0]
                dy = p2[1] - p1[1]
                if dx == 0:  # é¿å…é™¤ä»¥é›¶
                    continue
                    
                # ç›´çº¿æ–¹ç¨‹: y = mx + c
                m = dy / dx
                c = p1[1] - m * p1[0]
                
                # è®¡ç®—æ‰€æœ‰ç‚¹åˆ°ç›´çº¿çš„è·ç¦»
                distances = []
                for point in points_array:
                    px, py = point
                    # ç‚¹åˆ°ç›´çº¿çš„è·ç¦»å…¬å¼
                    dist = abs(m * px - py + c) / np.sqrt(m**2 + 1)
                    distances.append(dist)
                
                # ç»Ÿè®¡å†…ç‚¹ï¼ˆè·ç¦»å°äºé˜ˆå€¼çš„ç‚¹ï¼‰
                inlier_threshold = 2.0  # åƒç´ è·ç¦»é˜ˆå€¼
                inliers = [i for i, dist in enumerate(distances) if dist < inlier_threshold]
                
                if len(inliers) > max_inliers:
                    max_inliers = len(inliers)
                    best_inliers = inliers
                    best_line = (m, c, p1, p2)
        
        current_time = time.time()
        with self._lock:
            self._detected_flags['50'] = False
            self._line_angle = 0.0
            
            if best_line is not None and len(best_inliers) >= 10:
                m, c, p1, p2 = best_line
                
                # ä½¿ç”¨å†…ç‚¹é‡æ–°æ‹Ÿåˆç›´çº¿ï¼ˆæ›´ç²¾ç¡®ï¼‰
                inlier_points = points_array[best_inliers]
                vx, vy, cx, cy = cv2.fitLine(inlier_points, cv2.DIST_L2, 0, 0.01, 0.01)
                
                # è®¡ç®—ç›´çº¿è§’åº¦ï¼ˆç›¸å¯¹äºæ°´å¹³è½´ï¼‰
                line_angle = np.arctan2(vy, vx)[0]
                angle_deg = np.degrees(line_angle)
                target_angle = 0
                angle_diff = angle_deg - target_angle
                
                self._line_angle = np.radians(angle_diff)
                self._detected_flags['50'] = True
                
                # æŒç»­å¯¹é½è®¡æ—¶é€»è¾‘
                if abs(self._line_angle) < self._line_threshold:
                    if self._alignment_start_time == 0:
                        self._alignment_start_time = current_time
                    self._aligned_duration = current_time - self._alignment_start_time
                else:
                    self._alignment_start_time = 0.0
                    self._aligned_duration = 0.0
            else:
                self._alignment_start_time = 0.0
                self._aligned_duration = 0.0
                self._detected_flags['50'] = False

            # è°ƒè¯•å›¾åƒå¤„ç†
            debug_img = cv2.cvtColor(mask_combined, cv2.COLOR_GRAY2BGR)
            cv2.rectangle(debug_img, (0, roi_y_start), (width, height), (255, 0, 0), 2)  # ç»˜åˆ¶ROIåŒºåŸŸ
            
            # ç»˜åˆ¶æ‰€æœ‰è¾¹ç•Œç‚¹
            for point in boundary_points:
                cv2.circle(debug_img, tuple(point), 2, (0, 255, 0), -1)  # ç»¿è‰²ç‚¹è¡¨ç¤ºè¾¹ç•Œç‚¹
            
            # å¦‚æœæ£€æµ‹åˆ°ç›´çº¿ï¼Œç»˜åˆ¶æœ€ä½³æ‹Ÿåˆçº¿å’Œå†…ç‚¹
            if self._detected_flags['50']:
                # ç»˜åˆ¶å†…ç‚¹ï¼ˆè“è‰²ï¼‰
                for idx in best_inliers:
                    point = boundary_points[idx]
                    cv2.circle(debug_img, tuple(point), 3, (255, 0, 0), -1)  # è“è‰²ç‚¹è¡¨ç¤ºå†…ç‚¹
                
                # ç»˜åˆ¶æ‹Ÿåˆç›´çº¿ï¼ˆçº¢è‰²ç²—çº¿ï¼‰
                length = 500
                pt1 = (int(cx - vx * length), int(cy - vy * length))
                pt2 = (int(cx + vx * length), int(cy + vy * length))
                cv2.line(debug_img, pt1, pt2, (0, 0, 255), 3)
                
                # æ˜¾ç¤ºè§’åº¦ä¿¡æ¯
                cv2.putText(debug_img, 
                            f"Points: {len(boundary_points)} | Inliers: {len(best_inliers)} | Angle: {angle_diff:+.1f}\u00B0 | Hold: {self._aligned_duration:.1f}s", 
                            (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            
            # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°åˆé€‚çš„ç›´çº¿
            elif len(boundary_points) >= 10:
                cv2.putText(debug_img, 
                            f"WARNING: No suitable line found ({len(boundary_points)} boundary points)", 
                            (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
            else:
                cv2.putText(debug_img, 
                            f"WARNING: Not enough boundary points ({len(boundary_points)})", 
                            (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
            
            # ç»˜åˆ¶æ‰€æœ‰è½®å»“
            cv2.drawContours(debug_img, contours, -1, (255, 255, 0), 2)  # é’è‰²è½®å»“
            
            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            save_debug_image(f"detect50_{timestamp}.jpg", debug_img)
            
            # å®æ—¶è°ƒè¯•æ˜¾ç¤º
            if self.debug_mode:
                cv2.imshow("Detection Preview", debug_img)
                cv2.waitKey(1)

    def _detect_51(self, cv_image):
        blurred = cv2.GaussianBlur(cv_image, (5, 5), 0)
        hsv = cv2.cvtColor(blurred, cv2.COLOR_BGR2HSV)
        height, width = hsv.shape[:2]

        # å®šä¹‰ ROI ä½ç½®ï¼šä½äºåº•éƒ¨å¾€ä¸Š 1/4 é«˜åº¦çš„ä½ç½®
        quarter_height = height // 3
        roi_center_y = height - quarter_height  # è·ç¦»åº•éƒ¨ 1/4 çš„ä½ç½®ï¼ˆå³æ•´ä½“çš„ 3/4 å¤„ï¼‰

        # å®šä¹‰ ROI é«˜åº¦ï¼ˆä¾‹å¦‚ 20 åƒç´ é«˜ï¼‰
        roi_height = height // 32

        # è®¡ç®—ä¸Šä¸‹è¾¹ç•Œ
        y_start = roi_center_y - roi_height // 2
        y_end = roi_center_y + roi_height // 2

        # ç¡®ä¿ä¸è¶Šç•Œ
        y_start = max(y_start, 0)
        y_end = min(y_end, height)

        # æ¨ªå‘ï¼šæ•´å¹…å®½åº¦
        x_start = 2 * width // 5
        x_end = 3 * width // 5  # æˆ–ç›´æ¥ç”¨ width

        # æå– ROI
        roi_hsv = hsv[y_start:y_end, x_start:x_end]

        mask_combined = get_combined_color_mask(roi_hsv, YELLOW_COMBINED_KEYS)

        # === 4. å½¢æ€å­¦å»å™ª ===
        mask_combined = cv2.morphologyEx(mask_combined, cv2.MORPH_OPEN, MORPH_KERNEL)
        mask_combined = cv2.morphologyEx(mask_combined, cv2.MORPH_CLOSE, MORPH_KERNEL)

        # === 5. é»„è‰²åƒç´ å æ¯”è®¡ç®— ===
        yellow_ratio = np.count_nonzero(mask_combined) / (mask_combined.size + 1e-5)
        
        with self._lock:
            if yellow_ratio > 0.5:
                self._detected_flags['51'] = True
            else:
                self._detected_flags['51'] = False 

        debug_img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
        cv2.rectangle(debug_img,
                    (x_start, y_start),           # å·¦ä¸Šè§’
                    (x_end, y_end),             # å³ä¸‹è§’
                    (0, 255, 0), 2)          # ç»¿è‰²æ¡†ï¼Œçº¿å®½ 2
        cv2.putText(debug_img, f"Yellow Ratio: {yellow_ratio:.3f}", (10, 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)
        cv2.putText(debug_img, f"Detected: {self._detected_flags['14']}", (10, 60),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255) if not self._detected_flags['14'] else (0, 255, 0), 2)
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        save_debug_image(f"detect51_{timestamp}_{yellow_ratio}.jpg", debug_img)
        # è°ƒè¯•æ˜¾ç¤º
        if self.debug_mode:
            cv2.imshow("Detection Preview", debug_img)
            cv2.waitKey(1)

        if self.real_debug_mode:
            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S_%f")  # ç²¾ç¡®åˆ°å¾®ç§’
            filename = f"detect51_{timestamp}.jpg"

            save_debug_image(filename, debug_img)
    
    def _detect_52(self, cv_image):
        hsv = cv2.cvtColor(cv_image, cv2.COLOR_BGR2HSV)
        height, width = hsv.shape[:2]# åŒºåŸŸå¾…è°ƒæ•´
        roi_height1 = 30
        roi_height2 = roi_height1 - 20
        x_start = 105
        x_end = 215
        roi = hsv[height-roi_height1:height - roi_height2, x_start:width]
        
        mask = cv2.inRange(roi, self.lower_yellow, self.upper_yellow)
        kernel = np.ones((3,3), np.uint8)
        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
        
        yellow_ratio = np.count_nonzero(mask) / (roi.size + 1e-5)  # é˜²æ­¢é™¤é›¶
        with self._lock:
            current_time = time.time()
            if yellow_ratio > self._state9_threshold:
                if current_time - self._last_detection_time < 0.3:
                    self._detected_flags['52'] = True
                else:
                    self._detected_flags['52'] = False  # é‡ç½®çŸ­æš‚æ£€æµ‹
                self._last_detection_time = current_time
            else:
                self._detected_flags['52'] = False

        # è°ƒè¯•æ˜¾ç¤º
        if self.debug_mode:
            debug_img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)
            cv2.rectangle(debug_img, 
                        (x_start, height-roi_height1),
                        (x_end, height - roi_height2),
                        (0,255,0), 2)
            cv2.imshow("Detection Preview", debug_img)
            cv2.waitKey(1)

    @property
    def _0_detected(self):
        with self._lock:
            return self._detected_flags['0']
    
    @property
    def _3_detected(self):
        with self._lock:
            return self._detected_flags['3']
    
    @property
    def yaw_adjust(self):
        with self._lock:
            return self._yaw_adjust
    
    @property
    def lateral_error(self):
        with self._lock:
            return self._lateral_error

    @property
    def yaw_adjust1(self):
        with self._lock:
            return self._yaw_adjust1

    @property
    def _4_detected(self):
        with self._lock:
            return self._detected_flags['4']

    @property
    def _4_5_detected(self):
        with self._lock:
            return self._detected_flags['4_5']
        
    @property
    def _5_detected(self):
        with self._lock:
            return self._detected_flags['5']
        
    @property
    def _6_detected(self):
        with self._lock:
            return self._detected_flags['6']

    @property
    def _8_detected(self):
        with self._lock:
            return self._detected_flags['8']

    @property
    def _9_detected(self):
        with self._lock:
            return self._detected_flags['9']

    @property
    def _10_detected(self):
        with self._lock:
            return self._detected_flags['10']
    
    @property
    def _12_detected(self):
        with self._lock:
            return self._detected_flags['12']
        
    @property
    def _13_detected(self):
        with self._lock:
            return self._detected_flags['13']

    @property
    def _14_detected(self):
        with self._lock:
            return self._detected_flags['14']
           
    @property
    def _15_detected(self):
        with self._lock:
            return self._detected_flags['15']

    @property
    def _16_detected(self):
        with self._lock:
            return self._detected_flags['16']
    
    @property
    def _17_detected(self):
        with self._lock:
            return self._detected_flags['17']

    @property
    def _18_detected(self):
        with self._lock:
            return self._detected_flags['18']
        
    @property
    def _18_5_detected(self):
        with self._lock:
            return self._detected_flags['18_5']
    
    @property
    def _19_detected(self):
        with self._lock:
            return self._detected_flags['19']

    @property
    def _19_5_detected(self):
        with self._lock:
            return self._detected_flags['19_5']
    
    @property
    def _19_55_detected(self):
        with self._lock:
            return self._detected_flags['19_55']

    @property
    def _19_6_detected(self):
        with self._lock:
            return self._detected_flags['19_6']
        
    @property
    def _20_detected(self):
        with self._lock:
            return self._detected_flags['20']
    
    @property
    def _21_detected(self):
        with self._lock:
            return self._detected_flags['21']

    @property
    def _22_detected(self):
        with self._lock:
            return self._detected_flags['22']
         
    @property
    def _23_detected(self):
        with self._lock:
            return self._detected_flags['23']
    
    @property
    def _24_detected(self):
        with self._lock:
            return self._detected_flags['24']

    @property
    def _25_detected(self):
        with self._lock:
            return self._detected_flags['25']
    
    @property
    def _26_detected(self):
        with self._lock:
            return self._detected_flags['26']
    
    @property
    def _27_detected(self):
        with self._lock:
            return self._detected_flags['27']
    
    @property
    def _28_detected(self):
        with self._lock:
            return self._detected_flags['28']
    
    @property
    def _29_detected(self):
        with self._lock:
            return self._detected_flags['29']
    
    @property
    def _30_detected(self):
        with self._lock:
            return self._detected_flags['30']
    
    @property
    def _31_detected(self):
        with self._lock:
            return self._detected_flags['31']
    
    @property
    def _32_detected(self):
        with self._lock:
            return self._detected_flags['32']
    
    @property
    def _33_detected(self):
        with self._lock:
            return self._detected_flags['33']
    
    @property
    def _34_detected(self):
        with self._lock:
            return self._detected_flags['34']
    
    @property
    def _34_5_detected(self):
        with self._lock:
            return self._detected_flags['34_5']
        
    @property
    def _35_detected(self):
        with self._lock:
            return self._detected_flags['35']
    
    @property
    def _35_5_detected(self):
        with self._lock:
            return self._detected_flags['35_5']
    
    @property
    def _36_detected(self):
        with self._lock:
            return self._detected_flags['36']
        
    @property
    def _36_5_detected(self):
        with self._lock:
            return self._detected_flags['36_5']
    
    @property
    def _37_detected(self):
        with self._lock:
            return self._detected_flags['37']
    
    @property
    def _38_detected(self):
        with self._lock:
            return self._detected_flags['38']
    
    @property
    def _39_detected(self):
        with self._lock:
            return self._detected_flags['39']
    
    @property
    def _39_55_detected(self):
        with self._lock:
            return self._detected_flags['39_55']

    @property
    def _40_detected(self):
        with self._lock:
            return self._detected_flags['40']
    
    @property
    def _41_detected(self):
        with self._lock:
            return self._detected_flags['41']
    
    @property
    def _42_detected(self):
        with self._lock:
            return self._detected_flags['42']
    
    @property
    def _43_detected(self):
        with self._lock:
            return self._detected_flags['43']
    
    @property
    def _44_detected(self):
        with self._lock:
            return self._detected_flags['44']
    
    @property
    def _45_detected(self):
        with self._lock:
            return self._detected_flags['45']
    
    @property
    def _46_detected(self):
        with self._lock:
            return self._detected_flags['46']
    
    @property
    def _47_detected(self):
        with self._lock:
            return self._detected_flags['47']
    
    @property
    def _48_detected(self):
        with self._lock:
            return self._detected_flags['48']
    
    @property
    def _49_detected(self):
        with self._lock:
            return self._detected_flags['49']
    
    @property
    def _50_detected(self):
        with self._lock:
            return self._detected_flags['50']
    
    @property
    def _51_detected(self):
        with self._lock:
            return self._detected_flags['51']
    
    @property
    def _52_detected(self):
        with self._lock:
            return self._detected_flags['52']
    
    @property
    def limit_height_distance(self):
        with self._lock:
            return self._limit_height_distance
    
    @property
    def yellow_light_distance(self):
        with self._lock:
            return self._yellow_light_distance
    
    @property
    def line_angle(self):
        with self._lock:
            return self._line_angle

    @property
    def aligned_duration(self):
        with self._lock:
            return self._aligned_duration


def loadtoml(file):
    try:
        steps = toml.load(file)
        for step in steps['step']:
            msg.mode = step['mode']
            msg.value = step['value']
            msg.contact = step['contact']
            msg.gait_id = step['gait_id']
            msg.duration = step['duration']
            msg.life_count = (msg.life_count + 1) % 128
            for i in range(3):
                msg.vel_des[i] = step['vel_des'][i]
                msg.rpy_des[i] = step['rpy_des'][i]
                msg.pos_des[i] = step['pos_des'][i]
                msg.acc_des[i] = step['acc_des'][i]
                msg.acc_des[i+3] = step['acc_des'][i+3]
                msg.foot_pose[i] = step['foot_pose'][i]
                msg.ctrl_point[i] = step['ctrl_point'][i]
            for i in range(2):
                msg.step_height[i] = step['step_height'][i]

            Ctrl.Send_cmd(msg)
            # Ctrl.Wait_finish(msg.mode, msg.gait_id, 10)
            print('robot_control_cmd lcm publish mode :',msg.mode , "gait_id :",msg.gait_id , "msg.duration=" , msg.duration)
                        
            time.sleep( 0.1 )
        # for i in range(300): #60s Heat beat, maintain the heartbeat when life count is not updated
        Ctrl.Send_cmd(msg)
        time.sleep( 0.27 )
            
    except KeyboardInterrupt:
        msg.mode = 7 #PureDamper before KeyboardInterrupt:
        msg.gait_id = 0
        msg.duration = 0
        pass

def main_detection_loop(depth_node, ctrl, msg, trigger_distance, detection_type):
    """ä¸»æ£€æµ‹å¾ªç¯"""
    print(f"\n===== å¼€å§‹{detection_type}æ£€æµ‹ =====")
    
    # ç¡®ä¿èŠ‚ç‚¹æ­£åœ¨è¿è¡Œ
    depth_node.set_node_running(True)
    
    # æ§åˆ¶æœºå™¨äººç›´è¡Œ
    msg.mode = 11
    msg.gait_id = 3
    msg.vel_des = [0.2, -0.005, 0]
    # msg.step_height = [0.04, 0.04]
    msg.life_count =(msg.life_count + 1) %128

    while rclpy.ok():
        detected, distance = depth_node.get_step_info()

        if detected and distance < trigger_distance:
            print(f"**æ£€æµ‹åˆ°{detection_type}!** è·ç¦»: {distance:.2f}ç±³ã€‚")
            # æ£€æµ‹åˆ°ç›®æ ‡åæš‚åœèŠ‚ç‚¹å¤„ç†
            depth_node.set_node_running(False)
            return True
        else:
            status = f"è·ç¦» {distance:.2f}m" if detected else "æ— "
            print(f"å‰æ–¹{detection_type}: {status}ã€‚")

        ctrl.Send_cmd(msg)
        time.sleep(0.1)
    
    return False

def standup():  # ç«™ç«‹
    msg.mode = 12  # Recovery stand
    msg.gait_id = 0
    msg.life_count = (msg.life_count + 1) % 128 # Command will take effect when life_count update
    Ctrl.Send_cmd(msg)
    time.sleep(1)
    # Ctrl.Wait_finish(12, 0, 10)

def stone_road(duration):  # çŸ³æ¿è·¯
    msg.mode = 62
    msg.gait_id = 81
    msg.life_count = (msg.life_count + 1) % 128
    msg.duration = 0
    Ctrl.Send_cmd(msg)
    time.sleep(duration)


def limit(ctrl, msg, duration=9):
    """é™é«˜æ†åŠ¨ä½œ"""
    msg.mode = 62
    msg.gait_id = 80
    msg.life_count = (msg.life_count + 1) % 128
    msg.duration = 0
    ctrl.Send_cmd(msg)
    ctrl.Wait_finish(62, 80, duration)


def upslope(step = 14):  
    msg.mode = 62
    msg.gait_id = 92  
    msg.life_count = (msg.life_count + 1) % 128
    msg.duration = 0
    Ctrl.Send_cmd(msg)
    # time.sleep(2.4 * step - 1.2 + 0.001)
    time.sleep(2.4 * step - 1.8 + 0.001)
    # Ctrl.Wait_finish(62, 92, 2.4 * step - 1.2 + 0.001)

def downslope():  
    msg.mode = 62
    msg.gait_id = 93  
    msg.life_count = (msg.life_count + 1) % 128
    msg.duration = 0
    Ctrl.Send_cmd(msg)
    time.sleep(40)


def stand():
    msg.mode = 112  # Recovery stand
    msg.gait_id = 1
    msg.life_count += 1  # Command will take effect when life_count update
    msg.step_height = [0.03, 0.03, 0.03, 0.03]
    msg.rpy_des = [0.0, 0.0, 0.0]
    msg.duration = 0

    Ctrl.Send_cmd(msg)
    Ctrl.Wait_finish(112, 1, 2)


def new_move(left=None,acc=None):
    if left != None:
        if left == True:
            rgb_camera.left = True
            processor.left = True
        else:
            rgb_camera.left = False
            processor.left = False

    angle_0 = 0.0
    Kp = 6.0
    Kd = 0.8
    max_yaw = 30
    if(acc == None): acc = 5
    #print("start_align")
    while(1):
        frame = rgb_camera.get_new_frame(left)
        # if frame == None:
        #     print('yjm')
        if(processor.main_process(frame) == False):
            continue
        
        current_angle = processor.angle
        if current_angle == None:
            continue
        if abs(current_angle) < acc:
            break
        delta_angle = current_angle - angle_0
        angle_0 = current_angle
        yaw_speed = np.clip(current_angle * Kp + delta_angle * Kd,-max_yaw,max_yaw)
        msg.mode=11
        msg.gait_id=27
        yaw_speed = yaw_speed/180*3.14
        msg.vel_des=[0.03,0.0,-yaw_speed]
        msg.life_count=(msg.life_count+1)%128    
        Ctrl.Send_cmd(msg)
        time.sleep(0.5)
    #print("aligh_over")

def move(flag,adjust):
    vel = 0.06
    if(flag == 0):
        if adjust == adjustment.faraway:
            vel = - vel
        msg.mode=11
        msg.gait_id=27
        msg.vel_des=[0.03,vel,0]
        msg.life_count=(msg.life_count+1)%128    
        Ctrl.Send_cmd(msg)
        time.sleep(0.6)
    else :
        if adjust == adjustment.near:
            vel = - vel
        msg.mode=11
        msg.gait_id=27
        msg.vel_des=[0.03,vel,0]
        msg.life_count=(msg.life_count+1)%128
        Ctrl.Send_cmd(msg)
        time.sleep(0.6)
    print(f"vel:{vel}")
    
def go_center(left):
    if left == True:
        rgb_camera.left = True
        processor.left = True
    else:
        rgb_camera.left = False
        processor.left = False

    prev_error = 0.0
    Kp = 0.05
    Kd = 0.1
    max_vel = 0.1
    if left == True:
        sign = 1
    else:
        sign = -1
    #print("start_center")
    while(1):
        frame = rgb_camera.get_new_frame(left)
        if(processor.main_process(frame) == False):
            continue
        
        error = processor.center_y - processor.reference_y
        if abs(error) < processor.reference_y * processor.tolerance_ratio * 0.8:
            break

        derivative = error - prev_error
        vel = -(Kp * error + Kd * derivative)
        vel = max(min(vel, max_vel), -max_vel)

        prev_error = error

        msg.mode=11
        msg.gait_id=27
        vel = vel * sign
        print(vel)
        msg.vel_des=[0.05,vel,0]
        msg.life_count=(msg.life_count+1)%128    
        Ctrl.Send_cmd(msg)
        time.sleep(0.3)
    #print("center_over")

def process(rotate_speed):
    msg.mode=11
    msg.gait_id=27
    msg.step_height = [0.03,0.03]
    msg.vel_des=[0.23*1/2,0,rotate_speed*1/2]
    msg.rpy_des=[0,-0.45,0]
    msg.duration = 0
    msg.life_count=(msg.life_count+1)%128
    Ctrl.Send_cmd(msg)

purple_detector = PurpleDetector()
arrow_detector = ArrowDetector()
processor = s_curve_processor()
order = 1

#flag for left or right 0 for left 1 for right
def detecte(flag,index,flag_change):   
    if(flag == 0): #left camera
        rgb_camera.left = True
        processor.left = True
    else:
        rgb_camera.left = False
        processor.left = False
    chang_count = 0
    start_change_count = 0
    count = 0
    while(1):
        start_change_count += 1
        if flag == 0:
            frame = rgb_camera.get_new_frame(True) #move
        else: 
            frame = rgb_camera.get_new_frame(False)
        
        if flag_change == 0:
            frame_change =  rgb_camera.get_new_frame(True) # change
        else:
            frame_change =  rgb_camera.get_new_frame(False)

        if(processor.main_process(frame) == False):
            print("no result")
            continue
        #print(processor.adjust!=adjustment.mid)
        print(f"adjust: {processor.adjust}")
        if (processor.adjust!=adjustment.mid):
            # print(adjustment.mid)
            print(f"adjust: {processor.adjust}")           
            move(flag,processor.adjust)
            if flag == 0 :
                new_move(True,7)
            elif flag == 1:
                new_move(False,7)
            print("move over") 
            processor.adjust = adjustment.mid
            process(processor.rotate_speed)
 
        if  (order == 1 and ((start_change_count >=230 and index==2) or (start_change_count >=205 and index==3) ) ) or (start_change_count >=205 and index < 4 and index > 1 and order == 2) or (start_change_count >=20 and index == 1) :
            # print('ssss')
            if processor.fit_yellow_curve(frame_change,flag_change):
                a,b,c = processor.coeffs
                #a  b é˜ˆå€¼
                if chang_count >=5:
                    print("change!!!!!!!!!!!!!!!!!!")
                    break
                print(f"a, b, c = {a},{b},{c} ")
                if abs(a) < 0.001:
                    chang_count = chang_count + 1
                    print(f"chang_count:{chang_count}")


        if index == 4 and order == 1:
            print(f"order:{order}")
            frame_real_rgb = real_rgb_camera.get_new_frame()
            #print("have gotten rgb fram")
            direction = arrow_detector.detect_arrow(frame_real_rgb)
            print(direction)
            if direction!= Direction.UNKNOWN:
                arrow_detector.direction_count += 1
                print(f"direction_count:{arrow_detector.direction_count}")
            
            if arrow_detector.direction_count > 6: #before 6
                arrow_detector.direction_count = 0
                #new
                print("find and move")

                angle = 12
                w = angle*3.14/180
                msg.mode=11
                msg.gait_id=27
                msg.vel_des=[0.03,0.0,-w]
                msg.life_count=(msg.life_count+1)%128    
                Ctrl.Send_cmd(msg)
                time.sleep(2.3)
            
                msg.mode=11
                msg.gait_id=27
                msg.vel_des=[-0.03,0.0,0]
                msg.life_count=(msg.life_count+1)%128    
                Ctrl.Send_cmd(msg)
                time.sleep(0.6)

                print("move over")

                #åœæ­¢
                # msg.mode = 21  
                # msg.gait_id = 0
                # msg.rpy_des=[0,-0.3,0]
                # msg.duration = 0
                # msg.life_count += 1
                # Ctrl.Send_cmd(msg)
                # time.sleep(4)

                msg.mode = 3
                msg.gait_id = 0
                msg.vel_des = [0.0, 0.0, 0.0]
                msg.rpy_des = [ 0.0, -1.8, 0.0]
                msg.pos_des = [0.0, 0.0, 0.235]
                msg.life_count = (msg.life_count + 1) % 128
                Ctrl.Send_cmd(msg)
                time.sleep(4)
                print("æŠ¬å¤´ç»“æŸ")

                findflag,most_frequent_direction = arrow_detector.get_arrow_direction(real_rgb_camera)
                if findflag == False:
                    process(processor.rotate_speed)
                else:
                    #print(most_frequent_direction)
                    arrow_detector.real_direction = most_frequent_direction
                    print(f"last_direction:{arrow_detector.real_direction}")
                    break

        if index == 4 and order == 2:
            #print(f"order:{order}")
            frame_real_rgb = real_rgb_camera.get_new_frame()
            #print("have got frame in purplr")

            
            if purple_detector.process_purple(frame_real_rgb):
                count += 1
                print("find purple count:{count}!")
                if count >= 7:
                    standup()
                    break
                # #åœæ­¢
                # msg.mode = 21  
                # msg.gait_id = 0
                # msg.rpy_des=[0,-0.3,0]
                # msg.duration = 0
                # msg.life_count += 1
                # Ctrl.Send_cmd(msg)
                # time.sleep(2)                

 
def run_cur():  # s
    print(f"order in runcur:{order}")
    if order == 1:#ç¬¬ä¸€æ¬¡èµ°så¼¯
        processor.rotate_speed = 0.35
        process(processor.rotate_speed)
        time.sleep(4)#åˆå§‹ä½ç½®å¿…è¦
        detecte(1,1,0)
        print('det')

        
        new_move(True,5)
        go_center(True)
        print("ç›´è¡Œ1")
        msg.mode=11
        msg.gait_id=27
        msg.step_height = [0.03,0.03]
        msg.vel_des=[0.2,0,0]
        msg.rpy_des=[0,-0.45,0]
        msg.life_count=(msg.life_count+1)%128
        Ctrl.Send_cmd(msg)
        time.sleep(0.5)
        print("ç›´è¡Œç»“æŸ")

        processor.rotate_speed = -0.34
        process(processor.rotate_speed)
        detecte(0,2,1)

        new_move(True,5)
        go_center(True)
        print("ç›´è¡Œ2")
        msg.mode=11
        msg.gait_id=27
        msg.step_height = [0.03,0.03]
        msg.vel_des=[0.2,0,0]
        msg.rpy_des=[0,-0.45,0]
        msg.life_count=(msg.life_count+1)%128
        Ctrl.Send_cmd(msg)
        time.sleep(0.2)
 
        print("ç›´è¡Œç»“æŸ")
        processor.rotate_speed = 0.35
        process(processor.rotate_speed)
        detecte(1,3,0)

        real_rgb_camera.is_node_running = True
        print(f"real_rgb_camera.is_node_running:{real_rgb_camera.is_node_running}")
        
        new_move(False,5)
        go_center(False)
        """
        print("ç›´è¡Œ3")
        msg.mode=11
        msg.gait_id=27
        msg.vel_des=[0.2,0,0]
        msg.rpy_des=[0,-0.45,0]
        msg.life_count=(msg.life_count+1)%128
        Ctrl.Send_cmd(msg)
        time.sleep(0.1)
        print("ç›´è¡Œç»“æŸ")
        """
        processor.rotate_speed = -0.35
        #print("wandao3")
        process(processor.rotate_speed)
        print(real_rgb_camera.is_node_running)
        detecte(1,4,1)

    elif order == 2:#ç¬¬äºŒæ¬¡èµ°så¼¯
        print(f"order in order == 2 {order}")

        processor.rotate_speed = 0.24
        process(processor.rotate_speed)
        time.sleep(1.5)
        detecte(1,1,0)

        new_move(True,5)
        go_center(True)
        #print("è¿”å›ç›´è¡Œ1")
        msg.mode=11
        msg.gait_id=27
        msg.vel_des=[0.2,0,0]
        msg.rpy_des=[0,-0.45,0]
        msg.life_count=(msg.life_count+1)%128
        Ctrl.Send_cmd(msg)
        time.sleep(0.2)
        #print("ç›´è¡Œç»“æŸ")

        processor.rotate_speed = -0.33
        process(processor.rotate_speed)
        detecte(0,2,1)

        new_move(False,5)
        go_center(False)
        #print("è¿”å›ç›´è¡Œ2")
        msg.mode=11
        msg.gait_id=27
        msg.vel_des=[0.2,0,0]
        msg.rpy_des=[0,-0.45,0]
        msg.life_count=(msg.life_count+1)%128
        Ctrl.Send_cmd(msg)
        time.sleep(0.5)
        #print("ç›´è¡Œç»“æŸ")

        processor.rotate_speed = 0.3
        process(processor.rotate_speed)
        detecte(1,3,0)

        new_move(False,5)
        go_center(False)
        #print("è¿”å›ç›´è¡Œ3")

        real_rgb_camera.is_node_running = True
        print(f"real_rgb_camera.is_node_running:{real_rgb_camera.is_node_running}")

        msg.mode=11
        msg.gait_id=27
        msg.vel_des=[0.2,0,0]
        msg.rpy_des=[0,-0.45,0]
        msg.life_count=(msg.life_count+1)%128
        Ctrl.Send_cmd(msg)
        time.sleep(0.1)
        #print("ç›´è¡Œç»“æŸ")


        processor.rotate_speed = -0.29
        process(processor.rotate_speed)
        detecte(0,4,1)
    else:
        print('yjmxhlxw')

def jiaozheng1():
    angle,distance = arrow_detector.get_arrow_adjust(real_rgb_camera)
    print(f"angle,distance:{angle,distance}")
    angle += 5 
    msg.mode=11
    msg.gait_id=27
    msg.step_height = [0.03,0.03]
    yaw_speed = 0.2  #ä»¥åƒä¸ºå•ä½
    msg.duration = int(1000*(angle)*3.14/(180*yaw_speed))
    if angle < 0:
        yaw_speed = -yaw_speed
    msg.vel_des=[0.05,0,yaw_speed]
    msg.life_count=(msg.life_count+1)%128    
    Ctrl.Send_cmd(msg)
    time.sleep(8)
    print("have jiaozheng1")


    #distance = 1.2

    msg.mode=11
    msg.gait_id=27
    msg.step_height = [0.03,0.03]
    msg.duration = 8000
    vel = (distance-0.4)*1000/msg.duration
    msg.vel_des=[vel,0,0]
    msg.life_count=(msg.life_count+1)%128     
    Ctrl.Send_cmd(msg)
    time.sleep(6)

# def jiaozheng2():
#     angle_0 = 0.0
#     Kp = 1.2
#     Kd = 1.0
#     max_yaw = 30#è§’åº¦åˆ¶
#     acc = 5
#     #print("jiaozheng2 start")
#     while(1):
#         frame = real_rgb_camera.get_new_frame()
#         if not purple_detector.process_purple(frame):
#             continue

#         current_angle = purple_detector.angle
#         if current_angle == None:
#             continue
#         if abs(current_angle) < acc:
#             break
#         delta_angle = current_angle - angle_0
#         angle_0 = current_angle
#         yaw_speed = np.clip(current_angle * Kp + delta_angle * Kd,-max_yaw,max_yaw)
#         msg.mode=11
#         msg.gait_id=27
#         msg.step_height = [0.03,0.03]
#         yaw_speed = yaw_speed/180*3.14
#         msg.vel_des=[0.05,0.0,-yaw_speed]
#         msg.life_count=(msg.life_count+1)%128    
#         Ctrl.Send_cmd(msg)
#         time.sleep(0.5)
#     #print("jiaozheng2 over")
#     msg.mode=11
#     msg.gait_id=27
#     msg.duration = 3000
#     vel = 1.0*1000/msg.duration
#     msg.vel_des=[vel,0,0]
#     msg.life_count=(msg.life_count+1)%128    
#     Ctrl.Send_cmd(msg)
#     time.sleep(5)

def jiaozheng2():

    #ä½ç§»ä¸€ä¸‹
    msg.mode=11
    msg.gait_id=27
    msg.vel_des=[0.02,0.1,0]
    msg.duration = 1000
    msg.life_count=(msg.life_count+1)%128    
    Ctrl.Send_cmd(msg)
    time.sleep(1.3)

    #æ—‹è½¬ä¸€ä¸‹
    angle = 40
    w = angle*3.14/180
    msg.mode=11
    msg.gait_id=27
    msg.vel_des=[0.03,0.0,-w]
    msg.duration = 1000 
    msg.life_count=(msg.life_count+1)%128
    Ctrl.Send_cmd(msg)
    time.sleep(3)

    while(True):
        #ä¸ç´«è‰²ç®­å¤´åé¢çš„é»„çº¿å¯¹é½
        frame = real_rgb_camera.get_new_frame()
        print("have get new frame in purple")
        duiqi_node.get_yellow_line_y(frame)
        #è°ƒè¯•
        # print(f"duiqi_node.angle_iny:{duiqi_node.angle_iny}")
        # print(f"duiqi_node.distance_iny:{duiqi_node.distance_iny}")
        # time.sleep(100000)

        if duiqi_node.find_line == False:
            print("no line behind purple")
            jiaozheng_bianxian(5.0*10*3.14/180)
            frame = real_rgb_camera.get_new_frame()
            duiqi_node.get_yellow_line_y(frame)
            if duiqi_node.find_line == False:
                print("no line behind purple really")
                break

        print(f"duiqi_node.angle_iny:{duiqi_node.angle_iny}")
        if duiqi_node.angle_iny >=0.1:
            jiaozheng_bianxian(6.6*duiqi_node.angle_iny*3.14/180)
        print(f"angle_over")
        time.sleep(3)
        frame = real_rgb_camera.get_new_frame()
        duiqi_node.get_yellow_line_y(frame)
        print(f"Distance_iny: {duiqi_node.distance_iny}")
        if duiqi_node.distance_iny >= 2:
            go_short_bianxian(0.17,3000) #50cm
            time.sleep(0.5)
        elif duiqi_node.distance_iny > 1.3 and duiqi_node.distance_iny < 2: 
            vel = (duiqi_node.distance_iny- 1.3)/3 
            go_short_bianxian(vel,3000)
            time.sleep(0.5) #goshortbianxian æœ¬èº«çš„sleepå¤ªçŸ­äº†
            print("distance over in purple")
            break
        if duiqi_node.distance_iny <=1.3 :
            break

    #å·¦è½¬
    jiaozheng_bianxian(138*3.14/180)

    # # Aåº“äºŒç»´ç åº•çº¿è°ƒæ•´è§’åº¦
    # frame = real_rgb_camera.get_new_frame()
    # print("have get new frame after purple")
    # duiqi_node.get_yellow_line_y(frame)
    # if duiqi_node.find_line == False:
    #     print("no line after purple")
    #     jiaozheng_bianxian(-4.4*3*3.14/180)
    #     frame = real_rgb_camera.get_new_frame()
    #     duiqi_node.get_yellow_line_y(frame)
    #     if duiqi_node.find_line == False:
    #         print("no line after purple really")
    #         return
    
    # print(f"duiqi_node.angle_iny:{duiqi_node.angle_iny}")
    # jiaozheng_bianxian(5.0*duiqi_node.angle_iny*3.14/180)
    # print(f"after purple angle_over")    

    return

def xuanzhuan(direction):
    bia = 35
    msg.mode=11
    msg.gait_id=27

    msg.duration = 3000  
    yaw_speed = 1000*(90+bia)*3.140/(180*msg.duration)  
    if direction == Direction.Right:
        yaw_speed = -yaw_speed
    msg.vel_des=[0,0,yaw_speed]
    msg.life_count=(msg.life_count+1)%128    
    Ctrl.Send_cmd(msg)
    time.sleep(6)

def jiaozheng(yaw): #å¼§åº¦
    msg.mode=11
    msg.gait_id=27
    yaw_speed = 20/180*3.14
    msg.duration= int(abs(yaw/yaw_speed)*1000)
    if yaw < 0:
        yaw_speed = -yaw_speed
    msg.vel_des=[0.05,0.0,yaw_speed]
    msg.life_count=(msg.life_count+1)%128    
    Ctrl.Send_cmd(msg)
    time.sleep(4)
BIA = 0.27576 - 0.164
detector = YellowLightDetector()
def yellowlight(vel=0.2, step=0.01, duration=2000):
    count = 0
    ratio = 2.2
    yaw_ratio_p = 2.8
    yaw_ratio_n = 1.8
    x_distance_ratio = 1
    x_distance_bia = 0.0
    count_max = 4
    flag_headup = False
    while(True):
        # è·å–æœ€æ–°å›¾åƒ
        frame = vision_node.get_new_frame()
        print("get new frame")
        if frame is None:
            time.sleep(0.1)
            continue
        count += 1
        try:
            # 
            flag = detector.measure_distance(frame)
            if flag == False:
                flag_headup = True
                if count == 1:
                    print("no yellow light")
                    print("æŠ¬å¤´")
                    msg.mode = 3
                    msg.gait_id = 0
                    msg.vel_des = [0.0, 0.0, 0.0]
                    msg.rpy_des = [ 0.0, -1.8, 0.0]
                    msg.pos_des = [0.0, 0.0, 0.235]
                    msg.life_count = (msg.life_count + 1) % 128
                    Ctrl.Send_cmd(msg)
                    time.sleep(1)
                    continue
                else:
                    print("no yellow light really, go 60cm ")
                    Ctrl.go_short(vel*ratio*0.6, step, duration)
                    print("have go")
                    
            else:

                if count <=count_max:
                    if detector.yaw >=0:
                        yaw = yaw_ratio_p*detector.yaw
                    else :
                        yaw = yaw_ratio_n*detector.yaw
                    print(f"[é»„ç¯æ§åˆ¶] åç§»è§’åº¦: {math.degrees(yaw):.2f}\u00B0")
                    jiaozheng(yaw)


            print("jiaozheng over")
            #standup()
            time.sleep(0.7)

            if flag_headup:
                    msg.mode = 3
                    msg.gait_id = 0
                    msg.vel_des = [0.0, 0.0, 0.0]
                    msg.rpy_des = [ 0.0, -1.8, 0.0]
                    msg.pos_des = [0.0, 0.0, 0.235]
                    msg.life_count = (msg.life_count + 1) % 128
                    Ctrl.Send_cmd(msg)
                    time.sleep(1)
                    flag_headup = False

            frame = vision_node.get_new_frame()
            detector.measure_distance(frame)
            distance = detector.z_distance
            x_distance = (detector.x_distance+x_distance_bia)*x_distance_ratio
            print(f"åç§»é‡: {x_distance:.2f}m")

            if count <=0:
                msg.mode=11
                msg.gait_id=27
                msg.duration= 3000
                change_vel = abs(x_distance*1000/msg.duration)
                if x_distance > 0:
                    change_vel = -change_vel
                print(f"[é»„ç¯æ§åˆ¶] x_é€Ÿåº¦: {change_vel:.2f}m/s")
                msg.vel_des=[0.0,change_vel,0.0]
                msg.life_count=(msg.life_count+1)%128    
                Ctrl.Send_cmd(msg)
                time.sleep(3.5)
                print("x have changed")
                #standup()
            # åº”ç”¨åç§»é‡
            current_distance = distance + BIA
            print(f"[é»„ç¯æ§åˆ¶] å½“å‰è·ç¦»: {current_distance:.2f}m")
            
            if current_distance >= 2.0+BIA:
                #print("æ‰§è¡Œå‰è¿›1m")
                Ctrl.go_short(vel*ratio*0.7, step, duration)  # å‰è¿›0.7m
                #standup()
                print("have go")
                #time.sleep(2)
            elif 1.5+BIA <= current_distance < 2.0+BIA:
                #print("æ‰§è¡Œå‰è¿›0.5m")
                Ctrl.go_short(vel*ratio*0.5, step, duration)  # å‰è¿›0.5m
                #standup()
                print("have go")
                #time.sleep(2)
            elif 0.8+BIA <= current_distance < 1.5+BIA:
                move_dist = (current_distance - 0.5)*ratio
                #print(f"æ‰§è¡Œå‰è¿›{move_dist:.2f}m")
                adjusted_duration = int(duration * (move_dist/1.0))
                Ctrl.go_short(vel, step, adjusted_duration)
                #standup()
                print("have go")
                #time.sleep(2.5)
                #jiaozheng(-yaw_ratio*10*3.14/180) #!!!!!!!!!!!!!!!!è¿™æ˜¯ç»™æ­»çš„ ä¸ä¸€å®šå‡†ï¼
                print("yellow over")
                break  # ç»“æŸæ£€æµ‹å¾ªç¯
            elif 0+BIA<current_distance<0.8+BIA:
                print("error,å½“å‰è·ç¦»è¿‡è¿‘")
                break
            else:
                #print("è·ç¦»è¿‡è¿œ,å‰è¿›1m")
                Ctrl.go_short(vel, step, int(duration*2))
                
            # æ˜¾ç¤ºç»“æœ
            #detector.display_result(frame)
  
            
        except Exception as e:
            print(f"å›¾åƒå¤„ç†å¤±è´¥: {str(e)}")
            time.sleep(0.1)


def walk(duration = 5, dir = 0.00):  
    msg.mode = 11
    msg.gait_id = 3
    msg.vel_des = [0.1, dir, 0]
    msg.life_count = (msg.life_count + 1) % 128
    msg.duration = duration * 1000  
    Ctrl.Send_cmd(msg)
    Ctrl.Wait_finish(11, 27, duration)

def down():
    msg.mode = 7
    msg.gait_id = 1
    msg.vel_des = [0.3, 0, 0]
    msg.life_count = (msg.life_count + 1) % 128
    Ctrl.Send_cmd(msg)
    time.sleep( 0.1 )
    # Ctrl.Wait_finish(7, 1, 5)

def spin_executor():
    try:
        executor.spin()
    finally:
        # ç¡®ä¿èŠ‚ç‚¹åœ¨ç¨‹åºé€€å‡ºæ—¶è¢«æ­£ç¡®é”€æ¯
        rclpy.shutdown()

yaw = 0.0
arrow_direction = Direction.UNKNOWN
arrow_lock = Lock()  # ä¿è¯çº¿ç¨‹å®‰å…¨
arrow = None
state_id = 0
now_state = 0
QR1 = ''
QR2 = ''
QR1_cnt = 0
QR2_cnt = 0
Ctrl = PC_cmd_send()
Ctrl.run()
msg = robot_control_cmd_lcmt()

rclpy.init()

detector = YellowLightDetector()

vision_node = VisionNode()
rgb_camera = SteroCameraNode("rgb_camera")
real_rgb_camera = RGBCameraNode("real_rgb_camera")
depth_node = DepthNode('slope')
speech_node = SpeechProcessor()
executor = MultiThreadedExecutor()
executor.add_node(rgb_camera)
executor.add_node(vision_node)
executor.add_node(depth_node)
executor.add_node(real_rgb_camera)
executor.add_node(speech_node)
# æ·»åŠ èŠ‚ç‚¹åˆ°æ‰§è¡Œå™¨

spin_thread = Thread(target=spin_executor)
spin_thread.start()

def main():
    global state_id
    global now_state
    global QR1
    global QR2
    global arrow
    global order
    global msg
    global limittime
    QR1 = 'A-1' # äºŒç»´ç 1
    QR2 = 'B-2' # äºŒç»´ç 2
    arrow = Direction.Left
    # çŠ¶æ€æœºåˆå§‹åŒ–
    state_id = 1
    depth_node.set_node_running(False)
    state_entry_time = time.time()
    last_cmd_time = time.time()
    cmd_interval = 0.1  # å‘½ä»¤å‘é€é—´éš”ï¼ˆç§’ï¼‰
    standup()
    time.sleep(2.5)
    try:
        while rclpy.ok():
            current_time = time.time()
            # 0 å‡†å¤‡å³è½¬ å‰è¿›é€Ÿåº¦0.3m/s
            if state_id == 0:
                if current_time - last_cmd_time > cmd_interval:
                    msg.mode = 11        # è¡Œèµ°æ¨¡å¼
                    msg.gait_id = 3     # æ­¥æ€ç±»å‹
                    msg.vel_des = [0.3, 0, 0]  # å‰è¿›é€Ÿåº¦0.3m/s
                    msg.life_count = (msg.life_count + 1) % 128
                    Ctrl.Send_cmd(msg)

                    last_cmd_time = current_time

                if vision_node._0_detected:
                    print("enter s-1")
                    state_id = 1
                    print("è¿›å…¥çŠ¶æ€1")

                
            # 1å³è½¬ 0.5m/s 2.25rad/s 1.2s
            elif state_id == 1:
                # ç»§ç»­ç›´èµ°ä¸€æ®µè·ç¦»
                msg.mode = 11
                msg.gait_id = 10
                msg.vel_des = [0.3, 0.0, 0.0]
                msg.step_height = [0.02, 0.02]
                msg.life_count = (msg.life_count + 1) % 128
                Ctrl.Send_cmd(msg)
                time.sleep( 1.8 )

                msg.mode = 11
                msg.gait_id = 10
                msg.vel_des = [0.35, 0.0, -1.4]
                msg.step_height = [0.02, 0.02]
                msg.life_count = (msg.life_count + 1) % 128
                Ctrl.Send_cmd(msg)
                time.sleep( 1.3 )
                state_id = 2
                print("è¿›å…¥çŠ¶æ€2")
           
            # 2 å‰è¿› 0.3m/s
            elif state_id == 2:
                msg.mode = 11        # è¡Œèµ°æ¨¡å¼
                msg.gait_id = 3     # æ­¥æ€ç±»å‹
                msg.vel_des = [0.3, 0, 0]  # å‰è¿›é€Ÿåº¦0.3m/s
                msg.life_count = (msg.life_count + 1) % 128
                Ctrl.Send_cmd(msg)
                time.sleep(3.5)
                last_cmd_time = current_time

                msg.mode = 12 # Recovery stand
                msg.gait_id = 0
                msg.life_count = (msg.life_count + 1) % 128  # Command will take effect when life_count update
                Ctrl.Send_cmd(msg)
                time.sleep(1)
                last_cmd_time = current_time

                state_id = 4
                print("è¿›å…¥çŠ¶æ€4")
                        
            # 3å¯¹é½é»„çº¿
            elif state_id == 3:
                print("3")
               
            # 4è¯†åˆ«äºŒç»´ç 
            elif state_id == 4:
                if current_time - last_cmd_time > cmd_interval:
                    msg.mode = 3
                    msg.gait_id = 0
                    msg.vel_des = [0.0, 0.0, 0.0]
                    msg.rpy_des = [ 0.0, -1.8, 0.0]
                    msg.pos_des = [0.0, 0.0, 0.235]
                    msg.life_count = (msg.life_count + 1) % 128
                    Ctrl.Send_cmd(msg)
                    '''msg.mode = 12 # Recovery stand
                    msg.gait_id = 0
                    msg.life_count = (msg.life_count + 1) % 128  # Command will take effect when life_count update
                    Ctrl.Send_cmd(msg)
                    Ctrl.Wait_finish(12, 0)
                    last_cmd_time = current_time'''
                    print("ç«™ç«‹ï¼Œå¼€å§‹è¯†åˆ«äºŒç»´ç ")
                    #ifsth
                    state_id = 4.5
                    print("è¿›å…¥çŠ¶æ€4.5")

            elif state_id == 4.5:
                #if QR1 == 'B-1':
                speech_node.play_speech("AåŒºåº“ä½1")    
                
                #speech_node.play_speech("AåŒºåº“ä½2")
                    

                cmd_state = None
                standup()
                #time.sleep(2)
                #time.sleep(1.5)
                # ç›´èµ°
                # global QR1
                

                # ç›´èµ°
                '''msg.mode = 11
                msg.gait_id = 10  
                msg.vel_des = [0.3, 0.0, 0.0]
                msg.rpy_des = [ 0.0, 2.5, 0.0]
                msg.life_count = (msg.life_count + 1) % 128
                Ctrl.Send_cmd(msg)
                time.sleep( 0.1 )'''

                # è¿™é‡Œå¿…é¡»ç«™ç€ä¸åŠ¨ç­‰å¾…è½¬åœˆç»“æŸï¼Œä¸ç„¶åé¢çš„è¯†åˆ«ä¼šæœ‰é—®é¢˜
                '''msg.mode = 12 # Recovery stand
                msg.gait_id = 0
                msg.life_count = (msg.life_count + 1) % 128  # Command will take effect when life_count update
                Ctrl.Send_cmd(msg)
                Ctrl.Wait_finish(12, 0)
                last_cmd_time = current_time'''

                state_id = 5
                print("è¿›å…¥çŠ¶æ€5") 
                    
            # 5 è¯†åˆ«äºŒç»´ç åï¼Œåˆ°ä½ç½®è½¬å¼¯
            elif state_id == 5:
                msg.mode = 11
                msg.gait_id = 10
                msg.vel_des = [0.3, 0.0, 0.0]
                msg.rpy_des = [ 0.0, 2.5, 0.0]
                msg.life_count = (msg.life_count + 1) % 128
                Ctrl.Send_cmd(msg)
                time.sleep( 1.2 )
                print("pass 5-sleep")
                # å³è½¬
                print(QR1)
                dir = 1 if QR1 == 'A-1' else -1
                # dur = 1.3 if QR1 == 'A-2' else 1.3
                dur = 1.3
                print(str(dur) + "wdwdad")
                msg.mode = 11
                msg.gait_id = 10
                msg.vel_des = [0.2, 0.0, -1.4 * dir]
                msg.rpy_des = [ 0.0, 2.5, 0.0]
                msg.life_count = (msg.life_count + 1) % 128
                Ctrl.Send_cmd(msg)
                print("pass")
                # time.sleep( 1.22 ) 
                #time.sleep( dur ) åŸä»£ç 
                t_start = time.time()
                while time.time() - t_start < 1.22:
                    Ctrl.Send_cmd(msg) # æŒç»­å‘é€æŒ‡ä»¤ç»´æŒè¿åŠ¨
                    time.sleep(0.02)   # 20ms å‘é€ä¸€æ¬¡ (50Hz)
                last_cmd_time = current_time
                state_id = 6
                print(state_id)
                # æ²¡æœ‰durä¸è¡Œï¼Œä¸€åˆ°durå°±ç»“æŸfff
            # 6 åˆ°ä½ç½®å‡†å¤‡è½¬å¼¯
            elif state_id == 6:
                #print("enter" + str(state_id))
                #print("curr_t" + str(current_time) + "last_c_t" + str(last_cmd_time))
                if current_time - last_cmd_time > cmd_interval:
                    msg.mode = 11
                    msg.gait_id = 3
                    msg.vel_des = [0.12, 0.0, 0]
                    msg.rpy_des = [0, 2.5, 0]
                    msg.life_count = (msg.life_count + 1) % 128
                    Ctrl.Send_cmd(msg)
                    last_cmd_time = current_time

                if vision_node._6_detected:
                    print("è¿›å…¥çŠ¶æ€7")
                    state_id = 6.5


            # 6 åˆ°ä½ç½®å‡†å¤‡è½¬å¼¯
            elif state_id == 6.5:
                msg.mode = 11
                msg.gait_id = 10
                msg.vel_des = [0.2, 0, 0]
                msg.rpy_des = [0, 2.5, 0]
                msg.life_count = (msg.life_count + 1) % 128
                Ctrl.Send_cmd(msg)
                last_cmd_time = current_time
                time.sleep( 0.5 )

                print("è¿›å…¥çŠ¶æ€7")
                state_id = 7

            # 7è½¬
            elif state_id == 7:
                dir = 1 if QR1 == 'A-1' else -1
                dur = 1.3 if QR1 == 'A-2' else 1.4
                msg.mode = 11
                msg.gait_id = 10
                msg.vel_des = [0.1, 0.0, -1.4 * dir]
                msg.rpy_des = [ 0.0, 2.5, 0.0]
                msg.life_count = (msg.life_count + 1) % 128
                Ctrl.Send_cmd(msg)
                time.sleep( dur )

                # è¿™é‡Œå¿…é¡»ç«™ç€ä¸åŠ¨ç­‰å¾…è½¬åœˆç»“æŸï¼Œä¸ç„¶åé¢çš„è¯†åˆ«ä¼šæœ‰é—®é¢˜
                '''msg.mode = 12 # Recovery stand
                msg.gait_id = 0
                msg.life_count = (msg.life_count + 1) % 128  # Command will take effect when life_count update
                Ctrl.Send_cmd(msg)
                Ctrl.Wait_finish(12, 0)
                last_cmd_time = current_time'''
                msg.mode = 11
                msg.gait_id = 10
                msg.vel_des = [0.3, 0.0, 0]
                msg.rpy_des = [ 0.0, 2.5, 0.0]
                msg.life_count = (msg.life_count + 1) % 128
                Ctrl.Send_cmd(msg)
                time.sleep( 0.9 )

                state_id = 9
                print("è¿›å…¥çŠ¶æ€8")    

            elif state_id == 8:
                ALIGN_DURATION = 0.5    # éœ€è¦æŒç»­å¯¹é½æ—¶é—´ï¼ˆç§’ï¼‰
                KP = -0.8               # æ¯”ä¾‹ç³»æ•°
                KD = 1.5                # å¾®åˆ†ç³»æ•°
                # angle_0 = 0.0           # åˆå§‹åŒ–è§’åº¦
                MAX_YAW = 0.05          # æœ€å¤§è½¬å‘é€Ÿåº¦ï¼ˆrad/sï¼‰
                SEARCH_SPEED = 0.00      # æœç´¢è½¬é€Ÿï¼ˆrad/sï¼‰
                
                if current_time - last_cmd_time > cmd_interval:
                    if vision_node._8_detected:
                        angle_error = vision_node.line_angle
                        delta = vision_node.angle_0 - angle_error
                        vision_node.angle_0 = angle_error
                        duration = vision_node.aligned_duration
                        
                        if duration >= ALIGN_DURATION:
                            print("è¿›å…¥çŠ¶æ€9")
                            vision_node.angle_0 = 0
                            msg.mode = 11
                            msg.gait_id = 3
                            msg.vel_des = [0.1, 0, 0]
                            msg.rpy_des = [0, 2.5, 0]
                            msg.step_height = [0.03, 0.03]
                            msg.life_count = (msg.life_count + 1) % 128
                            Ctrl.Send_cmd(msg)
                            time.sleep(0.5)
                            state_id = 9 
                            continue
                        
                        yaw_speed = np.clip(angle_error * KP + delta * KD, -MAX_YAW, MAX_YAW)
                        msg.mode = 11
                        msg.gait_id = 3
                        msg.vel_des = [0.01, 0.0, yaw_speed]
                        msg.rpy_des = [0, 2.5, 0]
                        msg.step_height = [0.03, 0.03]
                        msg.life_count = (msg.life_count + 1) % 128
                        Ctrl.Send_cmd(msg)
                        last_cmd_time = current_time
                    else:
                        msg.mode = 11
                        msg.gait_id = 3
                        msg.vel_des = [0.08, 0.0, SEARCH_SPEED]
                        msg.rpy_des = [0, 2.5, 0]
                        msg.step_height = [0.03, 0.03]
                        msg.life_count = (msg.life_count + 1) % 128
                        Ctrl.Send_cmd(msg)
                        # print("æœç´¢é»„çº¿")
                        last_cmd_time = current_time

            # 9åˆ°ä½ç½®è¶´ä¸‹
            elif state_id == 9:
                if current_time - last_cmd_time > cmd_interval:
                    msg.mode = 11
                    msg.gait_id = 3
                    msg.vel_des = [0.1, 0.0, 0.0]
                    msg.rpy_des = [0, 2.5, 0]
                    msg.life_count = (msg.life_count + 1) % 128
                    Ctrl.Send_cmd(msg)
                    last_cmd_time = current_time

                if vision_node._9_detected:
                    state_id = 9.5
                    print("è¿›å…¥çŠ¶æ€9.5")

            elif state_id == 9.5:
                msg.mode = 11
                msg.gait_id = 10
                msg.vel_des = [0.3, 0, 0]
                msg.rpy_des = [0, 2.5, 0]
                msg.life_count = (msg.life_count + 1) % 128
                Ctrl.Send_cmd(msg)
                time.sleep(0.7)
                last_cmd_time = current_time
                
                down()
                while(True):
                    if now_state == 1:
                        break
                now_state = 0
                #time.sleep(3)
                standup()
                
                msg.mode = 11
                msg.gait_id = 10
                msg.vel_des = [-0.3, 0, 0]
                msg.rpy_des = [0, 2.5, 0]
                msg.life_count = (msg.life_count + 1) % 128
                Ctrl.Send_cmd(msg)
                time.sleep(1.2)
                print("è¿›å…¥çŠ¶æ€10")
                state_id = 10

            # 10 å‡†å¤‡å‡ºåº“ã€‚
            elif state_id == 10:
                '''if current_time - last_cmd_time > cmd_interval:
                    msg.mode = 11
                    msg.gait_id = 3
                    msg.vel_des = [-0.15, 0.0, 0.0]
                    msg.rpy_des = [0, 2.5, 0]
                    msg.life_count = (msg.life_count + 1) % 128
                    Ctrl.Send_cmd(msg)
                    last_cmd_time = current_time
                
                if vision_node._10_detected:
                    print("è¿›å…¥çŠ¶æ€11")
                    state_id = 11'''
                msg.mode = 11
                msg.gait_id = 10
                msg.vel_des = [-0.2, 0.0, 0.0]
                msg.rpy_des = [0, 2.5, 0]
                msg.life_count = (msg.life_count + 1) % 128
                Ctrl.Send_cmd(msg)
                time.sleep(3)
                print("è¿›å…¥çŠ¶æ€11")
                state_id = 11

            # 11 
            elif state_id == 11:
                dir = 1 if QR1 == 'A-1' else -1
                mul = 1.5 if QR1 == 'A-1' else 2.2
                msg.mode = 11
                msg.gait_id = 10 
                msg.vel_des = [-0.3, 0.0, 0.0]
                msg.rpy_des = [0, 2.5, 0]
                msg.life_count = (msg.life_count + 1) % 128
                Ctrl.Send_cmd(msg)
                time.sleep(0.5)
                msg.mode = 11
                msg.gait_id = 10
                msg.vel_des = [0.01 * mul, 0.0, -1.4 * dir]
                msg.life_count = (msg.life_count + 1) % 128
                Ctrl.Send_cmd(msg)
                time.sleep( 1.28 )
                msg.mode = 11
                msg.gait_id = 10
                msg.vel_des = [0.3, 0.0, 0.0]
                msg.rpy_des = [0, 2.5, 0]
                msg.life_count = (msg.life_count + 1) % 128
                Ctrl.Send_cmd(msg)
                time.sleep(0.4)
                state_id = 12
                print("è¿›å…¥çŠ¶æ€12")


            # 12åˆ°ä½ç½®æ‹å‡º
            elif state_id == 12:
                if current_time - last_cmd_time > cmd_interval:
                    msg.mode = 11        # è¡Œèµ°æ¨¡å¼
                    msg.gait_id = 3     # æ­¥æ€ç±»å‹
                    msg.vel_des = [0.1, 0, 0]  # å‰è¿›é€Ÿåº¦0.3m/s
                    msg.life_count = (msg.life_count + 1) % 128
                    Ctrl.Send_cmd(msg)
                    last_cmd_time = current_time
                
                if vision_node._12_detected:
                    print("è¿›å…¥çŠ¶æ€13")
                    
                    '''msg.mode = 11
                    msg.gait_id = 27
                    msg.vel_des = [0.5, 0.0, 1.4 * dir]
                    msg.life_count = (msg.life_count + 1) % 128
                    Ctrl.Send_cmd(msg)
                    time.sleep( 1.3 )'''
                    state_id = 12.5

            # 12.5 æ£€æµ‹åˆ°ä½ç½®åï¼Œæ‹å‡º
            elif state_id == 12.5:
                '''if QR1 == 'A-2':
                    msg.mode = 11
                    msg.gait_id = 3
                    msg.vel_des = [0.3, 0.0, 0.0]
                    msg.life_count = (msg.life_count + 1) % 128
                    Ctrl.Send_cmd(msg)
                    time.sleep( 2 )'''
                dur = 0.5 if QR1 == 'A-2' else 0.5
                msg.mode = 11
                msg.gait_id = 10
                msg.vel_des = [0.1, 0.0, 0.0]
                msg.life_count = (msg.life_count + 1) % 128
                Ctrl.Send_cmd(msg)
                time.sleep( dur )
                dir = 1 if QR1 == 'A-1' else -1
                dur = 1.24 if QR1 == 'A-2' else 1.2
                msg.mode = 11
                msg.gait_id = 10
                msg.vel_des = [0.3, 0.0, 1.4 * dir]
                msg.life_count = (msg.life_count + 1) % 128
                Ctrl.Send_cmd(msg)
                time.sleep( dur )

                # å¿…é¡»è½¬å¼¯å®Œååœä¸€ä¸‹
                '''msg.mode = 12 # Recovery stand
                msg.gait_id = 0
                msg.life_count = (msg.life_count + 1) % 128  # Command will take effect when life_count update
                Ctrl.Send_cmd(msg)
                Ctrl.Wait_finish(12, 0)
                last_cmd_time = current_time'''

                msg.mode = 11
                msg.gait_id = 10
                msg.vel_des = [0.3, 0.01, 0.01]
                msg.life_count = (msg.life_count + 1) % 128
                Ctrl.Send_cmd(msg)
                time.sleep( 1.5 )

                '''msg.mode = 11
                msg.gait_id = 27
                msg.vel_des = [0.3, 0.0, 1.4]
                msg.life_count = (msg.life_count + 1) % 128
                Ctrl.Send_cmd(msg)
                time.sleep( 1.3 )

                # å¿…é¡»è½¬å¼¯å®Œååœä¸€ä¸‹
                msg.mode = 12 # Recovery stand
                msg.gait_id = 0
                msg.life_count = (msg.life_count + 1) % 128  # Command will take effect when life_count update
                Ctrl.Send_cmd(msg)
                Ctrl.Wait_finish(12, 0)
                last_cmd_time = current_time'''

                state_id = 13
                print("è¿›å…¥çŠ¶æ€13")

            # 13å¯¹é½æ–¹å‘
            elif state_id == 13:
                ALIGN_DURATION = 0.5    # éœ€è¦æŒç»­å¯¹é½æ—¶é—´ï¼ˆç§’ï¼‰
                KP = -0.4               # æ¯”ä¾‹ç³»æ•°
                KD = 1.6                # å¾®åˆ†ç³»æ•°
                # angle_0 = 0.0           # åˆå§‹åŒ–è§’åº¦
                MAX_YAW = 0.05          # æœ€å¤§è½¬å‘é€Ÿåº¦ï¼ˆrad/sï¼‰
                SEARCH_SPEED = 0.0      # æœç´¢è½¬é€Ÿï¼ˆrad/sï¼‰
                
                if current_time - last_cmd_time > cmd_interval:
                    if vision_node._13_detected:
                        angle_error = vision_node.line_angle
                        delta = vision_node.angle_0 - angle_error
                        vision_node.angle_0 = angle_error
                        duration = vision_node.aligned_duration
                        
                        if duration >= ALIGN_DURATION:
                            print("è¿›å…¥çŠ¶æ€14")
                            vision_node.angle_0 = 0
                            state_id = 14
                            continue
                        
                        yaw_speed = np.clip(angle_error * KP + delta * KD, -MAX_YAW, MAX_YAW)
                        msg.mode = 11
                        msg.gait_id = 3
                        msg.vel_des = [0.01, 0.0, yaw_speed]
                        msg.rpy_des = [0, 2.5, 0]
                        msg.life_count = (msg.life_count + 1) % 128
                        Ctrl.Send_cmd(msg)
                        # print(f"è§’åº¦è¯¯å·®: {np.degrees(angle_error):+.1f}\u00B0 | æŒç»­: {duration:.4f}s | yaw: {yaw_speed:.2f}")
                        last_cmd_time = current_time
                    else:
                        msg.mode = 11
                        msg.gait_id = 3
                        msg.vel_des = [0.1, 0.0, SEARCH_SPEED]
                        msg.rpy_des = [0, 2.5, 0]
                        msg.life_count = (msg.life_count + 1) % 128
                        Ctrl.Send_cmd(msg)
                        # print("æœç´¢é»„çº¿")
                        last_cmd_time = current_time

            # 14åˆ°ä½ç½®å³æ‹
            elif state_id == 14:
                if current_time - last_cmd_time > cmd_interval:
                    msg.mode = 11
                    msg.gait_id = 3
                    msg.vel_des = [0.1, 0, 0]
                    msg.rpy_des = [0, 2.5, 0]
                    msg.life_count = (msg.life_count + 1) % 128
                    Ctrl.Send_cmd(msg)
                    last_cmd_time = current_time

                if vision_node._14_detected:
                    msg.mode = 12 # Recovery stand
                    msg.gait_id = 0
                    msg.life_count = (msg.life_count + 1) % 128  # Command will take effect when life_count update
                    Ctrl.Send_cmd(msg)
                    Ctrl.Wait_finish(12, 0)
                    last_cmd_time = current_time
                    print("è¿›å…¥çŠ¶æ€14.5")
                    state_id = 14.5

            elif state_id == 14.5:
                msg.mode = 11
                msg.gait_id = 10
                msg.vel_des = [0.3, 0, 0]
                msg.rpy_des = [0, 2.5, 0]
                msg.life_count = (msg.life_count + 1) % 128
                Ctrl.Send_cmd(msg)
                time.sleep( 0.6 )
                msg.mode = 11
                msg.gait_id = 10
                msg.vel_des = [0.2, 0, -1.4]
                msg.rpy_des = [0, 2.5, 0]
                msg.life_count = (msg.life_count + 1) % 128
                Ctrl.Send_cmd(msg)
                time.sleep( 1.24 )
                msg.mode = 11
                msg.gait_id = 10
                msg.vel_des = [0.2, 0.01, 0]
                msg.rpy_des = [0, 2.5, 0]
                msg.life_count = (msg.life_count + 1) % 128
                Ctrl.Send_cmd(msg)
                time.sleep( 3 )
                '''dur = 0.3 if QR1 == 'A-2' else 3
                msg.mode = 11
                msg.gait_id = 10
                msg.vel_des = [0.16, 0, 0]
                msg.rpy_des = [0, 2.5, 0]
                msg.life_count = (msg.life_count + 1) % 128
                Ctrl.Send_cmd(msg)
                time.sleep( dur )'''
                # å¿…é¡»è½¬å¼¯å®Œååœä¸€ä¸‹
                msg.mode = 12 # Recovery stand
                msg.gait_id = 0
                msg.life_count = (msg.life_count + 1) % 128  # Command will take effect when life_count update
                Ctrl.Send_cmd(msg)
                Ctrl.Wait_finish(12, 0)
                last_cmd_time = current_time

                print("è¿›å…¥çŠ¶æ€15")
                rgb_camera.is_node_running = True
                # print(rgb_camera.is_node_running)
                state_id = 15
                

            # 15å‡†å¤‡è¿›Så¼¯ è·‘så¼¯
            elif state_id == 15:
                #print(15)
                # global arrow
                rgb_camera.is_node_running = True
                real_rgb_camera.is_node_running = False
                # os.system('python3 order1and2_test_7_15.py')
                #print(rgb_camera.is_node_running)
                time.sleep(2)
                run_cur()
                jiaozheng1()
                arrow = arrow_detector.real_direction
                print(arrow)
                if arrow == Direction.Left:
                     speech_node.play_speech("å·¦ä¾§è·¯çº¿")
                else:
                     speech_node.play_speech("å³ä¾§è·¯çº¿")
                standup()
                time.sleep(4)
                if arrow == Direction.Right:
                    msg.mode=11
                    msg.gait_id=27     
                    msg.duration= 5000
                    msg.vel_des=[0.0,-0.3,0.0]
                    msg.step_height = [0.01, 0.01]
                    msg.life_count=(msg.life_count+1)%128    
                    Ctrl.Send_cmd(msg)
                    time.sleep(4)

                elif arrow == Direction.Left:
                    msg.mode=11
                    msg.gait_id=27     
                    msg.duration= 3600
                    msg.vel_des=[0.0,0.3,0.0]
                    msg.step_height = [0.01, 0.01]
                    msg.life_count=(msg.life_count+1)%128    
                    Ctrl.Send_cmd(msg)
                    time.sleep(4)
                # dir = 1 if arrow == Direction.Left else -1
                # msg.mode = 11
                # msg.gait_id = 10
                # msg.vel_des = [0.3, 0, -1.4 * dir]
                # msg.rpy_des = [0, 2.5, 0]
                # msg.life_count = (msg.life_count + 1) % 128
                # Ctrl.Send_cmd(msg)
                # time.sleep( 1.3 )

                rgb_camera.is_node_running = False
                real_rgb_camera.is_node_running = False
                state_id = 18
                standup()
                print("è¿›å…¥çŠ¶æ€18")
                # break

            # 16å¯¹é½æ–¹å‘
            elif state_id == 16:
                ALIGN_DURATION = 3    # éœ€è¦æŒç»­å¯¹é½æ—¶é—´ï¼ˆç§’ï¼‰
                KP = -1.2              # æ¯”ä¾‹ç³»æ•°
                KD = 4.0                # å¾®åˆ†ç³»æ•°
                KI = 0.01
                MAX_YAW = 0.05          # æœ€å¤§è½¬å‘é€Ÿåº¦ï¼ˆrad/sï¼‰
                SEARCH_SPEED = -0.00      # æœç´¢è½¬é€Ÿï¼ˆrad/sï¼‰
                

                if current_time - last_cmd_time > cmd_interval:
                    if vision_node._16_detected:
                        angle_error = vision_node.line_angle

                        delta = vision_node.angle_0 - angle_error
                        vision_node.angle_0 = angle_error
                        duration = vision_node._aligned_duration

                        if duration >= ALIGN_DURATION:
                            print("è¿›å…¥çŠ¶æ€17")
                            vision_node.angle_0 = 0
                            state_id = 17
                            continue
                        
                        yaw_speed = np.clip(angle_error * KP + delta * KD , -MAX_YAW, MAX_YAW)

                        msg.mode = 11
                        msg.gait_id = 3
                        msg.vel_des = [0.01, 0.01, yaw_speed]
                        msg.rpy_des = [0, 3, 0]
                        msg.life_count = (msg.life_count + 1) % 128
                        Ctrl.Send_cmd(msg)
                        # print(f"è§’åº¦è¯¯å·®: {angle_error:+.8f}\u00B0 | æŒç»­: {duration:.3f}s | yaw: {yaw_speed:.2f}")
                        last_cmd_time = current_time
                    else:
                        msg.mode = 11
                        msg.gait_id = 3
                        msg.vel_des = [0.1, 0.01, SEARCH_SPEED]
                        msg.rpy_des = [0, 2.5, 0]
                        msg.life_count = (msg.life_count + 1) % 128
                        Ctrl.Send_cmd(msg)
                        # print("æœç´¢é»„çº¿")
                        last_cmd_time = current_time

            elif state_id == 17:
                rgb_camera.is_node_running = False
                if current_time - last_cmd_time > cmd_interval:
                    msg.mode = 11        # è¡Œèµ°æ¨¡å¼
                    msg.gait_id = 3     # æ­¥æ€ç±»å‹
                    msg.vel_des = [0.06, 0.01, 0]  # å‰è¿›é€Ÿåº¦0.3m/s
                    msg.life_count = (msg.life_count + 1) % 128
                    Ctrl.Send_cmd(msg)
                    last_cmd_time = current_time
                
                if vision_node._17_detected:
                    print("è¿›å…¥çŠ¶æ€17.5")
                    
                    '''dir = 1 if arrow == Direction.Left else -1
                    msg.mode = 11
                    msg.gait_id = 10
                    msg.vel_des = [0.1, 0.0, -1.4 * dir]
                    msg.life_count = (msg.life_count + 1) % 128
                    Ctrl.Send_cmd(msg)
                    time.sleep( 1.24 )'''
                    state_id = 17.5
                    if arrow == Direction.Left:
                        depth_node.set_detection_type('stone')
                    else:
                        depth_node.set_detection_type('slope')

            elif state_id == 17.5:
                dir = 1 if arrow == Direction.Left else -1
                standup()
                time.sleep(1)
                print(175)
                msg.mode = 11
                msg.gait_id = 10
                msg.vel_des = [0.2, 0.0, 0]
                msg.life_count = (msg.life_count + 1) % 128
                Ctrl.Send_cmd(msg)
                time.sleep( 0.55 )
                msg.mode = 11
                msg.gait_id = 10
                msg.vel_des = [0.2, 0.0, -1.4 * dir]
                msg.life_count = (msg.life_count + 1) % 128
                Ctrl.Send_cmd(msg)
                time.sleep( 1.31 )
                state_id = 18

            # 18çŸ³æ¿è·¯/å¡é“
            elif state_id == 18:
                if arrow == Direction.Left:
                    # depth_node.set_detection_type('stone')
                    #no depth
                    # stone_detected = main_detection_loop(
                    #     depth_node, Ctrl, msg, 
                    #     trigger_distance=0.55, 
                    #     detection_type="çŸ³å¤´è·¯"
                    # )
                    stone_detected = True

                    if stone_detected:
                        # æ‰§è¡ŒçŸ³æ¿è·¯åŠ¨ä½œ
                        # cv2.destroyWindow("Stone Detection")

                        #no depth
                        # standup()
                        # msg.mode = 11
                        # msg.gait_id = 27
                        # msg.vel_des = [0.3, 0, 0]
                        # msg.step_height = [0.01, 0.01]
                        # msg.life_count = (msg.life_count + 1) % 128
                        # time.sleep(1)

                        standup()
                        stone_road(88)
                        # ctrl.Wait_finish(62, 81, duration)
                        state_id = 18.5
                        # vision_node.last_error = 0
                        # vision_node.integral = 0
                        state_entry_time = time.time()
                else:
                    '''msg.mode = 11
                    msg.gait_id = 27
                    msg.vel_des = [0.1, 0, 0]
                    msg.step_height = [0.04, 0.04]
                    msg.life_count = (msg.life_count + 1) % 128
                    Ctrl.Send_cmd(msg)
                    time.sleep(1)
                    standup()
                    time.sleep(1)
                    upslope(Ctrl, msg)
                    walk(0.2, 0.2)         # å–å†³äºä¸­é—´å¹³å°èµ°å¤šä¹…
                    # time.sleep(2)
                    standup()
                    downslope(Ctrl, msg)
                    # walk(5)
                    state_id = 18.5
                    state_entry_time = time.time()'''

                    #no depth

                    # slope_detected = main_detection_loop(
                    #     depth_node, Ctrl, msg, 
                    #     trigger_distance=1.4, 
                    #     detection_type="æ–œå¡"
                    # )
                    slope_detected = True  
                    if slope_detected:
                        # æ‰§è¡Œä¸Šæ–œå¡åŠ¨ä½œ
                        #cv2.destroyWindow("Slope Detection")

                        # no depth
                        # standup()
                        # msg.mode = 11
                        # msg.gait_id = 27
                        # msg.vel_des = [0.1, 0, 0]
                        # #msg.step_height = [0.04, 0.04]
                        # msg.life_count = (msg.life_count + 1) % 128
                        # Ctrl.Send_cmd(msg)
                        # time.sleep(0.5)

                        standup()  
                        upslope(12)  
                        print("Upslope ends.")
                        stand()
                        standup()
                        '''msg.mode = 11
                        msg.gait_id = 3
                        msg.vel_des = [0.15, 0, 0]
                        msg.life_count = (msg.life_count + 1) % 128
                        msg.step_height = [0.02, 0.02]
                        #msg.duration = duration * 1000  
                        Ctrl.Send_cmd(msg)
                        time.sleep(2) '''   
                        #standup()
                        downslope()
                        msg.mode = 11
                        msg.gait_id = 27
                        msg.vel_des = [0.15, 0, -0.1]
                        msg.life_count = (msg.life_count + 1) % 128
                        msg.step_height = [0.03, 0.03]
                        #msg.duration = duration * 1000  
                        Ctrl.Send_cmd(msg)
                        time.sleep(2)
                        # walk(1)
                        # walk(5)
                        state_id = 18.5
                        state_entry_time = time.time()

            # 
            elif state_id == 18.5:
                # PIDæ§åˆ¶å™¨å‚æ•°
                KP_YAW = 0.7      # åèˆªæ§åˆ¶æ¯”ä¾‹ç³»æ•°
                KD_YAW = 1.0      # åèˆªæ§åˆ¶å¾®åˆ†ç³»æ•°
                KI_YAW = 0.05     # åèˆªæ§åˆ¶ç§¯åˆ†ç³»æ•°
                MAX_YAW = 0.2     # æœ€å¤§åèˆªé€Ÿåº¦
                
                # æ¨ªå‘ä½ç½®æ§åˆ¶å‚æ•°
                KP_LATERAL = 0.1  # æ¨ªå‘æ§åˆ¶æ¯”ä¾‹ç³»æ•°
                MAX_LATERAL = 0.1 # æœ€å¤§æ¨ªå‘é€Ÿåº¦
                
                # åˆå§‹åŒ–æ§åˆ¶å˜é‡
                '''integral = 0.0
                last_error = 0.0'''
                
                current_time = time.time()
                time_since_entry = current_time - state_entry_time
                
                # è·å–è§†è§‰è¯¯å·®
                yaw_error = vision_node.yaw_adjust
                lateral_error = vision_node.lateral_error
                
                # åèˆªæ§åˆ¶è®¡ç®—
                
                delta_error = yaw_error - vision_node.last_error
                # print(1)
                '''integral += yaw_error * cmd_interval
                integral = np.clip(vision_node.integral, -1.0, 1.0)'''
                # print(2)
                yaw_speed = KP_YAW * yaw_error + KD_YAW * delta_error
                yaw_speed = np.clip(yaw_speed, -MAX_YAW, MAX_YAW)
                
                # æ¨ªå‘ä½ç½®æ§åˆ¶è®¡ç®—
                lateral_speed = KP_LATERAL * lateral_error
                lateral_speed = np.clip(lateral_speed, -MAX_LATERAL, MAX_LATERAL)
                
                # æ„é€ æ§åˆ¶æŒ‡ä»¤
                # msg = MotionMsg()
                msg.mode = 11                  # è¿åŠ¨æ¨¡å¼
                msg.gait_id = 3               # æ­¥æ€ç±»å‹
                msg.vel_des = [0.01, lateral_speed, yaw_speed]  # [å‰è¿›é€Ÿåº¦ï¼Œæ¨ªå‘é€Ÿåº¦ï¼Œåèˆªé€Ÿåº¦]
                msg.rpy_des = [0, 2.5, 0]      # å§¿æ€è§’åº¦
                msg.step_height = [0.01, 0.01] # æ­¥é«˜
                msg.life_count = (msg.life_count + 1) % 128
                
                # å‘é€æ§åˆ¶æŒ‡ä»¤
                Ctrl.Send_cmd(msg)
                
                # è°ƒè¯•è¾“å‡º
                if vision_node.debug_mode:
                    print(f"Control | YawErr: {np.degrees(yaw_error):+.1f}\u00B0 "
                        f"LatErr: {lateral_error:.2f} | "
                        f"YawSpd: {yaw_speed:.2f} LatSpd: {lateral_speed:.2f}")
                
                # æ›´æ–°çŠ¶æ€å˜é‡
                vision_node.last_error = yaw_error
                last_cmd_time = current_time
                
                # çŠ¶æ€é€€å‡ºæ¡ä»¶
                if time_since_entry > 5 and abs(yaw_error) < 0.2:  # 15ç§’åé€€å‡º
                    if arrow == Direction.Right:
                        depth_node.set_node_running(False)
                    else:
                        depth_node.set_detection_type('limit')
                    state_id = 19
                    vision_node.last_error = 0
                    vision_node.integral = 0
                    print("è¿›å…¥çŠ¶æ€19")
                
                time.sleep(cmd_interval)  # æ§åˆ¶å¾ªç¯é¢‘ç‡
            
            # 19é™é«˜æ†/é»„ç¯
            elif state_id == 19:
                if arrow == Direction.Left:
                    depth_node.set_detection_type('limit')
                    standup()
                    print(19)
                    limit_detected = main_detection_loop(
                        depth_node, Ctrl, msg, 
                        trigger_distance=1, 
                        detection_type="é™é«˜æ†"
                    )
                    
                    if limit_detected:
                        # æ‰§è¡Œé™é«˜æ†åŠ¨ä½œ
                        # cv2.destroyWindow("Limit Detection")
                        # standup(Ctrl, msg)
                        limittime = 3
                        msg.mode = 11
                        msg.gait_id = 3
                        msg.vel_des = [0.2, 0.0, 0]
                        msg.life_count = (msg.life_count + 1) % 128
                        Ctrl.Send_cmd(msg)
                        time.sleep( limittime )
                        # standup(Ctrl, msg)
                        standup()
                        limit(Ctrl, msg)
                        standup()
                        msg.mode = 11
                        msg.gait_id = 3
                        msg.vel_des = [0.01, 0.05, 0.1]
                        msg.life_count = (msg.life_count + 1) % 128
                        Ctrl.Send_cmd(msg)
                        time.sleep( 1 )
                        print('è¿›å…¥19.5')
                        standup()
                        '''msg.mode = 11
                        msg.gait_id = 3
                        msg.vel_des = [0.2, 0.0, 0]
                        msg.life_count = (msg.life_count + 1) % 128
                        Ctrl.Send_cmd(msg)
                        time.sleep( 1.5 )'''

                        state_id = 19.5
                        state_entry_time = time.time()
                else:
                    standup()
                    yellowlight()
                    standup()
                    speech_node.start_countdown()
                    time.sleep(7)
                    state_id = 19.5
                    state_entry_time = time.time()

            
            elif state_id == 19.5:
                # PIDæ§åˆ¶å™¨å‚æ•°
                KP_YAW = 0.7      # åèˆªæ§åˆ¶æ¯”ä¾‹ç³»æ•°
                KD_YAW = 1.0      # åèˆªæ§åˆ¶å¾®åˆ†ç³»æ•°
                KI_YAW = 0.05     # åèˆªæ§åˆ¶ç§¯åˆ†ç³»æ•°
                MAX_YAW = 0.2     # æœ€å¤§åèˆªé€Ÿåº¦
                
                # æ¨ªå‘ä½ç½®æ§åˆ¶å‚æ•°
                KP_LATERAL = 0.1  # æ¨ªå‘æ§åˆ¶æ¯”ä¾‹ç³»æ•°
                MAX_LATERAL = 0.1 # æœ€å¤§æ¨ªå‘é€Ÿåº¦
                
                # åˆå§‹åŒ–æ§åˆ¶å˜é‡
                '''integral = 0.0
                last_error = 0.0'''
                
                current_time = time.time()
                time_since_entry = current_time - state_entry_time
                
                # è·å–è§†è§‰è¯¯å·®
                yaw_error = vision_node.yaw_adjust
                lateral_error = vision_node.lateral_error
                
                # åèˆªæ§åˆ¶è®¡ç®—
                
                delta_error = yaw_error - vision_node.last_error
                # print(1)
                '''integral += yaw_error * cmd_interval
                integral = np.clip(vision_node.integral, -1.0, 1.0)'''
                # print(2)
                yaw_speed = KP_YAW * yaw_error + KD_YAW * delta_error
                yaw_speed = np.clip(yaw_speed, -MAX_YAW, MAX_YAW)
                
                # æ¨ªå‘ä½ç½®æ§åˆ¶è®¡ç®—
                lateral_speed = KP_LATERAL * lateral_error
                lateral_speed = np.clip(lateral_speed, -MAX_LATERAL, MAX_LATERAL)
                
                # æ„é€ æ§åˆ¶æŒ‡ä»¤
                # msg = MotionMsg()
                msg.mode = 11                  # è¿åŠ¨æ¨¡å¼
                msg.gait_id = 3               # æ­¥æ€ç±»å‹
                msg.vel_des = [0.01, lateral_speed, yaw_speed]  # [å‰è¿›é€Ÿåº¦ï¼Œæ¨ªå‘é€Ÿåº¦ï¼Œåèˆªé€Ÿåº¦]
                msg.rpy_des = [0, 2.5, 0]      # å§¿æ€è§’åº¦
                msg.step_height = [0.01, 0.01] # æ­¥é«˜
                msg.life_count = (msg.life_count + 1) % 128
                
                # å‘é€æ§åˆ¶æŒ‡ä»¤
                Ctrl.Send_cmd(msg)
                
                # è°ƒè¯•è¾“å‡º
                if vision_node.debug_mode:
                    print(f"Control | YawErr: {np.degrees(yaw_error):+.1f}\u00B0"
                        f"LatErr: {lateral_error:.2f} | "
                        f"YawSpd: {yaw_speed:.2f} LatSpd: {lateral_speed:.2f}")
                
                # æ›´æ–°çŠ¶æ€å˜é‡
                vision_node.last_error = yaw_error
                last_cmd_time = current_time
                
                # çŠ¶æ€é€€å‡ºæ¡ä»¶
                if time_since_entry > 10 and abs(yaw_error) < 0.1:  # 15ç§’åé€€å‡º
                    state_id = 19.55
                    msg.mode = 11
                    msg.gait_id = 3
                    msg.vel_des = [0.2, 0.0, 0]
                    msg.life_count = (msg.life_count + 1) % 128
                    Ctrl.Send_cmd(msg)
                    time.sleep( 3 )
                    vision_node.last_error = 0
                    vision_node.integral = 0
                    print("è¿›å…¥çŠ¶æ€1955")
                
                time.sleep(cmd_interval)  # æ§åˆ¶å¾ªç¯é¢‘ç‡
            
            elif state_id == 19.55:
                dir = 1 if arrow == Direction.Left else -1
                if current_time - last_cmd_time > cmd_interval:
                    msg.mode = 11
                    msg.gait_id = 3
                    msg.vel_des = [0.1, -0.005 * dir, 0]
                    msg.rpy_des = [0, 2.5, 0]
                    msg.step_height = [0.02, 0.02]
                    msg.life_count = (msg.life_count + 1) % 128
                    Ctrl.Send_cmd(msg)
                    last_cmd_time = current_time
                # æ£€æµ‹åˆ°å¹¶å†³å®šè½¬å‘
                if vision_node._19_55_detected:
                    msg.mode = 11
                    msg.gait_id = 3
                    msg.vel_des = [0.2, 0, 0]
                    msg.rpy_des = [0, 2.5, 0]
                    msg.life_count = (msg.life_count + 1) % 128
                    Ctrl.Send_cmd(msg)
                    time.sleep(1.5)
                    # standup()
                    dir = 1 if arrow == Direction.Left else -1
                    msg.mode = 11
                    msg.gait_id = 3
                    msg.vel_des = [0.0, 0, -1.3 * dir]
                    msg.rpy_des = [0, 2.5, 0]
                    msg.life_count = (msg.life_count + 1) % 128
                    Ctrl.Send_cmd(msg)
                    time.sleep(0.6)
                    standup()
                    state_id = 19.6

            elif state_id == 19.6:
                if current_time - last_cmd_time > cmd_interval:
                    
                    msg.mode = 3
                    msg.gait_id = 0
                    msg.vel_des = [0.0, 0.0, 0.0]
                    msg.rpy_des = [ 0.0, -1.8, 0.0]
                    msg.pos_des = [0.0, 0.0, 0.235]
                    msg.life_count = (msg.life_count + 1) % 128
                    Ctrl.Send_cmd(msg)
                    # print("ç«™ç«‹ï¼Œå¼€å§‹è¯†åˆ«äºŒç»´ç ")

                if vision_node._19_6_detected:
                    if QR2 == 'B-1':
                        speech_node.play_speech("BåŒºåº“ä½1")
                        #pass
                    else:
                        #pass
                        speech_node.play_speech("BåŒºåº“ä½2")
                    time.sleep(1)
                    cmd_state = None
                    dir = 1 if arrow == Direction.Left else -1
                    msg.mode = 11
                    msg.gait_id = 3
                    msg.vel_des = [0.0, 0, 0.55 * dir]
                    msg.rpy_des = [0, 2.5, 0]
                    msg.life_count = (msg.life_count + 1) % 128
                    Ctrl.Send_cmd(msg)
                    time.sleep(1.3)
                    standup()
                    state_id = 20
                    print("è¿›å…¥çŠ¶æ€20")

            #20æ‹(left+B2 or right+B1)->21ï¼Œä¸æ‹(left+B1 or right+B2)->23
            elif state_id == 20:
                # print(20)
                # å‘¨æœŸæ€§å‘å‘½ä»¤ä¿æŒè¿åŠ¨çŠ¶æ€
                dir = 0.0 if arrow == Direction.Right else -0.01
                if current_time - last_cmd_time > cmd_interval:
                    msg.mode = 11
                    msg.gait_id = 3
                    msg.vel_des = [0.1, dir, 0]
                    msg.rpy_des = [0, 2.5, 0]
                    msg.life_count = (msg.life_count + 1) % 128
                    Ctrl.Send_cmd(msg)
                    last_cmd_time = current_time
                # æ£€æµ‹åˆ°å¹¶å†³å®šè½¬å‘
                if vision_node._20_detected:
                    
                    if arrow == Direction.Left:
                        # state_id = 23 if QR2 == 'B-1' else 21
                        dir = 0 if QR2 == 'B-1' else 1
                    else:
                        # state_id = 23 if QR2 == 'B-2' else 21
                        dir = 0 if QR2 == 'B-2' else -1
                    dur = 1.3 if arrow == Direction.Left else 1.25
                    msg.mode = 11
                    msg.gait_id = 3
                    msg.vel_des = [0.3, 0, 0]
                    msg.rpy_des = [0, 2.5, 0]
                    msg.life_count = (msg.life_count + 1) % 128
                    Ctrl.Send_cmd(msg)
                    time.sleep( 0.15 )
                    msg.mode = 11
                    msg.gait_id = 3
                    msg.vel_des = [0.15, 0, -1.4 * dir]
                    msg.rpy_des = [0, 2.5, 0]
                    msg.life_count = (msg.life_count + 1) % 128
                    Ctrl.Send_cmd(msg)
                    time.sleep( dur )
                    if dir != 0:
                        msg.mode = 11
                        msg.gait_id = 3
                        msg.vel_des = [0.3, 0, 0]
                        msg.rpy_des = [0, 2.5, 0]
                        msg.life_count = (msg.life_count + 1) % 128
                        Ctrl.Send_cmd(msg)
                        time.sleep( 3.0 )
                        state_id = 21
                        print("è¿›å…¥çŠ¶æ€21")
                        continue
                    else:
                        msg.mode = 11
                        msg.gait_id = 3
                        msg.vel_des = [0.3, 0, 0] #yç»™æ­£ä¸ºå·¦
                        msg.rpy_des = [0, 2.5, 0]
                        msg.life_count = (msg.life_count + 1) % 128
                        Ctrl.Send_cmd(msg)
                        time.sleep( 1.3 )
                    if arrow == Direction.Left:
                        state_id = 29
                        print("è¿›å…¥çŠ¶æ€29")
                    else:
                        state_id = 23
                        print("è¿›å…¥çŠ¶æ€23")
                    # break
                    # state_id = 29

            
            # 21å¯¹é½æ–¹å‘
            elif state_id == 21:
                ALIGN_DURATION = 0.1    # éœ€è¦æŒç»­å¯¹é½æ—¶é—´ï¼ˆç§’ï¼‰
                KP = -0.6               # æ¯”ä¾‹ç³»æ•°
                KD = 1.0                # å¾®åˆ†ç³»æ•°
                # angle_0 = 0.0           # åˆå§‹åŒ–è§’åº¦
                MAX_YAW = 0.05          # æœ€å¤§è½¬å‘é€Ÿåº¦ï¼ˆrad/sï¼‰
                SEARCH_SPEED = 0.0      # æœç´¢è½¬é€Ÿï¼ˆrad/sï¼‰
                
                if current_time - last_cmd_time > cmd_interval:
                    if vision_node._21_detected:
                        angle_error = vision_node.line_angle
                        delta = vision_node.angle_0 - angle_error
                        vision_node.angle_0 = angle_error
                        duration = vision_node.aligned_duration
                        
                        if duration >= ALIGN_DURATION:
                            print("è¿›å…¥çŠ¶æ€22")
                            state_id = 22
                            vision_node.angle_0 = 0
                            # vision_node.aligned_duration = 0
                            continue
                        
                        yaw_speed = np.clip(angle_error * KP + delta * KD, -MAX_YAW, MAX_YAW)
                        msg.mode = 11
                        msg.gait_id = 3
                        msg.vel_des = [0.01, 0.0, yaw_speed]
                        msg.rpy_des = [0, 2.5, 0]
                        msg.life_count = (msg.life_count + 1) % 128
                        Ctrl.Send_cmd(msg)
                        # print(f"è§’åº¦è¯¯å·®: {np.degrees(angle_error):+.1f}\u00B0 | æŒç»­: {duration:.4f}s | yaw: {yaw_speed:.2f}")
                        last_cmd_time = current_time
                    else:
                        msg.mode = 11
                        msg.gait_id = 3
                        msg.vel_des = [0.04, 0.0, SEARCH_SPEED]
                        msg.rpy_des = [0, 2.5, 0]
                        msg.life_count = (msg.life_count + 1) % 128
                        Ctrl.Send_cmd(msg)
                        # print("æœç´¢é»„çº¿")
                        last_cmd_time = current_time
            
            # 22åˆ°ä½ç½®æ‹å¼¯
            elif state_id == 22:
                if current_time - last_cmd_time > cmd_interval:
                    msg.mode = 11
                    msg.gait_id = 3
                    msg.vel_des = [0.08, 0, 0]
                    msg.rpy_des = [0, 2.5, 0]
                    msg.life_count = (msg.life_count + 1) % 128
                    Ctrl.Send_cmd(msg)
                    last_cmd_time = current_time

                if vision_node._22_detected:
                    # ç›´èµ°0.2s
                    dir = 1 if arrow == Direction.Left else -1
                    msg.mode = 11
                    msg.gait_id = 3
                    msg.vel_des = [0.1, 0.0, 0.0]
                    msg.rpy_des = [ 0.0, 2.5, 0.0]
                    msg.life_count = (msg.life_count + 1) % 128
                    Ctrl.Send_cmd(msg)
                    time.sleep( 0.1 )   
                    # å·¦è½¬å¼¯1.14s
                    msg.mode = 11
                    msg.gait_id = 3
                    msg.vel_des = [0.15, 0.0, 1.4 * dir]
                    msg.rpy_des = [ 0.0, 2.5, 0.0]
                    msg.life_count = (msg.life_count + 1) % 128
                    Ctrl.Send_cmd(msg)
                    time.sleep( 1.31 )
                    msg.mode = 11
                    msg.gait_id = 3
                    msg.vel_des = [0.2, 0.0, 0.0]
                    msg.rpy_des = [ 0.0, 2.5, 0.0]
                    msg.life_count = (msg.life_count + 1) % 128
                    Ctrl.Send_cmd(msg)
                    time.sleep( 1.0 )
                    if QR2 == 'B-2':
                        print("è¿›å…¥çŠ¶æ€23")
                        state_id = 24
                    else:
                        print("è¿›å…¥çŠ¶æ€29")
                        state_id = 30
                # break

            # 23 è¿›B2
            elif state_id == 23:
                ALIGN_DURATION = 0.3    # éœ€è¦æŒç»­å¯¹é½æ—¶é—´ï¼ˆç§’ï¼‰
                KP = -0.5               # æ¯”ä¾‹ç³»æ•°
                KD = 1.0                # å¾®åˆ†ç³»æ•°
                angle_0 = 0.0           # åˆå§‹åŒ–è§’åº¦
                MAX_YAW = 0.05          # æœ€å¤§è½¬å‘é€Ÿåº¦ï¼ˆrad/sï¼‰
                SEARCH_SPEED = -0.00      # æœç´¢è½¬é€Ÿï¼ˆrad/sï¼‰
                
                if current_time - last_cmd_time > cmd_interval:
                    if vision_node._23_detected:
                        angle_error = vision_node.line_angle
                        delta = vision_node.angle_0 - angle_error
                        vision_node.angle_0 = angle_error
                        duration = vision_node.aligned_duration
                        
                        if duration >= ALIGN_DURATION:
                            print("è¿›å…¥çŠ¶æ€24")
                            vision_node.angle_0 = 0
                            # vision_node.aligned_duration = 0
                            state_id = 24
                        
                        yaw_speed = np.clip(angle_error * KP + delta * KD, -MAX_YAW, MAX_YAW)
                        msg.mode = 11
                        msg.gait_id = 3
                        msg.vel_des = [0.01, 0.0, yaw_speed]
                        msg.rpy_des = [0, 2.5, 0]
                        # msg.step_height = [0.03, 0.03]
                        msg.life_count = (msg.life_count + 1) % 128
                        Ctrl.Send_cmd(msg)
                        # print(f"è§’åº¦è¯¯å·®: {np.degrees(angle_error):+.1f}\u00B0 | æŒç»­: {duration:.4f}s | yaw: {yaw_speed:.2f}")
                        last_cmd_time = current_time
                    else:
                        msg.mode = 11
                        msg.gait_id = 3
                        msg.vel_des = [0.05, 0.0, SEARCH_SPEED]
                        msg.rpy_des = [0, 2.5, 0]
                        msg.life_count = (msg.life_count + 1) % 128
                        Ctrl.Send_cmd(msg)
                        # print("æœç´¢é»„çº¿")
                        last_cmd_time = current_time

            # 24åˆ°ä½ç½®è¶´ä¸‹
            elif state_id == 24:
                if current_time - last_cmd_time > cmd_interval:
                    msg.mode = 11
                    msg.gait_id = 3
                    msg.vel_des = [0.08, 0, 0]
                    msg.rpy_des = [0, 2.5, 0]
                    msg.life_count = (msg.life_count + 1) % 128
                    Ctrl.Send_cmd(msg)
                    last_cmd_time = current_time

                if vision_node._24_detected:
                    # state_id = 25
                    msg.mode = 11
                    msg.gait_id = 3
                    msg.vel_des = [0.2, 0, 0]
                    msg.rpy_des = [0, 2.5, 0]
                    msg.life_count = (msg.life_count + 1) % 128
                    Ctrl.Send_cmd(msg)
                    time.sleep(1)
                    print('è¶´ä¸‹')
                    down()
                    time.sleep(3)

                    #è¿›å…¥äº¤äº’ç¯èŠ‚
                    while(True):
                        if now_state == 1:
                            break
                    now_state = 0

                    #äº¤äº’æˆåŠŸ
                    standup()
                    time.sleep(1)
                    state_id = 25
                    print("è¿›å…¥çŠ¶æ€25")

            # 25èµ·èº«å‘åè½¬
            elif state_id == 25:
                # time.sleep(5)
                msg.mode = 11
                msg.gait_id = 10
                msg.vel_des = [0.0, 0.0, -0.8]
                msg.rpy_des = [0, 2.5, 0]
                msg.life_count = (msg.life_count + 1) % 128
                Ctrl.Send_cmd(msg)
                time.sleep(4.7)

                #test åŸåœ°è¸æ­¥
                msg.mode = 11
                msg.gait_id = 10
                msg.vel_des = [0.0, 0.0, 0.0]
                msg.rpy_des = [0, 2.5, 0]
                msg.life_count = (msg.life_count + 1) % 128
                Ctrl.Send_cmd(msg)
                time.sleep(0.4)

                msg.mode = 11
                msg.gait_id = 10
                msg.vel_des = [0.1, 0.0, 0.0]
                msg.rpy_des = [0, 2.5, 0]
                msg.life_count = (msg.life_count + 1) % 128
                Ctrl.Send_cmd(msg)
                time.sleep(0.5)
                
                '''if QR2 == 'B-2':
                    print("è¿›å…¥çŠ¶æ€26")
                    state_id = 26
                else:
                    print("è¿›å…¥çŠ¶æ€32")
                    state_id = 32'''
                # state_id = 26
                print("è¿›å…¥çŠ¶æ€26")
                state_id = 26
                state_entry_time = time.time()

                # break

            elif state_id == 26:# å‡ºB2
                if current_time - last_cmd_time > cmd_interval:
                    msg.mode = 11
                    msg.gait_id = 3
                    msg.vel_des = [0.1, 0, 0]
                    msg.rpy_des = [0, 2.5, 0]
                    msg.life_count = (msg.life_count + 1) % 128
                    Ctrl.Send_cmd(msg)
                    last_cmd_time = current_time

                if vision_node._26_detected:
                    # standup()
                    # break
                    # # æ£€æµ‹åˆ°é»„è‰²åŒºåŸŸèµ°1.6s
                    vision_node.angle_0 = 0
                    msg.mode = 11
                    msg.gait_id = 3
                    msg.vel_des = [0.3, 0, 0]
                    msg.rpy_des = [0, 2.5, 0]
                    msg.life_count = (msg.life_count + 1) % 128
                    Ctrl.Send_cmd(msg)
                    time.sleep( 1.3 )
                    dir = 0 if QR2 == 'B-1' and arrow == Direction.Left else 1
                    #å³è½¬ 1s 
                    msg.mode = 11
                    msg.gait_id = 3
                    msg.vel_des = [0.3, 0.0, -1.4 * dir]
                    msg.life_count = (msg.life_count + 1) % 128
                    Ctrl.Send_cmd(msg)
                    time.sleep( 1.28 )
                    
                    if dir == 1:
                        msg.mode = 11
                        msg.gait_id = 3
                        msg.vel_des = [0.3, 0.0, 0]
                        msg.life_count = (msg.life_count + 1) % 128
                        Ctrl.Send_cmd(msg)
                        time.sleep( 3 )
                    else:
                        msg.mode = 11
                        msg.gait_id = 3
                        msg.vel_des = [0.2, 0.0, 0]
                        msg.life_count = (msg.life_count + 1) % 128
                        Ctrl.Send_cmd(msg)
                        time.sleep( 2 )

                    if QR2 == 'B-1' and arrow == Direction.Left:
                        print("è¿›å…¥çŠ¶æ€34.5")
                    else:
                        print("è¿›å…¥çŠ¶æ€27")
                    state_id = 34.5 if QR2 == 'B-1' and arrow == Direction.Left else 27
                    state_entry_time = time.time()
                    # vision_node.aligned_duration = 0
            
            
            elif state_id == 27:
                ALIGN_DURATION = 0.3    # éœ€è¦æŒç»­å¯¹é½æ—¶é—´ï¼ˆç§’ï¼‰
                KP = -0.5               # æ¯”ä¾‹ç³»æ•°
                KD = 1.0                # å¾®åˆ†ç³»æ•°
                angle_0 = 0.0           # åˆå§‹åŒ–è§’åº¦
                MAX_YAW = 0.05          # æœ€å¤§è½¬å‘é€Ÿåº¦ï¼ˆrad/sï¼‰
                SEARCH_SPEED = 0.00      # æœç´¢è½¬é€Ÿï¼ˆrad/sï¼‰
                
                if current_time - last_cmd_time > cmd_interval:
                    if vision_node._27_detected:
                        angle_error = vision_node.line_angle
                        delta = vision_node.angle_0 - angle_error
                        vision_node.angle_0 = angle_error
                        duration = vision_node.aligned_duration
                        
                        if duration >= ALIGN_DURATION:
                            print("è¿›å…¥çŠ¶æ€28")
                            vision_node.angle_0 = 0
                            # vision_node.aligned_duration = 0
                            state_id = 28
                            continue
                        
                        yaw_speed = np.clip(angle_error * KP + delta * KD, -MAX_YAW, MAX_YAW)
                        msg.mode = 11
                        msg.gait_id = 3
                        msg.vel_des = [0.01, 0.0, yaw_speed]
                        msg.rpy_des = [0, 2.5, 0]
                        msg.life_count = (msg.life_count + 1) % 128
                        Ctrl.Send_cmd(msg)
                        # print(f"è§’åº¦è¯¯å·®: {np.degrees(angle_error):+.1f}\u00B0 | æŒç»­: {duration:.4f}s | yaw: {yaw_speed:.2f}")
                        last_cmd_time = current_time
                    else:
                        msg.mode = 11
                        msg.gait_id = 3
                        msg.vel_des = [0.09, 0.0, SEARCH_SPEED]
                        msg.rpy_des = [0, 2.5, 0]
                        msg.life_count = (msg.life_count + 1) % 128
                        Ctrl.Send_cmd(msg)
                        # print("æœç´¢é»„çº¿")
                        last_cmd_time = current_time
                # break

            # 28åˆ°ä½ç½®å³æ‹å¼¯
            elif state_id == 28:
                if current_time - last_cmd_time > cmd_interval:
                    msg.mode = 11
                    msg.gait_id = 3
                    msg.vel_des = [0.06, 0, 0]
                    msg.rpy_des = [0, 2.5, 0]
                    msg.life_count = (msg.life_count + 1) % 128
                    Ctrl.Send_cmd(msg)
                    last_cmd_time = current_time

                if vision_node._28_detected:
                    # break
                    '''if QR2 == 'B-2':
                        print("state28.5")
                    else:
                        print("state34.5")'''
                    state_id = 28.5 # if QR2 == 'B-2' else 34.5
                    state_entry_time = time.time()
                    
                    # vision_node.aligned_duration = 0
            
            elif state_id == 28.5:
                msg.mode = 11
                msg.gait_id = 10
                msg.vel_des = [0.1, 0.0, 0.0]
                msg.rpy_des = [ 0.0, 2.5, 0.0]
                msg.life_count = (msg.life_count + 1) % 128
                Ctrl.Send_cmd(msg)
                time.sleep( 0.1 )
                dir = 1 if QR2 == 'B-2' else -1
                msg.mode = 11
                msg.gait_id = 10
                msg.vel_des = [0.15, 0.0, -1.4 * dir]
                msg.rpy_des = [ 0.0, 2.5, 0.0]
                msg.life_count = (msg.life_count + 1) % 128
                Ctrl.Send_cmd(msg)
                time.sleep( 1.33 )
                
                msg.mode = 11
                msg.gait_id = 10
                msg.vel_des = [0.2, 0.0, 0.0]
                msg.rpy_des = [ 0.0, 2.5, 0.0]
                msg.life_count = (msg.life_count + 1) % 128
                Ctrl.Send_cmd(msg)
                time.sleep( 0.4 ) 
                
                # vision_node.aligned_duration = 0
                if QR2 == 'B-2':
                    print("state29")
                else:
                    print("state34.5")
                state_id = 29 if QR2 == 'B-2' else 34.5

            # 29è¿›B1
            elif state_id == 29:
                ALIGN_DURATION = 0.5    # éœ€è¦æŒç»­å¯¹é½æ—¶é—´ï¼ˆç§’ï¼‰
                KP = -0.8               # æ¯”ä¾‹ç³»æ•°
                KD = 1.0                # å¾®åˆ†ç³»æ•°
                angle_0 = 0.0           # åˆå§‹åŒ–è§’åº¦
                MAX_YAW = 0.05          # æœ€å¤§è½¬å‘é€Ÿåº¦ï¼ˆrad/sï¼‰
                SEARCH_SPEED = -0.0      # æœç´¢è½¬é€Ÿï¼ˆrad/sï¼‰
                
                if current_time - last_cmd_time > cmd_interval:
                    if vision_node._29_detected:
                        angle_error = vision_node.line_angle
                        delta = vision_node.angle_0 - angle_error
                        vision_node.angle_0 = angle_error
                        duration = vision_node.aligned_duration
                        
                        if duration >= ALIGN_DURATION:
                            print("è¿›å…¥çŠ¶æ€30")
                            vision_node.angle_0 = 0

                            state_id = 30
                        
                        yaw_speed = np.clip(angle_error * KP + delta * KD, -MAX_YAW, MAX_YAW)
                        msg.mode = 11
                        msg.gait_id = 3
                        msg.vel_des = [0.01, 0.0, yaw_speed]
                        msg.rpy_des = [0, 2.5, 0]
                        msg.step_height = [0.01, 0.01]
                        msg.life_count = (msg.life_count + 1) % 128
                        Ctrl.Send_cmd(msg)
                        # print(f"è§’åº¦è¯¯å·®: {np.degrees(angle_error):+.1f}\u00B0 | æŒç»­: {duration:.4f}s | yaw: {yaw_speed:.2f}")
                        last_cmd_time = current_time
                    else:
                        msg.mode = 11
                        msg.gait_id = 3
                        msg.vel_des = [0.1, 0.0, SEARCH_SPEED]
                        msg.rpy_des = [0, 2.5, 0]
                        msg.life_count = (msg.life_count + 1) % 128
                        Ctrl.Send_cmd(msg)
                        # print("æœç´¢é»„çº¿")
                        last_cmd_time = current_time
            
            # 30åˆ°ä½ç½®è¶´ä¸‹
            elif state_id == 30:
                if current_time - last_cmd_time > cmd_interval:
                    msg.mode = 11
                    msg.gait_id = 3
                    msg.vel_des = [0.08, 0, 0]
                    msg.rpy_des = [0, 2.5, 0]
                    msg.life_count = (msg.life_count + 1) % 128
                    Ctrl.Send_cmd(msg)
                    last_cmd_time = current_time

                if vision_node._30_detected:
                    msg.mode = 11
                    msg.gait_id = 3
                    msg.vel_des = [0.2, 0, 0]
                    msg.rpy_des = [0, 2.5, 0]
                    msg.life_count = (msg.life_count + 1) % 128
                    Ctrl.Send_cmd(msg)
                    time.sleep(1)
                    down()
                    time.sleep(2)

                    #è¿›å…¥äº¤äº’
                    while(True):
                        if now_state == 1:
                            break
                    now_state = 0

                    print("è¿›å…¥çŠ¶æ€31")
                    standup()
                    time.sleep(1)
                    state_id = 31
            
            # 31èµ·èº«å‘åè½¬
            elif state_id == 31:
                msg.mode = 11
                msg.gait_id = 10
                msg.vel_des = [0.0, 0.0, -0.8]
                msg.rpy_des = [0, 2.5, 0]
                # msg.step_height = [0.03, 0.03]
                msg.life_count = (msg.life_count + 1) % 128
                Ctrl.Send_cmd(msg)
                time.sleep(4.7)

                #test åŸåœ°è¸æ­¥
                '''msg.mode = 11
                msg.gait_id = 10
                msg.vel_des = [0.0, 0.0, 0.0]
                msg.rpy_des = [0, 2.5, 0]
                msg.step_height = [0.03,0.03]
                msg.life_count = (msg.life_count + 1) % 128
                Ctrl.Send_cmd(msg)
                time.sleep(0.4)'''

                msg.mode = 11
                msg.gait_id = 10
                msg.vel_des = [0.4, 0.0, 0.0]
                msg.rpy_des = [0, 2.5, 0]
                msg.step_height =[0.03,0.03]
                msg.life_count = (msg.life_count + 1) % 128
                Ctrl.Send_cmd(msg)
                time.sleep(0.5)

                
                '''if QR2 == 'B-1':
                    print("è¿›å…¥çŠ¶æ€26")
                    state_id = 26
                else:'''
                print("è¿›å…¥çŠ¶æ€32")
                state_id = 32
                # state_id = 26
                state_entry_time = time.time()
            
            # 32åˆ°ä½ç½®æ‹å¼¯ (å‡ºB1)
            elif state_id == 32:
                if current_time - last_cmd_time > cmd_interval:
                    msg.mode = 11
                    msg.gait_id = 3
                    msg.vel_des = [0.12, 0, 0]
                    msg.rpy_des = [0, 2.5, 0]
                    msg.life_count = (msg.life_count + 1) % 128
                    Ctrl.Send_cmd(msg)
                    last_cmd_time = current_time

                if vision_node._32_detected:
                    # standup()
                    vision_node.angle_0 = 0
                    msg.mode = 11
                    msg.gait_id = 3
                    msg.vel_des = [0.3, 0, 0]
                    msg.rpy_des = [0, 2.5, 0]
                    msg.life_count = (msg.life_count + 1) % 128
                    Ctrl.Send_cmd(msg)
                    time.sleep( 1.28 )
                    dir = 0 if QR2 == 'B-2' and arrow == Direction.Right else 1
                    msg.mode = 11
                    msg.gait_id = 3
                    msg.vel_des = [0.3, 0.0, 1.4 * dir]
                    msg.step_height = [0.03,0.03]
                    msg.life_count = (msg.life_count + 1) % 128
                    Ctrl.Send_cmd(msg)
                    time.sleep( 1.26 )
                    if QR2 == 'B-2' and arrow == Direction.Right:
                        print("è¿›å…¥çŠ¶æ€34.5")
                    else:
                        print("è¿›å…¥çŠ¶æ€33")
                    if dir == 1:
                        msg.mode = 11
                        msg.gait_id = 3
                        msg.vel_des = [0.3, 0.0, 0]
                        msg.life_count = (msg.life_count + 1) % 128
                        Ctrl.Send_cmd(msg)
                        time.sleep( 3.3 )
                    state_id = 34.5 if QR2 == 'B-2' and arrow == Direction.Right else 33
                    state_entry_time = time.time()
                    # state_id = 33
            
            # 33å¯¹é½æ–¹å‘
            elif state_id == 33:
                ALIGN_DURATION = 0.3    # éœ€è¦æŒç»­å¯¹é½æ—¶é—´ï¼ˆç§’ï¼‰
                KP = -0.4               # æ¯”ä¾‹ç³»æ•°
                KD = 1.6                # å¾®åˆ†ç³»æ•°
                # angle_0 = 0.0           # åˆå§‹åŒ–è§’åº¦
                MAX_YAW = 0.05          # æœ€å¤§è½¬å‘é€Ÿåº¦ï¼ˆrad/sï¼‰
                SEARCH_SPEED = 0.0      # æœç´¢è½¬é€Ÿï¼ˆrad/sï¼‰
                
                if current_time - last_cmd_time > cmd_interval:
                    if vision_node._33_detected:
                        angle_error = vision_node.line_angle
                        delta = vision_node.angle_0 - angle_error
                        vision_node.angle_0 = angle_error
                        duration = vision_node.aligned_duration
                        
                        if duration >= ALIGN_DURATION:
                            print("è¿›å…¥çŠ¶æ€34")
                            state_id = 34
                            continue
                        
                        yaw_speed = np.clip(angle_error * KP + delta * KD, -MAX_YAW, MAX_YAW)
                        msg.mode = 11
                        msg.gait_id = 3
                        msg.vel_des = [0.01, 0.0, yaw_speed]
                        msg.rpy_des = [0, 2.5, 0]
                        # msg.step_height = [0.03, 0.03]
                        msg.life_count = (msg.life_count + 1) % 128
                        Ctrl.Send_cmd(msg)
                        # print(f"è§’åº¦è¯¯å·®: {np.degrees(angle_error):+.1f}\u00B0 | æŒç»­: {duration:.4f}s | yaw: {yaw_speed:.2f}")
                        last_cmd_time = current_time
                    else:
                        msg.mode = 11
                        msg.gait_id = 3
                        msg.vel_des = [0.06, 0.0, SEARCH_SPEED]
                        msg.rpy_des = [0, 2.5, 0]
                        # msg.step_height = [0.03, 0.03]
                        msg.life_count = (msg.life_count + 1) % 128
                        Ctrl.Send_cmd(msg)
                        # print("æœç´¢é»„çº¿")
                        last_cmd_time = current_time
            
            # 34åˆ°ä½ç½®å³æ‹å¼¯
            elif state_id == 34:
                # print(1)
                if current_time - last_cmd_time > cmd_interval:
                    msg.mode = 11
                    msg.gait_id = 3
                    msg.vel_des = [0.1, 0, 0]
                    msg.rpy_des = [0, 2.5, 0]
                    msg.life_count = (msg.life_count + 1) % 128
                    Ctrl.Send_cmd(msg)
                    last_cmd_time = current_time

                if vision_node._34_detected:
                    msg.mode = 11
                    msg.gait_id = 3
                    msg.vel_des = [0.1, 0, 0]
                    msg.rpy_des = [0, 2.5, 0]
                    msg.life_count = (msg.life_count + 1) % 128
                    Ctrl.Send_cmd(msg)
                    time.sleep( 0.1 )
                    dir = -1 if QR2 == 'B-2' and arrow == Direction.Left else 1
                    msg.mode = 11
                    msg.gait_id = 3
                    msg.vel_des = [0.1, 0.0, 1.4 * dir]
                    msg.life_count = (msg.life_count + 1) % 128
                    Ctrl.Send_cmd(msg)
                    time.sleep( 1.35 )
                    msg.mode = 11
                    msg.gait_id = 3
                    msg.vel_des = [0.2, 0.0, 0.0]
                    msg.rpy_des = [ 0.0, 2.5, 0.0]
                    msg.life_count = (msg.life_count + 1) % 128
                    Ctrl.Send_cmd(msg)
                    time.sleep( 1.0 ) 
                    # åŸåœ°è¸æ­¥ï¼Œä¸ç„¶state34.5ä¼šå¯¼è‡´è½¬å¼¯è§’åº¦ä¸å¯¹
                    if QR2 == 'B-2' and arrow == Direction.Left:
                        print("è¿›å…¥çŠ¶æ€34_5")
                    else:
                        print("è¿›å…¥çŠ¶æ€23")
                    state_id = 34.5 if QR2 == 'B-2' and arrow == Direction.Left else 23
                    state_entry_time = time.time()
                    

            elif state_id == 34.5:
                # PIDæ§åˆ¶å™¨å‚æ•°
                KP_YAW = 0.7      # åèˆªæ§åˆ¶æ¯”ä¾‹ç³»æ•°
                KD_YAW = 1.0      # åèˆªæ§åˆ¶å¾®åˆ†ç³»æ•°
                KI_YAW = 0.05     # åèˆªæ§åˆ¶ç§¯åˆ†ç³»æ•°
                MAX_YAW = 0.2     # æœ€å¤§åèˆªé€Ÿåº¦
                
                # æ¨ªå‘ä½ç½®æ§åˆ¶å‚æ•°
                KP_LATERAL = 0.4  # æ¨ªå‘æ§åˆ¶æ¯”ä¾‹ç³»æ•°
                MAX_LATERAL = 0.1 # æœ€å¤§æ¨ªå‘é€Ÿåº¦
                
                # åˆå§‹åŒ–æ§åˆ¶å˜é‡
                '''integral = 0.0
                last_error = 0.0'''
                
                current_time = time.time()
                time_since_entry = current_time - state_entry_time
                
                # è·å–è§†è§‰è¯¯å·®
                yaw_error = vision_node.yaw_adjust
                lateral_error = vision_node.lateral_error
                
                # åèˆªæ§åˆ¶è®¡ç®—
                
                delta_error = yaw_error - vision_node.last_error
                # print(1)
                '''integral += yaw_error * cmd_interval
                integral = np.clip(vision_node.integral, -1.0, 1.0)'''
                # print(2)
                yaw_speed = KP_YAW * yaw_error + KD_YAW * delta_error
                yaw_speed = np.clip(yaw_speed, -MAX_YAW, MAX_YAW)
                
                # æ¨ªå‘ä½ç½®æ§åˆ¶è®¡ç®—
                lateral_speed = KP_LATERAL * lateral_error
                lateral_speed = np.clip(lateral_speed, -MAX_LATERAL, MAX_LATERAL)
                
                # æ„é€ æ§åˆ¶æŒ‡ä»¤
                # msg = MotionMsg()
                msg.mode = 11                  # è¿åŠ¨æ¨¡å¼
                msg.gait_id = 3               # æ­¥æ€ç±»å‹
                msg.vel_des = [0.01, lateral_speed, yaw_speed]  # [å‰è¿›é€Ÿåº¦ï¼Œæ¨ªå‘é€Ÿåº¦ï¼Œåèˆªé€Ÿåº¦]
                msg.rpy_des = [0, 2.5, 0]      # å§¿æ€è§’åº¦
                msg.step_height = [0.01, 0.01] # æ­¥é«˜
                msg.life_count = (msg.life_count + 1) % 128
                
                # å‘é€æ§åˆ¶æŒ‡ä»¤
                Ctrl.Send_cmd(msg)
                
                # è°ƒè¯•è¾“å‡º
                print(f"Control | YawErr: {np.degrees(yaw_error):+.1f}\u00B0 "
                        f"LatErr: {lateral_error:.2f} | "
                        f"YawSpd: {yaw_speed:.2f} LatSpd: {lateral_speed:.2f}")
                
                # æ›´æ–°çŠ¶æ€å˜é‡
                vision_node.last_error = yaw_error
                last_cmd_time = current_time
                
                # çŠ¶æ€é€€å‡ºæ¡ä»¶
                if time_since_entry > 5 and abs(np.degrees(yaw_error)) < 0.3:  # 15ç§’åé€€å‡º
                    state_id = 35
                    vision_node.last_error = 0
                    vision_node.integral = 0
                    print("è¿›å…¥çŠ¶æ€35")
                
                time.sleep(cmd_interval)  # æ§åˆ¶å¾ªç¯é¢‘ç‡
                # break
            
            elif state_id == 35:
                if arrow == Direction.Right:
                    standup()
                    depth_node.set_detection_type('limit')
                    limit_detected = main_detection_loop(
                        depth_node, Ctrl, msg, 
                        trigger_distance=1.0, 
                        detection_type="é™é«˜æ†"
                    )
                    if limit_detected:
                        # æ‰§è¡Œé™é«˜æ†åŠ¨ä½œ
                        # cv2.destroyWindow("Limit Detection")
                        standup()
                        msg.mode = 11
                        msg.gait_id = 3
                        msg.vel_des = [0.1, 0.0, 0]
                        msg.life_count = (msg.life_count + 1) % 128
                        Ctrl.Send_cmd(msg)
                        time.sleep( 1.5 )
                        limit(Ctrl, msg)
                        print('è¿›å…¥35.5')
                        state_id = 35.5
                        current_time = time.time()
                        state_entry_time = time.time()
                else:
                    standup()
                    yellowlight()
                    standup()
                    speech_node.start_countdown()
                    time.sleep(7)
                    '''msg.mode = 11
                    msg.gait_id = 3
                    msg.vel_des = [0.2, 0.0, 0]
                    msg.life_count = (msg.life_count + 1) % 128
                    Ctrl.Send_cmd(msg)
                    time.sleep( 1.5 )'''
                    print('è¿›å…¥35.5')
                    state_id = 35.55
                    current_time = time.time()
                    state_entry_time = time.time()
            
            elif state_id == 35.55:
                msg.mode = 11
                msg.gait_id = 10
                msg.vel_des = [0.2, 0.0, 0]
                msg.life_count = (msg.life_count + 1) % 128
                Ctrl.Send_cmd(msg)
                time.sleep( 0.5 )
                state_id = 35.5
                current_time = time.time()
                state_entry_time = time.time()

            elif state_id == 35.5:
                # PIDæ§åˆ¶å™¨å‚æ•°
                KP_YAW = 0.7      # åèˆªæ§åˆ¶æ¯”ä¾‹ç³»æ•°
                KD_YAW = 1.0      # åèˆªæ§åˆ¶å¾®åˆ†ç³»æ•°
                KI_YAW = 0.05     # åèˆªæ§åˆ¶ç§¯åˆ†ç³»æ•°
                MAX_YAW = 0.2     # æœ€å¤§åèˆªé€Ÿåº¦
                
                # æ¨ªå‘ä½ç½®æ§åˆ¶å‚æ•°
                KP_LATERAL = 0.4  # æ¨ªå‘æ§åˆ¶æ¯”ä¾‹ç³»æ•°
                MAX_LATERAL = 0.2 # æœ€å¤§æ¨ªå‘é€Ÿåº¦
                
                # åˆå§‹åŒ–æ§åˆ¶å˜é‡
                '''integral = 0.0
                last_error = 0.0'''
                
                current_time = time.time()
                time_since_entry = current_time - state_entry_time
                
                # è·å–è§†è§‰è¯¯å·®
                yaw_error = vision_node.yaw_adjust
                lateral_error = vision_node.lateral_error
                
                # åèˆªæ§åˆ¶è®¡ç®—
                
                delta_error = yaw_error - vision_node.last_error
                # print(1)
                '''integral += yaw_error * cmd_interval
                integral = np.clip(vision_node.integral, -1.0, 1.0)'''
                # print(2)
                yaw_speed = KP_YAW * yaw_error + KD_YAW * delta_error
                yaw_speed = np.clip(yaw_speed, -MAX_YAW, MAX_YAW)
                
                # æ¨ªå‘ä½ç½®æ§åˆ¶è®¡ç®—
                lateral_speed = KP_LATERAL * lateral_error
                lateral_speed = np.clip(lateral_speed, -MAX_LATERAL, MAX_LATERAL)
                
                # æ„é€ æ§åˆ¶æŒ‡ä»¤
                # msg = MotionMsg()
                msg.mode = 11                  # è¿åŠ¨æ¨¡å¼
                msg.gait_id = 3               # æ­¥æ€ç±»å‹
                msg.vel_des = [0.01, lateral_speed, yaw_speed]  # [å‰è¿›é€Ÿåº¦ï¼Œæ¨ªå‘é€Ÿåº¦ï¼Œåèˆªé€Ÿåº¦]
                msg.rpy_des = [0, 2.5, 0]      # å§¿æ€è§’åº¦
                msg.step_height = [0.02, 0.02] # æ­¥é«˜
                msg.life_count = (msg.life_count + 1) % 128
                
                # å‘é€æ§åˆ¶æŒ‡ä»¤
                Ctrl.Send_cmd(msg)
                
                # è°ƒè¯•è¾“å‡º
                if vision_node.debug_mode:
                    print(f"Control | YawErr: {np.degrees(yaw_error):+.1f}\u00B0 "
                        f"LatErr: {lateral_error:.2f} | "
                        f"YawSpd: {yaw_speed:.2f} LatSpd: {lateral_speed:.2f}")
                
                # æ›´æ–°çŠ¶æ€å˜é‡
                vision_node.last_error = yaw_error
                last_cmd_time = current_time
                
                # çŠ¶æ€é€€å‡ºæ¡ä»¶
                if time_since_entry > 5 and abs(np.degrees(yaw_error)) < 0.1:  # 15ç§’åé€€å‡º
                    vision_node.last_error = 0
                    vision_node.integral = 0
                    print("è¿›å…¥çŠ¶æ€36")
                    state_id = 36
                
                time.sleep(cmd_interval)  # æ§åˆ¶å¾ªç¯é¢‘ç‡
            
            elif state_id == 36:
                if arrow == Direction.Right:
                    depth_node.set_detection_type('stone')
                    stone_detected = main_detection_loop(
                        depth_node, Ctrl, msg, 
                        trigger_distance=0.6, 
                        detection_type="çŸ³å¤´è·¯"
                    )

                    if stone_detected:
                        standup()
                        msg.mode = 11
                        msg.gait_id = 27
                        msg.vel_des = [0.1, 0, 0.02]
                        # msg.step_height = [0.04, 0.04]
                        msg.life_count = (msg.life_count + 1) % 128
                        Ctrl.Send_cmd(msg)
                        time.sleep(2.5)
                        standup()
                        # time.sleep(1)
                        stone_road(88)
                        # ctrl.Wait_finish(62, 81, duration)
                        state_id = 36.5
                        # vision_node.last_error = 0
                        # vision_node.integral = 0
                        msg.mode = 11
                        msg.gait_id = 27
                        msg.vel_des = [0.01, -0.02, -0.02]
                        # msg.step_height = [0.04, 0.04]
                        msg.life_count = (msg.life_count + 1) % 128
                        Ctrl.Send_cmd(msg)
                        time.sleep(3)
                        state_entry_time = time.time()
                else:
                    depth_node.set_detection_type('slope')
                    slope_detected = main_detection_loop(
                        depth_node, Ctrl, msg, 
                        trigger_distance=1.4, 
                        detection_type="æ–œå¡"
                    )
                    
                    if slope_detected:
                        msg.mode = 11
                        msg.gait_id = 27
                        msg.vel_des = [0.1, 0, 0]
                        msg.step_height = [0.01, 0.01]
                        msg.life_count = (msg.life_count + 1) % 128
                        Ctrl.Send_cmd(msg)
                        time.sleep(6.7)
                        standup()  
                        upslope(15)  
                        print("Upslope ends.")
                        stand()
                        standup()
                        '''msg.mode = 11
                        msg.gait_id = 3
                        msg.vel_des = [0.15, 0, 0]
                        msg.life_count = (msg.life_count + 1) % 128
                        msg.step_height = [0.02, 0.02]
                        #msg.duration = duration * 1000  
                        Ctrl.Send_cmd(msg)
                        time.sleep(2) '''   
                        #standup()
                        downslope()
                        msg.mode = 11
                        msg.gait_id = 27
                        msg.vel_des = [0.01, 0, -0.2]
                        msg.life_count = (msg.life_count + 1) % 128
                        msg.step_height = [0.01, 0.01]
                        #msg.duration = duration * 1000  
                        Ctrl.Send_cmd(msg)
                        time.sleep(0.1)
                        # walk(1)
                        # walk(5)
                        state_id = 36.5
                        state_entry_time = time.time()

            elif state_id == 36.5:
                ALIGN_DURATION = 0.3    # éœ€è¦æŒç»­å¯¹é½æ—¶é—´ï¼ˆç§’ï¼‰
                KP = -1.0               # æ¯”ä¾‹ç³»æ•°
                KD = 0.5                # å¾®åˆ†ç³»æ•°
                angle_0 = 0.0           # åˆå§‹åŒ–è§’åº¦
                MAX_YAW = 0.02          # æœ€å¤§è½¬å‘é€Ÿåº¦ï¼ˆrad/sï¼‰
                SEARCH_SPEED = 0.00      # æœç´¢è½¬é€Ÿï¼ˆrad/sï¼‰
                
                if current_time - last_cmd_time > cmd_interval:
                    if vision_node._36_5_detected:
                        angle_error = vision_node.line_angle
                        delta = vision_node.angle_0 - angle_error
                        vision_node.angle_0 = angle_error
                        duration = vision_node.aligned_duration
                        
                        if duration >= ALIGN_DURATION:
                            print("è¿›å…¥çŠ¶æ€37")
                            msg.mode = 11
                            msg.gait_id = 3
                            msg.vel_des = [0.01, 0, 0]
                            msg.rpy_des = [0, 5, 0]
                            #msg.step_height = [0.02, 0.03]
                            msg.life_count = (msg.life_count + 1) % 128
                            Ctrl.Send_cmd(msg)
                            time.sleep(0.5)
                            vision_node.angle_0 = 0
                            state_id = 37
                        
                        yaw_speed = np.clip(angle_error * KP + delta * KD, -MAX_YAW, MAX_YAW)
                        msg.mode = 11
                        msg.gait_id = 3
                        msg.vel_des = [0.00, 0.0, yaw_speed]
                        msg.rpy_des = [0, 5, 0]
                        msg.step_height = [0.01, 0.01]
                        msg.life_count = (msg.life_count + 1) % 128
                        Ctrl.Send_cmd(msg)
                        # print(f"è§’åº¦è¯¯å·®: {np.degrees(angle_error):+.1f}\u00B0 | æŒç»­: {duration:.4f}s | yaw: {yaw_speed:.2f}")
                        last_cmd_time = current_time
                    else:
                        msg.mode = 11
                        msg.gait_id = 3
                        msg.vel_des = [0.01, 0.0, SEARCH_SPEED]
                        msg.rpy_des = [0, 2.5, 0]
                        msg.life_count = (msg.life_count + 1) % 128
                        Ctrl.Send_cmd(msg)
                        # print("æœç´¢é»„çº¿")
                        last_cmd_time = current_time
            
            elif state_id == 37:
                if current_time - last_cmd_time > cmd_interval:
                    msg.mode = 11
                    msg.gait_id = 3
                    msg.vel_des = [0.01, 0, 0]
                    msg.rpy_des = [0, 2.5, 0]
                    msg.step_height = [0.01, 0.01]
                    msg.life_count = (msg.life_count + 1) % 128
                    Ctrl.Send_cmd(msg)
                    last_cmd_time = current_time

                if vision_node._37_detected:
                    msg.mode = 11
                    msg.gait_id = 3
                    msg.vel_des = [0.1, 0, 0]
                    msg.rpy_des = [0, 0, 0]
                    msg.step_height = [0.01, 0.01]
                    msg.life_count = (msg.life_count + 1) % 128
                    Ctrl.Send_cmd(msg)
                    time.sleep( 2.0)
                    dir = 1 if arrow == Direction.Left else -1
                    msg.mode = 11
                    msg.gait_id = 3
                    msg.vel_des = [0.01, 0.0, -1.4 * dir]
                    msg.step_height = [0.01, 0.01]
                    msg.life_count = (msg.life_count + 1) % 128
                    Ctrl.Send_cmd(msg)
                    time.sleep( 1.44 )
                    print("è¿›å…¥çŠ¶æ€38")
                    state_id = 39
            
            elif state_id == 38:
                ALIGN_DURATION = 0.15    # éœ€è¦æŒç»­å¯¹é½æ—¶é—´ï¼ˆç§’ï¼‰
                KP = -1.5               # æ¯”ä¾‹ç³»æ•°
                KD = 1.0                # å¾®åˆ†ç³»æ•°
                angle_0 = 0.0           # åˆå§‹åŒ–è§’åº¦
                MAX_YAW = 0.05          # æœ€å¤§è½¬å‘é€Ÿåº¦ï¼ˆrad/sï¼‰
                SEARCH_SPEED = -0.01      # æœç´¢è½¬é€Ÿï¼ˆrad/sï¼‰
                
                if current_time - last_cmd_time > cmd_interval:
                    if vision_node._38_detected:
                        angle_error = vision_node.line_angle
                        delta = vision_node.angle_0 - angle_error
                        vision_node.angle_0 = angle_error
                        duration = vision_node.aligned_duration
                        
                        if duration >= ALIGN_DURATION:
                            print("è¿›å…¥çŠ¶æ€39")
                            vision_node.angle_0 = 0
                            state_id = 39
                            continue
                        
                        yaw_speed = np.clip(angle_error * KP + delta * KD, -MAX_YAW, MAX_YAW)
                        msg.mode = 11
                        msg.gait_id = 3
                        msg.vel_des = [0.01, 0.0, yaw_speed]
                        msg.rpy_des = [0, 0, 0]
                        msg.life_count = (msg.life_count + 1) % 128
                        Ctrl.Send_cmd(msg)
                        # print(f"è§’åº¦è¯¯å·®: {np.degrees(angle_error):+.1f}\u00B0 | æŒç»­: {duration:.4f}s | yaw: {yaw_speed:.2f}")
                        last_cmd_time = current_time
                    else:
                        msg.mode = 11
                        msg.gait_id = 3
                        msg.vel_des = [0.03, 0.0, SEARCH_SPEED]
                        msg.rpy_des = [0, 0, 0]
                        msg.life_count = (msg.life_count + 1) % 128
                        Ctrl.Send_cmd(msg)
                        # print("æœç´¢é»„çº¿")
                        last_cmd_time = current_time
            
            elif state_id == 39:
                if current_time - last_cmd_time > cmd_interval:
                    msg.mode = 11
                    msg.gait_id = 3
                    msg.vel_des = [0.16, 0, 0]
                    msg.rpy_des = [0, 2.5, 0]
                    msg.life_count = (msg.life_count + 1) % 128
                    Ctrl.Send_cmd(msg)
                    last_cmd_time = current_time

                if vision_node._39_detected:
                    # rgb_camera.is_node_running = True
                    dir = 1 if arrow == Direction.Right else -1
                    dur = 1.2 if arrow == Direction.Right else 2
                    msg.mode = 11
                    msg.gait_id = 3
                    msg.vel_des = [0.2, 0, 0]
                    msg.rpy_des = [0, 2.5, 0]
                    msg.step_height=[0.01,0.01]
                    msg.life_count = (msg.life_count + 1) % 128
                    Ctrl.Send_cmd(msg)
                    time.sleep( dur )
                    dur = 1.4 if arrow == Direction.Right else 1.6
                    msg.mode = 11
                    msg.gait_id = 3
                    msg.vel_des = [0.2, 0, -1.4 * dir]
                    msg.rpy_des = [0, 2.5, 0]
                    msg.step_height=[0.01,0.01]
                    msg.life_count = (msg.life_count + 1) % 128
                    Ctrl.Send_cmd(msg)
                    time.sleep( 1.44 )
                
                    msg.mode = 11
                    msg.gait_id = 3
                    msg.vel_des = [0.1, 0, 0]
                    msg.rpy_des = [0, 2.5, 0]
                    msg.life_count = (msg.life_count + 1) % 128
                    Ctrl.Send_cmd(msg)
                    time.sleep( 2 )
                    print("è¿›å…¥çŠ¶æ€39.5")
                    
                    state_id = 39.5
            
            elif state_id == 39.5:
                #print(15)
                order = 2
                rgb_camera.is_node_running = True
                # os.system('python3 order1and2_test_7_15.py')
                #print(rgb_camera.is_node_running)
                time.sleep(2)
                print(order)

                run_cur()

                #just for test æ­£å¼çš„æ—¶å€™éœ€è¦æ³¨é‡Š è°ƒè¯•
                # real_rgb_camera.is_node_running = True
                # print(real_rgb_camera.is_node_running)

                jiaozheng2()
                #xuanzhuan(Direction.Left)
                time.sleep(8) #å‡½æ•°è‡ªå¸¦çš„timesleepå¤ªçŸ­

                # print(arrow)
                rgb_camera.is_node_running = False
                real_rgb_camera.is_node_running = False
                state_id = 39.55
                print("è¿›å…¥çŠ¶æ€40")            
            elif state_id == 39.55:
                msg.mode = 11                  # è¿åŠ¨æ¨¡å¼
                msg.gait_id = 3               # æ­¥æ€ç±»å‹
                msg.vel_des = [0.2, 0, 0]  # [å‰è¿›é€Ÿåº¦ï¼Œæ¨ªå‘é€Ÿåº¦ï¼Œåèˆªé€Ÿåº¦]
                msg.rpy_des = [0, 2.5, 0]      # å§¿æ€è§’åº¦
                msg.step_height = [0.03, 0.03] # æ­¥é«˜
                msg.life_count = (msg.life_count + 1) % 128
                time.sleep(5)
                state_id = 40

            # å¯¹é½åº•çº¿
            elif state_id == 40:
                ALIGN_DURATION = 0.15    # éœ€è¦æŒç»­å¯¹é½æ—¶é—´ï¼ˆç§’ï¼‰
                KP = -1.5               # æ¯”ä¾‹ç³»æ•°
                KD = 1.0                # å¾®åˆ†ç³»æ•°
                angle_0 = 0.0           # åˆå§‹åŒ–è§’åº¦
                MAX_YAW = 0.05          # æœ€å¤§è½¬å‘é€Ÿåº¦ï¼ˆrad/sï¼‰
                SEARCH_SPEED = -0.0      # æœç´¢è½¬é€Ÿï¼ˆrad/sï¼‰
                
                if current_time - last_cmd_time > cmd_interval:
                    if vision_node._40_detected:
                        angle_error = vision_node.line_angle
                        delta = vision_node.angle_0 - angle_error
                        vision_node.angle_0 = angle_error
                        duration = vision_node.aligned_duration
                        
                        if duration >= ALIGN_DURATION:
                            print("è¿›å…¥çŠ¶æ€41")
                            standup()
                            vision_node.angle_0 = 0
                            state_id = 41
                            continue
                        
                        yaw_speed = np.clip(angle_error * KP + delta * KD, -MAX_YAW, MAX_YAW)
                        msg.mode = 11
                        msg.gait_id = 3
                        msg.vel_des = [0.01, 0.0, yaw_speed]
                        msg.rpy_des = [0, 2.5, 0]
                        msg.step_height = [0.02, 0.02]
                        msg.life_count = (msg.life_count + 1) % 128
                        Ctrl.Send_cmd(msg)
                        print(f"è§’åº¦è¯¯å·®: {np.degrees(angle_error):+.1f}\u00B0 | æŒç»­: {duration:.4f}s | yaw: {yaw_speed:.2f}")
                        last_cmd_time = current_time
                    else:
                        msg.mode = 11
                        msg.gait_id = 3
                        msg.vel_des = [0.1, 0.0, SEARCH_SPEED]
                        msg.rpy_des = [0, 2.5, 0]
                        msg.step_height = [0.02, 0.02]
                        msg.life_count = (msg.life_count + 1) % 128
                        Ctrl.Send_cmd(msg)
                        # print("æœç´¢é»„çº¿")
                        last_cmd_time = current_time
            
            elif state_id == 41:
                if current_time - last_cmd_time > cmd_interval:
                    msg.mode = 11
                    msg.gait_id = 3
                    msg.vel_des = [0.1, 0, 0]
                    msg.rpy_des = [0, 2.5, 0]
                    msg.step_height = [0.03, 0.03]
                    msg.life_count = (msg.life_count + 1) % 128
                    Ctrl.Send_cmd(msg)
                    last_cmd_time = current_time

                if vision_node._41_detected:
                    msg.mode = 11
                    msg.gait_id = 3
                    msg.vel_des = [0.1, 0.0, 0.0]
                    msg.rpy_des = [ 0.0, 2.5, 0.0]
                    msg.step_height = [0.01, 0.01]
                    msg.life_count = (msg.life_count + 1) % 128
                    Ctrl.Send_cmd(msg)
                    time.sleep( 0.2 )
                    dir = 1 if QR1 == 'A-2' else -1
                    msg.mode = 11
                    msg.gait_id = 3
                    msg.vel_des = [0.2, 0.0, -1.4 * dir]
                    msg.rpy_des = [ 0.0, 2.5, 0.0]
                    msg.step_height = [0.01, 0.01]
                    msg.life_count = (msg.life_count + 1) % 128
                    Ctrl.Send_cmd(msg)
                    time.sleep( 1.38 )
                    msg.mode = 11
                    msg.gait_id = 3
                    msg.vel_des = [0.3, 0.0, 0]
                    msg.rpy_des = [ 0.0, 2.5, 0.0]
                    msg.step_height = [0.01, 0.01]
                    msg.life_count = (msg.life_count + 1) % 128
                    Ctrl.Send_cmd(msg)
                    time.sleep( 1.2 )
                    state_id = 43
                    print("è¿›å…¥çŠ¶æ€42")
            # å¯¹é½æ–¹å‘å‡†å¤‡å…¥åº“        
            elif state_id == 42:
                ALIGN_DURATION = 0.5    # éœ€è¦æŒç»­å¯¹é½æ—¶é—´ï¼ˆç§’ï¼‰
                KP = -1.2              # æ¯”ä¾‹ç³»æ•°
                KD = 4.0                # å¾®åˆ†ç³»æ•°
                KI = 0.01
                MAX_YAW = 0.05          # æœ€å¤§è½¬å‘é€Ÿåº¦ï¼ˆrad/sï¼‰
                SEARCH_SPEED = 0.00      # æœç´¢è½¬é€Ÿï¼ˆrad/sï¼‰
                
                if current_time - last_cmd_time > cmd_interval:
                    if vision_node._42_detected:
                        angle_error = vision_node.line_angle
                        delta = vision_node.angle_0 - angle_error
                        vision_node.angle_0 = angle_error
                        duration = vision_node.aligned_duration
                        
                        if duration >= ALIGN_DURATION:
                            print("è¿›å…¥çŠ¶æ€43")
                            state_id = 43
                            vision_node.angle_0 = 0
                            '''msg.mode = 11
                            msg.gait_id = 3
                            msg.vel_des = [0.1, 0, 0]
                            msg.rpy_des = [0, 2.5, 0]
                            msg.step_height = [0.03, 0.03]
                            msg.life_count = (msg.life_count + 1) % 128
                            Ctrl.Send_cmd(msg)
                            time.sleep(0.5)'''
                            continue
                        
                        yaw_speed = np.clip(angle_error * KP + delta * KD, -MAX_YAW, MAX_YAW)
                        msg.mode = 11
                        msg.gait_id = 3
                        msg.vel_des = [0.01, 0.0, yaw_speed]
                        msg.rpy_des = [0, 2.5, 0]
                        # msg.step_height = [0.03, 0.03]
                        msg.life_count = (msg.life_count + 1) % 128
                        Ctrl.Send_cmd(msg)
                        # print(f"è§’åº¦è¯¯å·®: {np.degrees(angle_error):+.1f}\u00B0 | æŒç»­: {duration:.4f}s | yaw: {yaw_speed:.2f}")
                        last_cmd_time = current_time
                    else:
                        msg.mode = 11
                        msg.gait_id = 3
                        msg.vel_des = [0.1, 0.0, SEARCH_SPEED]
                        msg.rpy_des = [0, 2.5, 0]
                        msg.step_height = [0.03, 0.03]
                        msg.life_count = (msg.life_count + 1) % 128
                        Ctrl.Send_cmd(msg)
                        # print("æœç´¢é»„çº¿")
                        last_cmd_time = current_time

            elif state_id == 43:
                if current_time - last_cmd_time > cmd_interval:
                    msg.mode = 11
                    msg.gait_id = 3
                    msg.vel_des = [0.12, 0, 0]
                    msg.rpy_des = [0, 2.5, 0]
                    msg.life_count = (msg.life_count + 1) % 128
                    Ctrl.Send_cmd(msg)
                    last_cmd_time = current_time

                if vision_node._43_detected:
                    print("è¿›å…¥çŠ¶æ€44")
                    state_id = 44
                    
            elif state_id == 44:
                msg.mode = 11
                msg.gait_id = 10
                msg.vel_des = [0.2, 0.0, 0.0]
                msg.rpy_des = [ 0.0, 2.5, 0.0]
                msg.life_count = (msg.life_count + 1) % 128
                Ctrl.Send_cmd(msg)
                time.sleep( 0.4 )

                dir = 1 if QR1 == 'A-2' else -1
                dur = 1.3 if QR1 == 'A-1' else 1.56
                msg.mode = 11
                msg.gait_id = 10
                msg.vel_des = [0.1, 0.0, -1.4 * dir]
                msg.rpy_des = [ 0.0, 2.5, 0.0]
                msg.step_height = [0.02, 0.02]
                msg.life_count = (msg.life_count + 1) % 128
                Ctrl.Send_cmd(msg)
                time.sleep( dur )

                msg.mode = 11
                msg.gait_id = 10
                msg.vel_des = [0.3, 0.0, 0]
                msg.rpy_des = [ 0.0, 2.5, 0.0]
                msg.life_count = (msg.life_count + 1) % 128
                Ctrl.Send_cmd(msg)
                time.sleep( 0.8 ) 
                state_id = 45
                print("è¿›å…¥çŠ¶æ€45")    

            elif state_id == 45:
                ALIGN_DURATION = 0.5    # éœ€è¦æŒç»­å¯¹é½æ—¶é—´ï¼ˆç§’ï¼‰
                KP = -0.8               # æ¯”ä¾‹ç³»æ•°
                KD = 1.5                # å¾®åˆ†ç³»æ•°
                # angle_0 = 0.0           # åˆå§‹åŒ–è§’åº¦
                MAX_YAW = 0.05          # æœ€å¤§è½¬å‘é€Ÿåº¦ï¼ˆrad/sï¼‰
                SEARCH_SPEED = 0.00      # æœç´¢è½¬é€Ÿï¼ˆrad/sï¼‰
                
                if current_time - last_cmd_time > cmd_interval:
                    if vision_node._45_detected:
                        angle_error = vision_node.line_angle
                        delta = vision_node.angle_0 - angle_error
                        vision_node.angle_0 = angle_error
                        duration = vision_node.aligned_duration
                        
                        if duration >= ALIGN_DURATION:
                            print("è¿›å…¥çŠ¶æ€46")
                            msg.mode = 11
                            msg.gait_id = 3
                            msg.vel_des = [0.1, 0, 0]
                            msg.rpy_des = [0, 2.5, 0]
                            msg.step_height = [0.03, 0.03]
                            msg.life_count = (msg.life_count + 1) % 128
                            Ctrl.Send_cmd(msg)
                            time.sleep(0.5)
                            state_id = 46
                            vision_node.angle_0 = 0
                            continue
                        
                        yaw_speed = np.clip(angle_error * KP + delta * KD, -MAX_YAW, MAX_YAW)
                        msg.mode = 11
                        msg.gait_id = 3
                        msg.vel_des = [0.01, 0.0, yaw_speed]
                        msg.rpy_des = [0, 2.5, 0]
                        msg.step_height = [0.03, 0.03]
                        msg.life_count = (msg.life_count + 1) % 128
                        Ctrl.Send_cmd(msg)
                        # print(f"è§’åº¦è¯¯å·®: {np.degrees(angle_error):+.1f}\u00B0 | æŒç»­: {duration:.4f}s | yaw: {yaw_speed:.2f}")
                        last_cmd_time = current_time
                    else:
                        msg.mode = 11
                        msg.gait_id = 3
                        msg.vel_des = [0.08, 0.01, SEARCH_SPEED]
                        msg.rpy_des = [0, 2.5, 0]
                        msg.step_height = [0.03, 0.03]
                        msg.life_count = (msg.life_count + 1) % 128
                        Ctrl.Send_cmd(msg)
                        # print("æœç´¢é»„çº¿")
                        last_cmd_time = current_time
            
            elif state_id == 46:
                if current_time - last_cmd_time > cmd_interval:
                    msg.mode = 11
                    msg.gait_id = 3
                    msg.vel_des = [0.1, 0, 0]
                    msg.rpy_des = [0, 2.5, 0]
                    msg.life_count = (msg.life_count + 1) % 128
                    Ctrl.Send_cmd(msg)
                    last_cmd_time = current_time

                if vision_node._46_detected:
                    msg.mode = 11
                    msg.gait_id = 3
                    msg.vel_des = [0.3, 0, 0]
                    msg.rpy_des = [0, 2.5, 0]
                    msg.life_count = (msg.life_count + 1) % 128
                    Ctrl.Send_cmd(msg)
                    time.sleep(0.7)
                    last_cmd_time = current_time

                    print("è¿›å…¥çŠ¶æ€47")
                    down()
                    #è¿›å…¥äº¤äº’
                    while(True):
                        if now_state == 1:
                            break
                    now_state = 0
                    # time.sleep(1)
                    standup()
                    time.sleep(2)

                    msg.mode = 11
                    msg.gait_id = 3
                    msg.vel_des = [-0.3, 0, 0]
                    msg.rpy_des = [0, 2.5, 0]
                    msg.life_count = (msg.life_count + 1) % 128
                    Ctrl.Send_cmd(msg)
                    time.sleep(1.5)
                    state_id = 47

            elif state_id == 47:
                '''if current_time - last_cmd_time > cmd_interval:
                    msg.mode = 11
                    msg.gait_id = 3
                    msg.vel_des = [-0.3, 0.0, 0.0]
                    msg.rpy_des = [0, 2.5, 0]
                    msg.life_count = (msg.life_count + 1) % 128
                    Ctrl.Send_cmd(msg)
                    last_cmd_time = current_time
                
                if vision_node._47_detected:
                    print("è¿›å…¥çŠ¶æ€48")
                    state_id = 48'''
                msg.mode = 11
                msg.gait_id = 10
                msg.vel_des = [-0.3, 0.0, 0.0]
                msg.rpy_des = [0, 2.5, 0]
                msg.life_count = (msg.life_count + 1) % 128
                Ctrl.Send_cmd(msg)
                time.sleep(1.0)
                print("è¿›å…¥çŠ¶æ€48")
                state_id = 48

            elif state_id == 48:
                # dir = 1 if QR1 == 'A-1' else -1
                dir = 1 if QR1 == 'A-2' else -1
                mul = 1.5 if QR1 == 'A-2' else 2.2
                msg.mode = 11
                msg.gait_id = 10 
                msg.vel_des = [-0.3, 0.0, 0.0]
                msg.rpy_des = [0, 2.5, 0]
                msg.life_count = (msg.life_count + 1) % 128
                Ctrl.Send_cmd(msg)
                time.sleep(0.5)
                msg.mode = 11
                msg.gait_id = 10
                msg.vel_des = [0.01 * mul, 0.0, -1.4 * dir]
                msg.life_count = (msg.life_count + 1) % 128
                Ctrl.Send_cmd(msg)
                time.sleep( 1.28 )
                msg.mode = 11
                msg.gait_id = 10
                msg.vel_des = [0.3, 0.0, 0.0]
                msg.rpy_des = [0, 2.5, 0]
                msg.life_count = (msg.life_count + 1) % 128
                Ctrl.Send_cmd(msg)
                time.sleep(0.4)
                state_id = 49
                print("è¿›å…¥çŠ¶æ€49")

            elif state_id == 49:
                if current_time - last_cmd_time > cmd_interval:
                    msg.mode = 11        # è¡Œèµ°æ¨¡å¼
                    msg.gait_id = 3     # æ­¥æ€ç±»å‹
                    msg.vel_des = [0.1, 0, 0]  # å‰è¿›é€Ÿåº¦0.3m/s
                    msg.life_count = (msg.life_count + 1) % 128
                    Ctrl.Send_cmd(msg)
                    last_cmd_time = current_time
                
                if vision_node._49_detected:
                    #print("è¿›å…¥çŠ¶æ€50")
                    '''msg.mode = 11
                    msg.gait_id = 10
                    msg.vel_des = [0.5, 0.0, -1.4]
                    msg.life_count = (msg.life_count + 1) % 128
                    Ctrl.Send_cmd(msg)
                    time.sleep( 1.3 )'''
                    state_id = 49.5

            elif state_id == 49.5:
                dur = 0.5 if QR1 == 'A-2' else 0.3
                msg.mode = 11
                msg.gait_id = 10
                msg.vel_des = [0.3, 0.0, 0.0]
                msg.life_count = (msg.life_count + 1) % 128
                Ctrl.Send_cmd(msg)
                time.sleep( dur )
                dir = 1 if QR1 == 'A-2' else -1
                dur = 1.24 if QR1 == 'A-2' else 1.2
                msg.mode = 11
                msg.gait_id = 10
                msg.vel_des = [0.3, 0.0, 1.4 * dir]
                msg.life_count = (msg.life_count + 1) % 128
                Ctrl.Send_cmd(msg)
                time.sleep( dur )

                # å¿…é¡»è½¬å¼¯å®Œååœä¸€ä¸‹
                '''msg.mode = 12 # Recovery stand
                msg.gait_id = 0
                msg.life_count = (msg.life_count + 1) % 128  # Command will take effect when life_count update
                Ctrl.Send_cmd(msg)
                Ctrl.Wait_finish(12, 0)
                last_cmd_time = current_time'''

                msg.mode = 11
                msg.gait_id = 10
                msg.vel_des = [0.3, 0.01, 0.01]
                msg.life_count = (msg.life_count + 1) % 128
                Ctrl.Send_cmd(msg)
                time.sleep( 1.5 )

                state_id = 50
                print("è¿›å…¥çŠ¶æ€50")

            elif state_id == 50:
                ALIGN_DURATION = 0.5    # éœ€è¦æŒç»­å¯¹é½æ—¶é—´ï¼ˆç§’ï¼‰
                KP = -0.4               # æ¯”ä¾‹ç³»æ•°
                KD = 1.6                # å¾®åˆ†ç³»æ•°
                angle_0 = 0.0           # åˆå§‹åŒ–è§’åº¦
                MAX_YAW = 0.05          # æœ€å¤§è½¬å‘é€Ÿåº¦ï¼ˆrad/sï¼‰
                SEARCH_SPEED = 0.0      # æœç´¢è½¬é€Ÿï¼ˆrad/sï¼‰
                
                if current_time - last_cmd_time > cmd_interval:
                    if vision_node._50_detected:
                        angle_error = vision_node.line_angle
                        delta = vision_node.angle_0 - angle_error
                        vision_node.angle_0 = angle_error
                        duration = vision_node.aligned_duration
                        
                        if duration >= ALIGN_DURATION:
                            print("è¿›å…¥çŠ¶æ€51")
                            vision_node.angle_0 = 0
                            state_id = 51
                            continue
                        
                        yaw_speed = np.clip(angle_error * KP + delta * KD, -MAX_YAW, MAX_YAW)
                        msg.mode = 11
                        msg.gait_id = 3
                        msg.vel_des = [0.01, 0.0, yaw_speed]
                        msg.rpy_des = [0, 2.5, 0]
                        msg.life_count = (msg.life_count + 1) % 128
                        Ctrl.Send_cmd(msg)
                        # print(f"è§’åº¦è¯¯å·®: {np.degrees(angle_error):+.1f}\u00B0 | æŒç»­: {duration:.4f}s | yaw: {yaw_speed:.2f}")
                        last_cmd_time = current_time
                    else:
                        msg.mode = 11
                        msg.gait_id = 3
                        msg.vel_des = [0.1, 0.0, SEARCH_SPEED]
                        msg.rpy_des = [0, 2.5, 0]
                        msg.life_count = (msg.life_count + 1) % 128
                        Ctrl.Send_cmd(msg)
                        # print("æœç´¢é»„çº¿")
                        last_cmd_time = current_time

            elif state_id == 51:
                if current_time - last_cmd_time > cmd_interval:
                    msg.mode = 11
                    msg.gait_id = 3
                    msg.vel_des = [0.05, 0, 0]
                    msg.rpy_des = [0, 2.5, 0]
                    msg.life_count = (msg.life_count + 1) % 128
                    Ctrl.Send_cmd(msg)
                    last_cmd_time = current_time

                if vision_node._51_detected:
                    msg.mode = 11
                    msg.gait_id = 3
                    msg.vel_des = [0.1, 0, 0]
                    msg.rpy_des = [0, 2.5, 0]
                    msg.life_count = (msg.life_count + 1) % 128
                    Ctrl.Send_cmd(msg)
                    time.sleep( 0.1 )
                    msg.mode = 11
                    msg.gait_id = 3
                    msg.vel_des = [0.01, 0.0, -1.4]
                    msg.life_count = (msg.life_count + 1) % 128
                    Ctrl.Send_cmd(msg)
                    time.sleep( 1.22 )
                    print("è¿›å…¥çŠ¶æ€53")
                    state_id = 53
            
            elif state_id == 52:
                if current_time - last_cmd_time > cmd_interval:
                    msg.mode = 11
                    msg.gait_id = 3
                    msg.vel_des = [-0.2, 0, 0]
                    msg.rpy_des = [0, 2.5, 0]
                    msg.life_count = (msg.life_count + 1) % 128
                    Ctrl.Send_cmd(msg)
                    last_cmd_time = current_time

                if vision_node._52_detected:
                    
                    msg.mode = 11
                    msg.gait_id = 3
                    msg.vel_des = [0.3, 0, 0]
                    msg.rpy_des = [0, 2.5, 0]
                    msg.life_count = (msg.life_count + 1) % 128
                    Ctrl.Send_cmd(msg)
                    time.sleep( 0.2 )
                    msg.mode = 11
                    msg.gait_id = 3
                    msg.vel_des = [0.3, 0.0, 2.25]
                    msg.life_count = (msg.life_count + 1) % 128
                    Ctrl.Send_cmd(msg)
                    time.sleep( 2.1 )
                    print("è¿›å…¥çŠ¶æ€53")
                    break
                    

            elif state_id == 53:
                msg.mode = 11
                msg.gait_id = 10
                msg.vel_des = [-0.3, 0, 0]
                msg.rpy_des = [0, 2.5, 0]
                msg.life_count = (msg.life_count + 1) % 128
                Ctrl.Send_cmd(msg)
                time.sleep( 3.5 )
                down()
                while(True):
                    continue
                break
            else:
                break
    except KeyboardInterrupt:
        print("ä¸­æ–­æ“ä½œ")
    finally:
        msg.mode = 12
        Ctrl.Send_cmd(msg)
        Ctrl.quit()
        executor.shutdown()
        cv2.destroyAllWindows()
        sys.exit()

# Main function
if __name__ == '__main__':
    main()
    
# coding: utf-8
